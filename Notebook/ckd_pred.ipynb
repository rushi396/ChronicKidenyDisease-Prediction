{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83320db",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17849910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2,f_classif\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5753f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22683917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  bp     sg al su  rbc  pc  pcc  ba  bgr  ... pcv  wbcc rbcc htn dm  cad  \\\n",
       "0  48  80   1.02  1  0    0   0    1   1  121  ...  44  7800  5.2   0  0    1   \n",
       "1   7  50   1.02  4  0    0   0    1   1    ?  ...  38  6000  0.0   1  1    1   \n",
       "2  62  80   1.01  2  3    0   0    1   1  423  ...  31  7500  0.0   1  0    1   \n",
       "3  48  70  1.005  4  0    0   1    0   1  117  ...  32  6700  3.9   0  1    1   \n",
       "4  51  80   1.01  2  0    0   0    1   1  106  ...  35  7300  4.6   1  1    1   \n",
       "\n",
       "   appet  pe  ane  class  \n",
       "0      1   1    1    ckd  \n",
       "1      1   1    1    ckd  \n",
       "2      0   1    0    ckd  \n",
       "3      0   0    0    ckd  \n",
       "4      1   1    1    ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Chronic_kidney_disease.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcfdef5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16045bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     400 non-null    object \n",
      " 1   bp      400 non-null    object \n",
      " 2   sg      400 non-null    object \n",
      " 3   al      400 non-null    object \n",
      " 4   su      400 non-null    object \n",
      " 5   rbc     400 non-null    int64  \n",
      " 6   pc      400 non-null    int64  \n",
      " 7   pcc     400 non-null    int64  \n",
      " 8   ba      400 non-null    int64  \n",
      " 9   bgr     400 non-null    object \n",
      " 10  bu      400 non-null    object \n",
      " 11  sc      400 non-null    object \n",
      " 12  sod     400 non-null    object \n",
      " 13  pot     400 non-null    object \n",
      " 14  hemo    400 non-null    object \n",
      " 15  pcv     400 non-null    int64  \n",
      " 16  wbcc    400 non-null    int64  \n",
      " 17  rbcc    400 non-null    float64\n",
      " 18  htn     400 non-null    int64  \n",
      " 19  dm      400 non-null    int64  \n",
      " 20  cad     400 non-null    int64  \n",
      " 21  appet   400 non-null    int64  \n",
      " 22  pe      400 non-null    int64  \n",
      " 23  ane     400 non-null    int64  \n",
      " 24  class   400 non-null    object \n",
      "dtypes: float64(1), int64(12), object(12)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b48ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.117500</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>31.982500</td>\n",
       "      <td>6178.500000</td>\n",
       "      <td>3.16575</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.322418</td>\n",
       "      <td>0.392792</td>\n",
       "      <td>0.319421</td>\n",
       "      <td>0.246835</td>\n",
       "      <td>16.962799</td>\n",
       "      <td>4490.489839</td>\n",
       "      <td>2.36621</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>0.479113</td>\n",
       "      <td>0.293582</td>\n",
       "      <td>0.406024</td>\n",
       "      <td>0.394757</td>\n",
       "      <td>0.359955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6900.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>9400.000000</td>\n",
       "      <td>5.10000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rbc          pc         pcc          ba         pcv  \\\n",
       "count  400.000000  400.000000  400.000000  400.000000  400.000000   \n",
       "mean     0.117500    0.190000    0.885000    0.935000   31.982500   \n",
       "std      0.322418    0.392792    0.319421    0.246835   16.962799   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    1.000000    1.000000   26.000000   \n",
       "50%      0.000000    0.000000    1.000000    1.000000   37.000000   \n",
       "75%      0.000000    0.000000    1.000000    1.000000   44.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000   54.000000   \n",
       "\n",
       "               wbcc       rbcc         htn          dm         cad  \\\n",
       "count    400.000000  400.00000  400.000000  400.000000  400.000000   \n",
       "mean    6178.500000    3.16575    0.627500    0.645000    0.905000   \n",
       "std     4490.489839    2.36621    0.484076    0.479113    0.293582   \n",
       "min        0.000000    0.00000    0.000000    0.000000    0.000000   \n",
       "25%        0.000000    0.00000    0.000000    0.000000    1.000000   \n",
       "50%     6900.000000    4.00000    1.000000    1.000000    1.000000   \n",
       "75%     9400.000000    5.10000    1.000000    1.000000    1.000000   \n",
       "max    26400.000000    8.00000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            appet          pe         ane  \n",
       "count  400.000000  400.000000  400.000000  \n",
       "mean     0.792500    0.807500    0.847500  \n",
       "std      0.406024    0.394757    0.359955  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      1.000000    1.000000    1.000000  \n",
       "50%      1.000000    1.000000    1.000000  \n",
       "75%      1.000000    1.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d9d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof = df.profile_report(title='Pandas Profiling Report')\n",
    "# prof.to_file(output_file=\"ckdreport.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926aaba",
   "metadata": {},
   "source": [
    "## Analying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0138650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB8kAAAedCAYAAADyRXfpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAADwyklEQVR4nOz9f7Rld1kn+L8fCEKMtuGHfVdI0oZpYjvRjIGpifhlpr2CtiF2G1xfmw7NQIJ0l3bHae3OOASdNdBq1oqjgRlopbv4hk7oFYGIP5I22BojV4ZZHRAwJiRIU0JhUgaiEgIlLVrx+f5xd5Fblco5t+qee865d79ea5119/mcvc99zpNK8qn93uezq7sDAAAAAAAAAGPwhEUXAAAAAAAAAADzIiQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA5LpKoOVNV3LLoOAAAAAABgecgPYLaE5AAAAAAAAACMhpAclkRVnbLoGgAAAAAAAGC3E5LDAg3Lo7y6qu5K8udJTknyP1TVvVX1UFX9+6p6yob9L6mqO6vq81X1h1V10cKKBwC2zTBHeM3x5gTmAwCw+53MXKCqnjbs98fDMb+60A8BAGyHx+QHVfXUqvq1qvqTYfzXquqsRRcKy666e9E1wGhV1YEkn0vyD5L8aZKPJjmU5EVZD83/Y5L3dPf/XlUXJrktyfcluT3JGUm+urv/YP6VAwDbaZgjPGZOkOSWmA8AwK53MnOBqrp1OOYHh5//n+7+nflXDwBshwnzgzckWU3y60memOStSZ7U3S9eRJ2wUwjJYYGG/6n9RHe/dcPza7r73w7PL07ypu7+21X175J8sbv/5aLqBQDm4/HmBEl+K+YDALDrnehcoKrOSHIwydO7+6E5lwsAzMGk/OCY/S7I+pfvnjr3ImEHsdw6LN59E55/Kskzh+2zk/zhXCoCAJbB8eYE5gMAMB4nMhc4O8lnBeQAsOs9Zn5QVV9ZVf+uqj5VVZ9P8t4kp1fVExdTIuwMQnJYvGOXczh7w/bfSvLHw/Z9Sf52AICxON6cwHwAAMbjROYC9yV5WlWdPoe6AIDFOd784MokfyfJt3T330jyd4fXa861wY4iJIflc0VVnVVVT0vy40neOYxfl+SVVfXCqnpCVZ1ZVd+wuDIBgG12vDmB+QAAjMem5wLd/UDW70P681X11Kp6UlX93UlvDgDsSMebH3x1kv+a5HPD+GsXWSDsFEJyWD6/kOQ3k3wi60uo/VSSdPcHkrwyyRuSPJzkd5J83YJqBAC232PmBOYDADAqJzoXeHmSv0ryB0keTPIjc64XANh+x8sP/q8kpyb50yR3JPlPiyoOdpLqPnalZwAAYJGq6kCSf9Ldv7XoWgCA+TMXAACA7eWb5AAAAAAAAACMhpAcAAAAAAAAgNGw3DoAAAAAAAAAo+Gb5AAAAAAAAACMximLLiBJnvGMZ/Q555yz5ff58z//85x22mlbL2gX06PJ9Gc6PZpMf6abVY8+9KEP/Wl3f+0MSmLJmBfMjx5Npj/T6dFk+jOdeQHTzGpekPh3chr9mU6PJtOfyfRnOvMCNsM5g/nQn+n0aDL9mU6PJpvHvGApQvJzzjknH/zgB7f8Pmtra1ldXd16QbuYHk2mP9Pp0WT6M92selRVn9p6NSwj84L50aPJ9Gc6PZpMf6YzL2CaWc0LEv9OTqM/0+nRZPozmf5MZ17AZjhnMB/6M50eTaY/0+nRZPOYF1huHQAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNE4ZdoOVfWUJO9N8uRh/3d192ur6vok35bk4WHXy7v7zqqqJP93kouTfHEY//B2FH+suw8+nMuvunUev2rTDlzz3YsuAQBGybwAAADg8Z2zZH9fuv6i0xZdAgCM1hjnBZv5JvmXkrygu785yQVJLqqq5w2v/Wh3XzA87hzGXpTk3OGxN8mbZ1syAAAAsGhV9ZSq+kBV/X5V3VNV/3oYv76qPllVdw6PC4bxqqo3VtX+qrqrqp670A8AAADAaE39Jnl3d5JDw9MnDY+ecMglSd42HHdHVZ1eVWd09wNbrhYAAABYFkcuqj9UVU9K8r6q+vXhtR/t7ncds//Gi+q/JesX1X/L3KoFAACAwdSQPEmq6olJPpTk2Ul+rrvfX1X/LMnVVfV/JLk9yVXd/aUkZya5b8Ph9w9jDxzznnuz/k3zrKysZG1tbYsfJVk5Nbny/MNbfp9ZmsXnmqVDhw4tXU3LRH+m06PJ9Gc6PQIA2B1cVA8AAMBOtamQvLsfSXJBVZ2e5Feq6puSvCbJp5N8RZJ9SV6d5Cc2+4u7e99wXPbs2dOrq6snVPjxvOnGm3Pt3Zv6SHNz4GWriy7hKGtra5lFr3cr/ZlOjybTn+n0CABg99gpF9UnLtacRn+m06PJ9GeyZezPsn3ZaBl7BADsXieUKHf356rqPUku6u6fHYa/VFX/Psn/Ojw/mOTsDYedNYwBAAAAu8hOuag+cbHmNPoznR5Npj+TLWN/Lr/q1kWXcJTrLzpt6XoEAOxeT5i2Q1V97fCX3VTVqUm+M8kfVNUZw1gleXGSjwyH3JLkFbXueUketnQaAAAA7F7d/bkkRy6qf6DXfSnJv09y4bCbi+oBAABYClND8iRnJHlPVd2V5HeT3Nbdv5bkxqq6O8ndSZ6R5KeG/d+d5BNJ9id5S5J/PvOqAQAAgIVyUT0AAAA71dTl1rv7riTPOc74Cx5n/05yxdZLAwAAAJbYGUluGO5L/oQkN3X3r1XVb1fV1yapJHcm+cFh/3cnuTjrF9V/Mckr518yAAAAnOA9yQEAAAASF9UDAACwc21muXUAAAAAAAAA2BWE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAOGlV9ZSq+kBV/X5V3VNV/3oYv76qPllVdw6PC4bxqqo3VtX+qrqrqp670A8AwOicsugCAAAAAACAHe1LSV7Q3Yeq6klJ3ldVvz689qPd/a5j9n9RknOHx7ckefPwEwDmwjfJAQAAAACAk9brDg1PnzQ8esIhlyR523DcHUlOr6oztrtOADjCN8kBAAAAAIAtqaonJvlQkmcn+bnufn9V/bMkV1fV/5Hk9iRXdfeXkpyZ5L4Nh98/jD1wnPfdm2RvkqysrGRtbW3LtR46dGgm77Nb6c90ejSZ/ky3bD268vzDiy7hKPPoj5AcANi0qnpKkvcmeXLW5xHv6u7XVtWzkrwjydOz/hfil3f3X1bVk5O8Lcl/n+TPkvyj7j6wkOIBAACAbdPdjyS5oKpOT/IrVfVNSV6T5NNJviLJviSvTvITJ/i++4Zjs2fPnl5dXd1yrWtra5nF++xW+jOdHk2mP9MtW48uv+rWRZdwlOsvOm3b+2O5dQDgRBy5x9g3J7kgyUVV9bwkP53kDd397CQPJXnVsP+rkjw0jL9h2A8AAADYpbr7c0nek+Si7n5gWFL9S0n+fZILh90OJjl7w2FnDWMAMBdCcgBg0ybcY+wFSd41jN+Q5MXD9iXD8wyvv7Cqaj7VAgAAAPNQVV87fIM8VXVqku9M8gdH7jM+nAt4cZKPDIfckuQVte55SR7u7scstQ4A28Vy6wDACTn2HmNJ/jDJ57r7yI1rjtxHLNlwj7HuPlxVD2d9SfY/PeY9Z35/sZVTl+9eOst0n6Fk+e59tGz0Zzo9mkx/ptMjAIBd44wkNwznDJ6Q5Kbu/rWq+u2q+tokleTOJD847P/uJBcn2Z/ki0leOf+SARgzITkAcEKOvcdYkm+YwXvO/P5ib7rx5lx793JNdQ68bHXRJRxl2e59tGz0Zzo9mkx/ptMjAIDdobvvSvKc44y/4HH27yRXbHddAPB4LLcOAJyUDfcY+9Ykp1fVkUR6433EvnyPseH1r0nyZ/OtFAAAAAAAHiUkBwA27XHuMfbRrIfl3zfsdlmSm4ftW4bnGV7/7eFqcQAAAAAAWIjlWoMUAFh2j3ePsXuTvKOqfirJ7yW5btj/uiT/oar2J/lskksXUTQAAAAAABwhJAcANm3CPcY+keTC44z/RZJ/OIfSAAAAAABgUyy3DgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMxNSSvqqdU1Qeq6ver6p6q+tfD+LOq6v1Vtb+q3llVXzGMP3l4vn94/Zxt/gwAAAAAAAAAsCmb+Sb5l5K8oLu/OckFSS6qqucl+ekkb+juZyd5KMmrhv1fleShYfwNw34AAADALuKiegAAAHaqqSF5rzs0PH3S8OgkL0jyrmH8hiQvHrYvGZ5neP2FVVWzKhgAAABYCi6qBwAAYEc6ZTM7VdUTk3woybOT/FySP0zyue4+POxyf5Izh+0zk9yXJN19uKoeTvL0JH96zHvuTbI3SVZWVrK2tralD5IkK6cmV55/ePqOczSLzzVLhw4dWrqalon+TKdHk+nPdHoEALA7dHcnebyL6v/xMH5DktcleXPWL6p/3TD+riT/pqpqeB8AAACYm02F5N39SJILqur0JL+S5Bu2+ou7e1+SfUmyZ8+eXl1d3epb5k033pxr797UR5qbAy9bXXQJR1lbW8sser1b6c90ejSZ/kynRwAAu8dOuag+cbHmNPoznR5Npj+TLWN/lu3LRsvYIwBg9zqhRLm7P1dV70nyrUlOr6pThr/4npXk4LDbwSRnJ7m/qk5J8jVJ/myGNQMAAABLYKdcVJ+4WHMa/ZlOjybTn8mWsT+XX3Xroks4yvUXnbZ0PQIAdq+p9ySvqq8d/rKbqjo1yXcm+WiS9yT5vmG3y5LcPGzfMjzP8PpvWzoNAAAAdq/u/lzWzxN8+aL64aXjXVQfF9UDAACwSFND8iRnJHlPVd2V5HeT3Nbdv5bk1Un+VVXtz/ryaNcN+1+X5OnD+L9KctXsywYAAAAWyUX1AAAA7FRTl1vv7ruSPOc4459IcuFxxv8iyT+cSXUAAADAsjojyQ3DfcmfkOSm7v61qro3yTuq6qeS/F6Ovqj+PwwX1X82yaWLKBoAAABO6J7kAAAAAImL6gEAANi5NrPcOgAAAAAAAADsCkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAABbUlVPqaoPVNXvV9U9VfWvh/FnVdX7q2p/Vb2zqr5iGH/y8Hz/8Po5C/0AAIyKkBwAAAAAANiqLyV5QXd/c5ILklxUVc9L8tNJ3tDdz07yUJJXDfu/KslDw/gbhv0AYC6E5AAAAAAAwJb0ukPD0ycNj07ygiTvGsZvSPLiYfuS4XmG119YVTWfagEYu1MWXQAAAAAAALDzVdUTk3woybOT/FySP0zyue4+POxyf5Izh+0zk9yXJN19uKoeTvL0JH96zHvuTbI3SVZWVrK2trblOg8dOjST99mt9Gc6PZpMf6Zbth5def7h6TvN0Tz6IyQHAAAAAAC2rLsfSXJBVZ2e5FeSfMMM3nNfkn1JsmfPnl5dXd3qW2ZtbS2zeJ/dSn+m06PJ9Ge6ZevR5VfduugSjnL9Radte38stw4AAAAAAMxMd38uyXuSfGuS06vqyBf2zkpycNg+mOTsJBle/5okfzbfSgEYKyE5AAAAAACwJVX1tcM3yFNVpyb5ziQfzXpY/n3DbpcluXnYvmV4nuH13+7unlvBAIya5dYBAAAAAICtOiPJDcN9yZ+Q5Kbu/rWqujfJO6rqp5L8XpLrhv2vS/Ifqmp/ks8muXQRRQMwTkJyAAAAAABgS7r7riTPOc74J5JceJzxv0jyD+dQGgA8huXWAQAAAAAAABgNITkAAAAAAAAAoyEkBwA2rarOrqr3VNW9VXVPVf3wMP66qjpYVXcOj4s3HPOaqtpfVR+rqu9aXPUAAAAAAOCe5ADAiTmc5Mru/nBVfXWSD1XVbcNrb+jun924c1Wdl+TSJN+Y5JlJfquqvr67H5lr1QAAAAAAMPBNcgBg07r7ge7+8LD9hSQfTXLmhEMuSfKO7v5Sd38yyf4kF25/pQAAAAAAcHy+SQ4AnJSqOifJc5K8P8nzk/xQVb0iyQez/m3zh7IeoN+x4bD7c5xQvar2JtmbJCsrK1lbW9tyfSunJleef3jL7zNLs/hcs3To0KGlq2mZ6M90ejSZ/kynRwAAAMAiCMkBgBNWVV+V5JeS/Eh3f76q3pzkJ5P08PPaJN+/2ffr7n1J9iXJnj17enV1dcs1vunGm3Pt3cs11TnwstVFl3CUtbW1zKLXu5X+TKdHk+nPdHoEAAAALILl1gGAE1JVT8p6QH5jd/9yknT3Z7r7ke7+6yRvyaNLqh9McvaGw88axgAAAAAAYCGE5ADAplVVJbkuyUe7+/Ubxs/YsNv3JvnIsH1Lkkur6slV9awk5yb5wLzqBQAAAACAYy3XGqQAwLJ7fpKXJ7m7qu4cxn4syUur6oKsL7d+IMkPJEl331NVNyW5N8nhJFd09yNzrhkAAAAAAL5MSA4AbFp3vy9JHeeld0845uokV29bUQAAAAAAcAIstw4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaU0Pyqjq7qt5TVfdW1T1V9cPD+Ouq6mBV3Tk8Lt5wzGuqan9Vfayqvms7PwAAAAAwf84XAAAAsFOdsol9Die5srs/XFVfneRDVXXb8NobuvtnN+5cVecluTTJNyZ5ZpLfqqqv7+5HZlk4AAAAsFDOFwAAALAjTf0meXc/0N0fHra/kOSjSc6ccMglSd7R3V/q7k8m2Z/kwlkUCwAAACwH5wsAAADYqTbzTfIvq6pzkjwnyfuTPD/JD1XVK5J8MOtXjz+U9b8Q37HhsPtznL8kV9XeJHuTZGVlJWtraydR/tFWTk2uPP/wlt9nlmbxuWbp0KFDS1fTMtGf6fRoMv2ZTo8AAHafZT9fkJiHTqM/0+nRZPoz2TL2Z9nOoy5jjwCA3WvTIXlVfVWSX0ryI939+ap6c5KfTNLDz2uTfP9m36+79yXZlyR79uzp1dXVEyj7+N5048259u4Tyv233YGXrS66hKOsra1lFr3erfRnOj2aTH+m0yMAgN1lJ5wvSMxDp9Gf6fRoMv2ZbBn7c/lVty66hKNcf9FpS9cjAGD3mrrcepJU1ZOy/hfeG7v7l5Okuz/T3Y90918neUseXSLtYJKzNxx+1jAGAAAA7CLOFwAAALATTQ3Jq6qSXJfko939+g3jZ2zY7XuTfGTYviXJpVX15Kp6VpJzk3xgdiUDAAAAi+Z8AQAAADvVZtYmf36Slye5u6ruHMZ+LMlLq+qCrC+fdiDJDyRJd99TVTcluTfJ4SRXdPcjsy0bAAAAWDDnCwAAANiRpobk3f2+JHWcl9494Zirk1y9hboAAACAJeZ8AQAAADvVpu5JDgAAAAAAAAC7gZAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAACAk1ZVZ1fVe6rq3qq6p6p+eBh/XVUdrKo7h8fFG455TVXtr6qPVdV3La56AMbolEUXAAAAAAAA7GiHk1zZ3R+uqq9O8qGqum147Q3d/bMbd66q85JcmuQbkzwzyW9V1dd39yNzrRqA0fJNcgAAAAAA4KR19wPd/eFh+wtJPprkzAmHXJLkHd39pe7+ZJL9SS7c/koBYJ1vkgMAAAAAADNRVeckeU6S9yd5fpIfqqpXJPlg1r9t/lDWA/Q7Nhx2fx4nVK+qvUn2JsnKykrW1ta2XOOhQ4dm8j67lf5Mp0eT6c90y9ajK88/vOgSjjKP/gjJAQAAAACALauqr0ryS0l+pLs/X1VvTvKTSXr4eW2S7z+R9+zufUn2JcmePXt6dXV1y3Wura1lFu+zW+nPdHo0mf5Mt2w9uvyqWxddwlGuv+i0be+P5dYBAAAAAIAtqaonZT0gv7G7fzlJuvsz3f1Id/91krfk0SXVDyY5e8PhZw1jADAXQnIAAAAAAOCkVVUluS7JR7v79RvGz9iw2/cm+ciwfUuSS6vqyVX1rCTnJvnAvOoFAMutAwAAAAAAW/H8JC9PcndV3TmM/ViSl1bVBVlfbv1Akh9Iku6+p6puSnJvksNJrujuR+ZcMwAjJiQHAAAAAABOWne/L0kd56V3Tzjm6iRXb1tRADCB5dYBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwA2rarOrqr3VNW9VXVPVf3wMP60qrqtqj4+/HzqMF5V9caq2l9Vd1XVcxf7CQAAAAAAGDshOQBwIg4nubK7z0vyvCRXVNV5Sa5Kcnt3n5vk9uF5krwoybnDY2+SN8+/ZAAAAAAAeJSQHADYtO5+oLs/PGx/IclHk5yZ5JIkNwy73ZDkxcP2JUne1uvuSHJ6VZ0x36oBAAAAAOBRpyy6AABgZ6qqc5I8J8n7k6x09wPDS59OsjJsn5nkvg2H3T+MPbBhLFW1N+vfNM/KykrW1ta2XN/KqcmV5x/e8vvM0iw+1ywdOnRo6WpaJvoznR5Npj/T6REAAACwCEJyAOCEVdVXJfmlJD/S3Z+vqi+/1t1dVX0i79fd+5LsS5I9e/b06urqlmt8040359q7l2uqc+Blq4su4Shra2uZRa93K/2ZTo8m05/p9AgAAABYBMutAwAnpKqelPWA/Mbu/uVh+DNHllEffj44jB9McvaGw88axgAAAAAAYCGE5ADAptX6V8avS/LR7n79hpduSXLZsH1Zkps3jL+i1j0vycMblmUHAAAAAIC5W641SAGAZff8JC9PcndV3TmM/ViSa5LcVFWvSvKpJC8ZXnt3kouT7E/yxSSvnGu1AAAAAABwDCE5ALBp3f2+JPU4L7/wOPt3kiu2tSgAAAAAADgBllsHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjMbUkLyqzq6q91TVvVV1T1X98DD+tKq6rao+Pvx86jBeVfXGqtpfVXdV1XO3+0MAAAAAAAAAwGZs5pvkh5Nc2d3nJXlekiuq6rwkVyW5vbvPTXL78DxJXpTk3OGxN8mbZ141AAAAsFAuqgcAAGCnmhqSd/cD3f3hYfsLST6a5MwklyS5YdjthiQvHrYvSfK2XndHktOr6oxZFw4AAAAslIvqAQAA2JFOOZGdq+qcJM9J8v4kK939wPDSp5OsDNtnJrlvw2H3D2MPbBhLVe3N+l+Ks7KykrW1tRMs/bFWTk2uPP/wlt9nlmbxuWbp0KFDS1fTMtGf6fRoMv2ZTo8AAHaH4ZzAA8P2F6pq40X1q8NuNyRZS/LqbLioPskdVXV6VZ2x4dwCAAAAzMWmQ/Kq+qokv5TkR7r781X15de6u6uqT+QXd/e+JPuSZM+ePb26unoihx/Xm268OdfefUK5/7Y78LLVRZdwlLW1tcyi17uV/kynR5Ppz3R6BACw+yz7RfWJizWn0Z/p9Ggy/ZlsGfuzbF82WsYeAQC716YS5ap6UtYD8hu7+5eH4c8cueJ7WE79wWH8YJKzNxx+1jAGAAAA7DI74aL6xMWa0+jPdHo0mf5Mtoz9ufyqWxddwlGuv+i0pesRALB7Tb0nea3/7fa6JB/t7tdveOmWJJcN25cluXnD+Ctq3fOSPGzpNAAAANh9Jl1UP7zuonoAAACWztSQPMnzk7w8yQuq6s7hcXGSa5J8Z1V9PMl3DM+T5N1JPpFkf5K3JPnnsy8bAAAAWCQX1QMAALBTTV1uvbvfl6Qe5+UXHmf/TnLFFusCAAAAltuRi+rvrqo7h7Efy/pF9DdV1auSfCrJS4bX3p3k4qxfVP/FJK+ca7UAAAAw2NQ9yQEAAAA2clE9AAAAO9VmllsHAAAAAAAAgF1BSA4AAAAAAADAaAjJAQAAAACALamqs6vqPVV1b1XdU1U/PIw/rapuq6qPDz+fOoxXVb2xqvZX1V1V9dzFfgIAxkRIDgAAAAAAbNXhJFd293lJnpfkiqo6L8lVSW7v7nOT3D48T5IXJTl3eOxN8ub5lwzAWAnJAQAAAACALenuB7r7w8P2F5J8NMmZSS5JcsOw2w1JXjxsX5Lkbb3ujiSnV9UZ860agLE6ZdEFAAAAAAAAu0dVnZPkOUnen2Slux8YXvp0kpVh+8wk92047P5h7IENY6mqvVn/pnlWVlaytra25foOHTo0k/fZrfRnOj2aTH+mW7YeXXn+4UWXcJR59EdIDgAAAAAAzERVfVWSX0ryI939+ar68mvd3VXVJ/J+3b0vyb4k2bNnT6+urm65xrW1tczifXYr/ZlOjybTn+mWrUeXX3Xroks4yvUXnbbt/bHcOgAAAAAAsGVV9aSsB+Q3dvcvD8OfObKM+vDzwWH8YJKzNxx+1jAGANtOSA4AAAAAAGxJrX9l/LokH+3u12946ZYklw3blyW5ecP4K2rd85I8vGFZdgDYVpZbBwAAAAAAtur5SV6e5O6qunMY+7Ek1yS5qapeleRTSV4yvPbuJBcn2Z/ki0leOddqARg1ITkAAAAAALAl3f2+JPU4L7/wOPt3kiu2tSgAeByWWwcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAwKZV1Vur6sGq+siGsddV1cGqunN4XLzhtddU1f6q+lhVfddiqgYAAAAAgEcJyQGAE3F9kouOM/6G7r5geLw7SarqvCSXJvnG4Zifr6onzq1SAAAAAAA4DiE5ALBp3f3eJJ/d5O6XJHlHd3+puz+ZZH+SC7etOAAAAAAA2IRTFl0AALAr/FBVvSLJB5Nc2d0PJTkzyR0b9rl/GHuMqtqbZG+SrKysZG1tbcsFrZyaXHn+4S2/zyzN4nPN0qFDh5aupmWiP9Pp0WT6M50eAQAAAIsgJAcAturNSX4ySQ8/r03y/SfyBt29L8m+JNmzZ0+vrq5uuag33Xhzrr17uaY6B162uugSjrK2tpZZ9Hq30p/p9Ggy/ZlOjwAAAIBFsNw6ALAl3f2Z7n6ku/86yVvy6JLqB5OcvWHXs4YxAAAAAABYGCE5ALAlVXXGhqffm+Qjw/YtSS6tqidX1bOSnJvkA/OuDwAAAAAANlquNUgBgKVWVW9PsprkGVV1f5LXJlmtqguyvtz6gSQ/kCTdfU9V3ZTk3iSHk1zR3Y8soGwAAAAAAPgyITkAsGnd/dLjDF83Yf+rk1y9fRUBAAAAAMCJsdw6AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaU0PyqnprVT1YVR/ZMPa6qjpYVXcOj4s3vPaaqtpfVR+rqu/arsIBAAAAAAAA4ERt5pvk1ye56Djjb+juC4bHu5Okqs5LcmmSbxyO+fmqeuKsigUAAACWhwvrAQAA2ImmhuTd/d4kn93k+12S5B3d/aXu/mSS/Uku3EJ9AAAAwPK6Pi6sBwAAYIc5ZQvH/lBVvSLJB5Nc2d0PJTkzyR0b9rl/GHuMqtqbZG+SrKysZG1tbQulrFs5Nbny/MNbfp9ZmsXnmqVDhw4tXU3LRH+m06PJ9Gc6PQIA2D26+71Vdc4md//yhfVJPllVRy6s/8/bVR8AAAAcz8mG5G9O8pNJevh5bZLvP5E36O59SfYlyZ49e3p1dfUkS3nUm268OdfevZXcf/YOvGx10SUcZW1tLbPo9W6lP9Pp0WT6M50eAQCMwklfWL8dF9UnLtacRn+m06PJ9GeyZezPsn3ZaBl7BADsXieVKHf3Z45sV9Vbkvza8PRgkrM37HrWMAYAAACMw5YurN+Oi+oTF2tOoz/T6dFk+jPZMvbn8qtuXXQJR7n+otOWrkcAwO419Z7kx1NVZ2x4+r1JPjJs35Lk0qp6clU9K8m5ST6wtRIBAACAnaK7P9Pdj3T3Xyd5S9aXVE9cWA8AAMCSmPpN8qp6e5LVJM+oqvuTvDbJalVdkPWrwg8k+YEk6e57quqmJPcmOZzkiu5+ZFsqBwAAAJZOVZ3R3Q8MT4+9sP4Xqur1SZ4ZF9YDAACwIFND8u5+6XGGr5uw/9VJrt5KUQAAAMDyc2E9AAAAO9FJ3ZMcAAAAwIX1AMARVfXWJH8/yYPd/U3D2OuS/NMkfzLs9mPd/e7htdckeVWSR5L8i+7+jbkXDcBondQ9yQEAAAAAADa4PslFxxl/Q3dfMDyOBOTnJbk0yTcOx/x8VT1xbpUCMHpCcgAAAAAAYEu6+71JPrvJ3S9J8o7u/lJ3fzLJ/iQXbltxAHAMy60DAAAAAADb5Yeq6hVJPpjkyu5+KMmZSe7YsM/9w9hjVNXeJHuTZGVlJWtra1su6NChQzN5n91Kf6bTo8n0Z7pl69GV5x9edAlHmUd/hOQAAAAAAMB2eHOSn0zSw89rk3z/ibxBd+9Lsi9J9uzZ06urq1suam1tLbN4n91Kf6bTo8n0Z7pl69HlV9266BKOcv1Fp217fyy3DgAAAAAAzFx3f6a7H+nuv07yljy6pPrBJGdv2PWsYQwA5kJIDgAAAAAAzFxVnbHh6fcm+ciwfUuSS6vqyVX1rCTnJvnAvOsDYLwstw4AAAAAAGxJVb09yWqSZ1TV/Ulem2S1qi7I+nLrB5L8QJJ09z1VdVOSe5McTnJFdz+ygLIBGCkhOQAAAAAAsCXd/dLjDF83Yf+rk1y9fRUBwOOz3DoAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwBOSFW9taoerKqPbBh7WlXdVlUfH34+dRivqnpjVe2vqruq6rmLqxwAAAAAAITkAMCJuz7JRceMXZXk9u4+N8ntw/MkeVGSc4fH3iRvnlONAAAAAABwXEJyAOCEdPd7k3z2mOFLktwwbN+Q5MUbxt/W6+5IcnpVnTGXQgEAAAAA4DhOWXQBAMCusNLdDwzbn06yMmyfmeS+DfvdP4w9sGEsVbU36980z8rKStbW1rZe0KnJlecf3vL7zNIsPtcsHTp0aOlqWib6M50eTaY/0+kRAAAAsAhCcgBgprq7q6pP8Jh9SfYlyZ49e3p1dXXLdbzpxptz7d3LNdU58LLVRZdwlLW1tcyi17uV/kynR5Ppz3R6BAAAACyC5dYBgFn4zJFl1IefDw7jB5OcvWG/s4YxAAAAAABYCCE5ADALtyS5bNi+LMnNG8ZfUeuel+ThDcuyAwAAAADA3C3XGqQAwNKrqrcnWU3yjKq6P8lrk1yT5KaqelWSTyV5ybD7u5NcnGR/ki8meeXcCwYAAAAAgA2E5ADACenulz7OSy88zr6d5IrtrQgAAAAAADbPcusAAAAAAAAAjMbUkLyq3lpVD1bVRzaMPa2qbquqjw8/nzqMV1W9sar2V9VdVfXc7SweAAAAWBznDAAAANiJNvNN8uuTXHTM2FVJbu/uc5PcPjxPkhclOXd47E3y5tmUCQAAACyh6+OcAQAAADvM1JC8u9+b5LPHDF+S5IZh+4YkL94w/rZed0eS06vqjBnVCgAAACwR5wwAAADYiU45yeNWuvuBYfvTSVaG7TOT3Ldhv/uHsQdyjKram/Urx7OyspK1tbWTLGVDUacmV55/eMvvM0uz+FyzdOjQoaWraZnoz3R6NJn+TKdHAAC73pbOGWzH+YLEPHQa/ZlOjybTn8mWsT/Ldh51GXsEAOxeJxuSf1l3d1X1SRy3L8m+JNmzZ0+vrq5utZS86cabc+3dW/5IM3XgZauLLuEoa2trmUWvdyv9mU6PJtOf6fQIAGA8TuacwXacL0jMQ6fRn+n0aDL9mWwZ+3P5VbcuuoSjXH/RaUvXIwBg99rMPcmP5zNHlkQbfj44jB9McvaG/c4axgAAAIBxcM4AAACApXayIfktSS4bti9LcvOG8VfUuucleXjDEmsAAADA7uecAQCMUFW9taoerKqPbBh7WlXdVlUfH34+dRivqnpjVe2vqruq6rmLqxyAMZoaklfV25P85yR/p6rur6pXJbkmyXdW1ceTfMfwPEneneQTSfYneUuSf74tVQMAAAAL55wBALDB9UkuOmbsqiS3d/e5SW4fnifJi5KcOzz2JnnznGoEgCSbuCd5d7/0cV564XH27SRXbLUoAAAAYPk5ZwAAHNHd762qc44ZviTJ6rB9Q5K1JK8ext82zA/uqKrTq+oMq8wAMC9TQ3IAAAAAAICTsLIh+P50kpVh+8wk923Y7/5h7DEheVXtzfq3zbOyspK1tbUtF3Xo0KGZvM9upT/T6dFk+jPdsvXoyvMPL7qEo8yjP0JyAAAAAABgW3V3V1WfxHH7kuxLkj179vTq6uqWa1lbW8ss3me30p/p9Ggy/Zlu2Xp0+VW3LrqEo1x/0Wnb3p+p9yQHAAAAAAA4CZ+pqjOSZPj54DB+MMnZG/Y7axgDgLkQkgMAAAAAANvhliSXDduXJbl5w/grat3zkjzsfuQAzJPl1gEAAAAAgC2pqrcnWU3yjKq6P8lrk1yT5KaqelWSTyV5ybD7u5NcnGR/ki8meeXcCwZg1ITkAAAAAADAlnT3Sx/npRceZ99OcsX2VgQAj89y6wAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABiNUxZdAAAAAPNxzlW3LrqEo1x/0WmLLgEAAAAYId8kBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0Tll0AQDA7lFVB5J8IckjSQ53956qelqSdyY5J8mBJC/p7ocWVSMAAAAAAOPmm+QAwKx9e3df0N17hudXJbm9u89NcvvwHAAAAAAAFkJIDgBst0uS3DBs35DkxYsrBQAAAACAsbPcOgAwS53kN6uqk/y77t6XZKW7Hxhe/3SSlWMPqqq9SfYmycrKStbW1rZcyMqpyZXnH97y+8zSLD7XLB06dGjpalom+jOdHk22jP1Ztv8uLmOPAAAAgN1PSA4AzNL/2N0Hq+pvJrmtqv5g44vd3UOAnmPG9yXZlyR79uzp1dXVLRfyphtvzrV3L9dU58DLVhddwlHW1tYyi17vVvoznR5Ntoz9ufyqWxddwlGuv+i0pesRAAAAsPtt6cxxVR1I8oUkjyQ53N17quppSd6Z5JwkB5K8pLsf2lqZAMBO0N0Hh58PVtWvJLkwyWeq6ozufqCqzkjy4EKLBADmwjkDAAAAltUs7kn+7d19QXfvGZ5fleT27j43ye3DcwBgl6uq06rqq49sJ/l7ST6S5JYklw27XZbk5sVUCAAsgHMGAAAALJ1ZhOTHuiTJDcP2DUlevA2/AwBYPitJ3ldVv5/kA0lu7e7/lOSaJN9ZVR9P8h3DcwBgnJwzAAAAYOG2eqPOTvKbw71F/91wP9GV7n5geP3TWT9h/hhVtTfJ3iRZWVnJ2traFktJVk5Nrjz/8JbfZ5Zm8blm6dChQ0tX0zLRn+n0aDL9mU6Pdq/u/kSSbz7O+J8leeH8KwIAFuykzhlsx/mCxDx0Gv2ZTo8m05/JlrE/y3YedRl7xOy4DQsAy2arIfn/2N0Hq+pvJrmtqv5g44vd3cNfhh9j+MvxviTZs2dPr66ubrGU5E033pxr797qR5qtAy9bXXQJR1lbW8sser1b6c90ejSZ/kynRwAAo3FS5wy243xBYh46jf5Mp0eT6c9ky9ify6+6ddElHOX6i05buh4xc9/e3X+64fmR27BcU1VXDc9fvZjSABibLS233t0Hh58PJvmVJBcm+UxVnZEkw88Ht1okAAAAsLM4ZwAATOE2LAAszEl/7bqqTkvyhO7+wrD995L8RJJbklyW9fuNXpbk5lkUCsCJO2fJrgpP1q8MBwBgd3POAAA4xlLdutXy/pPpz3R6NJn+TLdsPRrjbVi2sjb5SpJfqaoj7/ML3f2fqup3k9xUVa9K8qkkL9l6mQAAAMAOsnTnDO4++PBSLS184JrvXnQJADBPS3Xr1mW8BcIy0Z/p9Ggy/Zlu2Xq0TH9XSuZzG5aTDsm7+xNJvvk443+W5IVbKQoAAADYuZwzAAA22ngblqo66jYs3f2A27AAMG9buic5AAAAAADA46mq06rqq49sZ/02LB/Jo7dhSdyGBYA528py6wAAAAAAAJMs3W1YAEBIDgAAAAAAbAu3YQFgGVluHQAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGqcsugAAAAAAAIB5ufvgw7n8qlsXXcaXHbjmuxddAsDo+CY5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBrbFpJX1UVV9bGq2l9VV23X7wEAlp95AQBwhHkBAHCEeQEAi7ItIXlVPTHJzyV5UZLzkry0qs7bjt8FACw38wIA4AjzAgDgCPMCABZpu75JfmGS/d39ie7+yyTvSHLJNv0uAGC5mRcAAEeYFwAAR5gXALAwp2zT+56Z5L4Nz+9P8i0bd6iqvUn2Dk8PVdXHZvB7n5HkT2fwPjNTP73oCh5j6Xq0ZPRnOj2aTH+m+PafnlmPvm4G78F8mBcMzAt2HP2ZTo8m058pzAtGaVHzgmTJ/p00L9iR9Ggy/ZlMf6YwLxilqfOCZBznDMwLdiQ9mkx/ptOjCeYxL9iukHyq7t6XZN8s37OqPtjde2b5nruNHk2mP9Pp0WT6M50ecTzmBYuhR5Ppz3R6NJn+TKdHHM92zAsSf96m0Z/p9Ggy/ZlMf6bTIx6Pcwbzpz/T6dFk+jOdHk02j/5s13LrB5OcveH5WcMYADA+5gUAwBHmBQDAEeYFACzMdoXkv5vk3Kp6VlV9RZJLk9yyTb8LAFhu5gUAwBHmBQDAEeYFACzMtiy33t2Hq+qHkvxGkicmeWt337Mdv+sYM1+ObRfSo8n0Zzo9mkx/ptOjkTEvWGp6NJn+TKdHk+nPdHo0MgucFyT+vE2jP9Pp0WT6M5n+TKdHI2NesNT0Zzo9mkx/ptOjyba9P9Xd2/07AAAAAAAAAGApbNdy6wAAAAAAAACwdITkAAAAAAAAAIzGjgzJq+qiqvpYVe2vqquO8/qTq+qdw+vvr6pzFlDmwmyiP/+qqu6tqruq6vaq+rpF1LlI03q0Yb//b1V1Ve2ZZ32Ltpn+VNVLhj9H91TVL8y7xkXbxL9nf6uq3lNVvzf8u3bxIupclKp6a1U9WFUfeZzXq6reOPTvrqp67rxrZPcwL5jO3GAy84LpzA0mMy+YzLyAeTIvmM68YDLzgunMCyYzL5jMvIB5Mi+YzrxgMvOC6cwLJjMvmGzh84Lu3lGPJE9M8odJ/pskX5Hk95Ocd8w+/zzJvx22L03yzkXXvWT9+fYkXzls/7Mx9WezPRr2++ok701yR5I9i657mfqT5Nwkv5fkqcPzv7noupewR/uS/LNh+7wkBxZd95x79HeTPDfJRx7n9YuT/HqSSvK8JO9fdM0eO/NhXjCzHo12bmBeMLM/Q6OdG5gXbKpH5gUec3mYF8ysR+YF5gVb/TNkXmBeMKlH5gUec3mYF8ysR+YF5gVb/TNkXmBeMKlHC50X7MRvkl+YZH93f6K7/zLJO5Jccsw+lyS5Ydh+V5IXVlXNscZFmtqf7n5Pd39xeHpHkrPmXOOibebPUJL8ZJKfTvIX8yxuCWymP/80yc9190NJ0t0PzrnGRdtMjzrJ3xi2vybJH8+xvoXr7vcm+eyEXS5J8rZed0eS06vqjPlUxy5jXjCducFk5gXTmRtMZl4whXkBc2ReMJ15wWTmBdOZF0xmXjCFeQFzZF4wnXnBZOYF05kXTGZeMMWi5wU7MSQ/M8l9G57fP4wdd5/uPpzk4SRPn0t1i7eZ/mz0qqxfhTEmU3s0LNlwdnffOs/ClsRm/gx9fZKvr6r/t6ruqKqL5lbdcthMj16X5H+uqvuTvDvJ/zKf0naME/1vFTwe84LpzA0mMy+YztxgMvOCrTMvYFbMC6YzL5jMvGA684LJzAu2zryAWTEvmM68YDLzgunMCyYzL9i6bZ0XnDKrN2Lnqar/OcmeJN+26FqWSVU9Icnrk1y+4FKW2SlZXyZlNetXD763qs7v7s8tsqgl89Ik13f3tVX1rUn+Q1V9U3f/9aILA3g85gaPZV6waeYGk5kXADuOecFjmRdsmnnBZOYFwI5jXvBY5gWbZl4wmXnBAu3Eb5IfTHL2hudnDWPH3aeqTsn6EgV/NpfqFm8z/UlVfUeSH0/yPd39pTnVtiym9eirk3xTkrWqOpD1+xzcUlV75lbhYm3mz9D9SW7p7r/q7k8m+S9Z/x/dWGymR69KclOSdPd/TvKUJM+YS3U7w6b+WwWbYF4wnbnBZOYF05kbTGZesHXmBcyKecF05gWTmRdMZ14wmXnB1pkXMCvmBdOZF0xmXjCdecFk5gVbt63zgp0Ykv9uknOr6llV9RVJLk1yyzH73JLksmH7+5L8dvf6Hd5HYGp/quo5Sf5d1v+nNqb7PxwxsUfd/XB3P6O7z+nuc7J+r5Xv6e4PLqbcudvMv2O/mvUrv1JVz8j6kimfmGONi7aZHv1RkhcmSVX9t1n/n9ufzLXK5XZLklfUuuclebi7H1h0UexI5gXTmRtMZl4wnbnBZOYFW2dewKyYF0xnXjCZecF05gWTmRdsnXkBs2JeMJ15wWTmBdOZF0xmXrB12zov2HHLrXf34ar6oSS/keSJSd7a3fdU1U8k+WB335LkuqwvSbA/6zd8v3RxFc/XJvvzM0m+KskvVlWS/FF3f8/Cip6zTfZotDbZn99I8veq6t4kjyT50e4ezVWWm+zRlUneUlX/MkknuXxMk+yqenvWJz/PqPX7qbw2yZOSpLv/bdbvr3Jxkv1JvpjklYuplJ3OvGA6c4PJzAumMzeYzLxgOvMC5sW8YDrzgsnMC6YzL5jMvGA68wLmxbxgOvOCycwLpjMvmMy8YLpFzwtqRL0GAAAAAAAAYOR24nLrAAAAAAAAAHBShOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjISQHAAAAAAAAYDSE5AAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAS6iquqqeveg6AIDFqKoDVfUdi64DAFgscwLYHkJyAAAAAAAA2EGqarWq7l90HbBTCckBAAAAYIlU1SmLrgEAAHYzITksyLBEymuq6t6qeqiq/n1VPWV47ZKqurOqPl9Vf1hVF1XVP6qqDx7zHv+yqm5ZzCcAAE5GVb2yqv7jhucfr6pf3PD8vqq6YHh6cVV9oqr+tKp+pqqesGG/f1pVH62qLwzziecO42dX1S9X1Z9U1Z9V1b+Z12cDAE7ecJ7g1VV1V5I/T3JKkv/heOcNhv0fc+5gGH/asO8fD8f96mI+EQAwQxdU1V1V9XBVvbOqTkvy60meWVWHhsczq+p1VXVTVb1tOF9wT1XtWXTxsIyE5LBYL0vyXUn+dpKvT/K/V9WFSd6W5EeTnJ7k7yY5kOQ/Jvk7VXXuhuP/cZJfmGO9AMDW/U6S/6mqnlBVz0zyFUm+NUmq6r9J8lVJ7hr2/d4ke5I8N8klSb5/2O8fJnldklck+RtJvifJn1XVE5P8WpJPJTknyZlJ3jGPDwUAzMRLk3x31s8HHM5xzhskyYRzB0nyH5J8ZZJvTPI3k7xhTrUDANvnJUkuSvKsJP9dkpcneVGSP+7urxoefzzs+z1ZPxdwepJbkrh4Ho5DSA6L9W+6+77u/mySq7P+l+FXJXlrd9/W3X/d3Qe7+w+6+4tJbh72yRCWf0PW/ycHAOwQ3f2JJF9IckHWT2j/RpI/rqpvSPJtSf6f7v7rYfef7u7PdvcfJfm/MswDkvyTJP9nd/9ur9vf3Z9KcmGSZyb50e7+8+7+i+5+39w+HACwVW8czhP81+H58c4bJI9z7qCqzsj6CfMf7O6Huvuvuvt3FvA5AIDZemN3//EwJ/iPWT+n8Hje193v7u5Hsn7x3DfPo0DYaYTksFj3bdj+VNZPap+d5A8fZ/9fyKN/If7HSX51CM8BgJ3ld5KsZj0k/50ka1kPyL9teH7E8eYKyePPF85O8qnuPjzbcgGAOblvwvPNzgU+290PbUNtAMDifHrD9hezvgrdZvd9SlWdsi1VwQ4mJIfFOnvD9t9K8sdZ/wvw336c/W9L8rXDfUpfGkutA8BOdSQk/5+G7d/J8UPy480VksefL9yX5G/5yy8A7Fh9zPOTmQs8rapOn31pAMCSOXbeAJwAITks1hVVdVZVPS3Jjyd5Z5Lrkryyql443Kv0zGH51XT3XyX5xSQ/k+RpWQ/NAYCd53eSfHuSU7v7/iT/T9bvLfb0JL+3Yb8fraqnVtXZSX4463OFJPn/Jflfq+q/r3XPrqqvS/KBJA8kuaaqTquqp1TV8+f1oQCAmTveeYPkcc4ddPcDSX49yc8Pc4gnVdXfXVTxAMC2+kySp1fV1yy6ENiJhOSwWL+Q5DeTfCLry6T9VHd/IMkrk7whycNZP4n+dccc8x1JftFSqgCwM3X3f0lyKOvheLr781mfD/y/wz3Djrg5yYeS3Jnk1qyfEE93/2LW70v6C1m/v/mvJnnacOw/SPLsJH+U5P4k/2jbPxAAsF0ec94gSaacO3h5kr9K8gdJHkzyI3OtGACYi+7+gyRvT/KJqvpcVT1z2jHAo6rbagywCFV1IMk/6e7fWnQtAAAAAAAAMBa+SQ4AAAAAAADAaAjJAQAAAAAAABgNy60DAAAAAAAAMBq+SQ4AAAAAAADAaJyy6AKS5BnPeEafc845W36fP//zP89pp5229YJ2Ab04mn48Si8epReP2om9+NCHPvSn3f21i66D2TMv2D568lh6cjT9eCw9eaxl7Il5we41q3lBspx/dqdR83zsxJqTnVm3mudnJ9Y9q5rNC3Y35wzmQ3+m06PJ9Gc6PZpsHvOCLYXkVfUvk/yTJJ3k7iSvTHJGknckeXqSDyV5eXf/5aT3Oeecc/LBD35wK6UkSdbW1rK6urrl99kN9OJo+vEovXiUXjxqJ/aiqj616BrYHuYF20dPHktPjqYfj6Unj7WMPTEv2L1mNS9IlvPP7jRqno+dWHOyM+tW8/zsxLpnVbN5we7mnMF86M90ejSZ/kynR5PNY15w0sutV9WZSf5Fkj3d/U1Jnpjk0iQ/neQN3f3sJA8ledXJ/g4AAAAAAAAAmKWt3pP8lCSnVtUpSb4yyQNJXpDkXcPrNyR58RZ/BwCwJKrqrVX1YFV9ZMPYz1TVH1TVXVX1K1V1+obXXlNV+6vqY1X1XQspGgAAAAAANjjp5da7+2BV/WySP0ryX5P8ZtaXV/9cdx8edrs/yZnHO76q9ibZmyQrKytZW1s72VK+7NChQzN5n91AL46mH4/Si0fpxaP0ghNwfZJ/k+RtG8ZuS/Ka7j5cVT+d5DVJXl1V52V9lZlvTPLMJL9VVV/f3Y/MuWYAAAAAAPiykw7Jq+qpSS5J8qwkn0vyi0ku2uzx3b0vyb4k2bNnT89iXXnr9z9KL46mH4/Si0fpxaP0gs3q7vdW1TnHjP3mhqd3JPm+YfuSJO/o7i8l+WRV7U9yYZL/PI9aAQAAAADgeE46JE/yHUk+2d1/kiRV9ctJnp/k9Ko6Zfg2+VlJDm69TABgh/j+JO8cts/Memh+hBVmFkxPHktPjqYfj6Unj6UnAAAAwE63lZD8j5I8r6q+MuvLrb8wyQeTvCfr3yB7R5LLkty81SIBgOVXVT+e5HCSG0/0WCvMzIeePJaeHE0/HktPHktPAAAAgJ3uCSd7YHe/P8m7knw4yd3De+1L8uok/2pYUvXpSa6bQZ0AwBKrqsuT/P0kL+vuHoYPJjl7w25WmAEAAAAAYOG28k3ydPdrk7z2mOFPZP1+owDACFTVRUn+tyTf1t1f3PDSLUl+oapen+SZSc5N8oEFlAgAAAAAAF+2pZAcABiXqnp7ktUkz6iq+7N+sdxrkjw5yW1VlSR3dPcPdvc9VXVTknuzvgz7Fd39yGIqBwAAAACAdUJyAGDTuvulxxl+3FurdPfVSa7evooAAAAAAODEnPQ9yQEAAAAAAABgpxGSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAcNKq6uyqek9V3VtV91TVDw/jr6uqg1V15/C4eMMxr6mq/VX1sar6rsVVD8AYnbLoAgC24pyrbj3pY688/3Au38Lxx3Pgmu+e6fsBbKet/Dd0O/hvKADb6e6DD898/r8V/r8HwC5zOMmV3f3hqvrqJB+qqtuG197Q3T+7ceeqOi/JpUm+Mckzk/xWVX19dz8y16oBSLJ85wmvv+i0bf8dvkkOAAAAAACctO5+oLs/PGx/IclHk5w54ZBLkryju7/U3Z9Msj/JhdtfKQCs801yAAAAAABgJqrqnCTPSfL+JM9P8kNV9YokH8z6t80fynqAfseGw+7P44TqVbU3yd4kWVlZydra2pZrPHTo0EzeZ7fSn+n0aDL9mW7ZenTl+YcXXcJR5tEfITkAAAAAALBlVfVVSX4pyY909+er6s1JfjJJDz+vTfL9J/Ke3b0vyb4k2bNnT6+urm65zrW1tczifXYr/ZlOjybTn+mWrUfLdGuqZH259e3uj+XWAQAAAACALamqJ2U9IL+xu385Sbr7M939SHf/dZK35NEl1Q8mOXvD4WcNYwAwF0JyAAAAAADgpFVVJbkuyUe7+/Ubxs/YsNv3JvnIsH1Lkkur6slV9awk5yb5wLzqBQDLrQMAAAAAAFvx/CQvT3J3Vd05jP1YkpdW1QVZX279QJIfSJLuvqeqbkpyb5LDSa7o7kfmXDMAIyYkBwAAAAAATlp3vy9JHeeld0845uokV29bUQAwgeXWAQAAAAAAABgNITkAAAAAAAAAoyEkBwAAAAAAAGA0hOQAAAAAAAAAjIaQHAAAAAAAAIDREJIDAAAAAAAAMBpCcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBoCMkBAAAAAAAAGA0hOQAAAAAAAACjccqiCwAA2A53H3w4l19166LLOMqBa7570SUAAAAAAIyeb5IDAAAAAAAAMBpCcgAAAAAAAABGY1ctt25ZVQAAAJifqnprkr+f5MHu/qZh7GeS/IMkf5nkD5O8srs/N7z2miSvSvJIkn/R3b+xiLoBAAAYN98kBwAAAE7W9UkuOmbstiTf1N3/XZL/kuQ1SVJV5yW5NMk3Dsf8fFU9cX6lAgAAwLqTDsmr6u9U1Z0bHp+vqh+pqqdV1W1V9fHh51NnWTAAAACwHLr7vUk+e8zYb3b34eHpHUnOGrYvSfKO7v5Sd38yyf4kF86tWAAAABic9HLr3f2xJBckyXDl98Ekv5LkqiS3d/c1VXXV8PzVWy8VAAAA2GG+P8k7h+0zsx6aH3H/MHaUqtqbZG+SrKysZG1tbSaFrJyaXHn+4ek7zslmPtehQ4dm9vnnRc3zsxPrVvP87MS6d2LNAMDONat7kr8wyR9296eq6pIkq8P4DUnWIiQHAACAUamqH09yOMmNJ3Jcd+9Lsi9J9uzZ06urqzOp50033pxr757VaZCtO/Cy1an7rK2tZVaff17UPD87sW41z89OrHsn1gwA7Fyz+tvhpUnePmyvdPcDw/ank6wc74DtuDJ82a4KTzZ3Zfh2cOXl0fTjUbutF1v5d347/puxU3u72/5cAACwWFV1eZK/n+SF3d3D8MEkZ2/Y7axhDAAAAOZqyyF5VX1Fku9J8ppjX+vurqp+7FHbc2X4sl0VnmzuyvDt4MrLo+nHo3ZbLy6/6taTPvbK8w/P/L8Zi/p3fqt2258LAAAWp6ouSvK/Jfm27v7ihpduSfILVfX6JM9Mcm6SDyygRAAAAEZuFunQi5J8uLs/Mzz/TFWd0d0PVNUZSR6cwe8AAAAAlkxVvT3rt1x7RlXdn+S1Wb+I/slJbquqJLmju3+wu++pqpuS3Jv1Zdiv6O5HFlM5AAAAYzaLkPyleXSp9WT9yvDLklwz/Lx5Br8DAAAAWDLd/dLjDF83Yf+rk1y9fRUBAADAdE/YysFVdVqS70zyyxuGr0nynVX18STfMTwHAAAAAAAAgIXb0jfJu/vPkzz9mLE/S/LCrbwvAAAAAAAAAGyHLX2THAAAAAAAAAB2EiE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAAMBonLLoAgCAnaWq3prk7yd5sLu/aRh7WpJ3JjknyYEkL+nuh6qqkvzfSS5O8sUkl3f3hxdRN8vvnKtunfvvvPL8w7n8cX7vgWu+e87VAAAAAADz4JvkAMCJuj7JRceMXZXk9u4+N8ntw/MkeVGSc4fH3iRvnlONAAAAAABwXEJyAOCEdPd7k3z2mOFLktwwbN+Q5MUbxt/W6+5IcnpVnTGXQgEAAAAA4Dgstw4AzMJKdz8wbH86ycqwfWaS+zbsd/8w9sCGsVTV3qx/0zwrKytZW1vbekGnri+lvUxm8bm24tChQ0fVsGz9WYRJf04W/c9rEY79M4KeHI+eAAAAADudkBwAmKnu7qrqEzxmX5J9SbJnz55eXV3dch1vuvHmXHv3ck11DrxsdaG/f21tLRt7+3j34h6TK88//Lh/Thb9z2sRjv0zgp4cj54AAAAAO53l1gGAWfjMkWXUh58PDuMHk5y9Yb+zhjEAAAAAAFgIITkAMAu3JLls2L4syc0bxl9R656X5OENy7IDAAAAAMDcLdcapADA0quqtydZTfKMqro/yWuTXJPkpqp6VZJPJXnJsPu7k1ycZH+SLyZ55dwLBgAAAACADYTkAMAJ6e6XPs5LLzzOvp3kiu2tCAAAAAAANs9y6wAAAAAAAACMhpAcAAAAAAAAgNEQkgMAAAAAAAAwGkJyAAAAAAAAAEZDSA4AAAAAAADAaAjJAQAAAAAAABiNUxZdAMBucs5Vty66hKMcuOa7F10CAAAAAADAUvFNcgAAAAAAAABGQ0gOAAAAAAAAwGgIyQEAAAAAAAAYDSE5AAAAAAAAAKMhJAcAAAAAAABgNITkAAAAAAAAAIyGkBwAAAAAAACA0RCSAwAAAAAAADAaQnIAAAAAAAAARkNIDgAAAAAAbElVnV1V76mqe6vqnqr64WH8aVV1W1V9fPj51GG8quqNVbW/qu6qqucu9hMAMCZCcgAAAAAAYKsOJ7myu89L8rwkV1TVeUmuSnJ7d5+b5PbheZK8KMm5w2NvkjfPv2QAxkpIDgAAAAAAbEl3P9D/f/b+Psqyu7wPfL+PJQGywBYvTl1ZUtKaINuR3cNLahH5kptbQSaWwWPJM4SIRUCylWlPAg7EPQkNuTO2YzMjz1gQTDw4bcuWcGSDLGCkhYjHRFYtD5kgjEBGINmhDcJI0Qs24qXsBNz4uX+c3ajU6q6q7jpV51Ttz2ets87ev/1ynvPU2ad+5zxn/3b3R4bpLye5J8nZSS5Jct2w2nVJLh2mL0ny9p74YJIzq+qs7Y0agLE6ddYBAAAAAAAAu0dV7UnynCS3J1no7geGRQ8mWRimz07y2VWb3Te0PbCqLVW1L5MzzbOwsJDl5eVNx7eysjKV/exW8rM+OVqb/Kxv3nK0f+/hWYfwGNuRH0VyAAAAAABgKqrqyUneleS13f2lqvr6su7uquoT2V93H0xyMEkWFxd7aWlp0zEuLy9nGvvZreRnfXK0NvlZ37zl6IoDt8w6hMe49uIztjw/hlsHAAAAAAA2rapOy6RAfn13v3tofujIMOrD/cND+/1Jzl21+TlDGwBsuU0VyavqzKq6sap+v6ruqarvrqqnVdX7q+qTw/1TpxUsAAAAAAAwf2pyyvg1Se7p7jetWnRzksuH6cuT3LSq/ZU1cWGSL64alh0AttRmzyR/S5Lf7O7vSPKsJPckOZDk1u4+P8mtwzwAAAAAALB7PT/JK5K8oKruHG4vSnJVkhdW1SeTfM8wnyTvS/KpJIeS/GKSfzSDmAEYqZO+JnlVfXOSv5XkiiTp7q8m+WpVXZJkaVjtuiTLSV63mSABAAAAAID51d0fSFLHWXzRMdbvJK/a0qAA4DhOukie5Lwkn0vyK1X1rCR3JHlNkoVVQ6I8mGThWBtX1b4k+5JkYWEhy8vLmwhlYuH0ZP/ew5vezzRN43mdjJWVlZk99jySj0fttlxs5pifx/eMadvo33q3vS4AAAAAAACOZzNF8lOTPDfJj3b37VX1lhw1tHp3d1X1sTbu7oNJDibJ4uJiLy0tbSKUibdef1OuvmszT2n67n350kwed3l5OdPI6W4hH4/abbm44sAtJ73t/r2H5+49Y9o2+h60214XAAAAAAAAx7OZa5Lfl+S+7r59mL8xk6L5Q1V1VpIM9w9vLkQAAAAAAAAAmI6TLpJ394NJPltV3z40XZTk7iQ3J7l8aLs8yU2bihAAAACYS1X1y1X1cFV9fFXb06rq/VX1yeH+qUN7VdXPVdWhqvpYVT13dpEDAAAwZps5kzxJfjTJ9VX1sSTPTvK/JLkqyQur6pNJvmeYBwAAAHafa5NcfFTbgSS3dvf5SW7No5dm+74k5w+3fUnetk0xAgAAwGNs6mK83X1nksVjLLpoM/sFAAAA5l93/05V7Tmq+ZIkS8P0dUmWk7xuaH97d3eSD1bVmVV1Vnc/sE3hAgAAQJJNFskBAAAAjrKwqvD9YJKFYfrsJJ9dtd59Q9tjiuRVtS+TM82zsLCQ5eXl6QR1erJ/7+Gp7GsaNvK8VlZWpvb8t4uYt89OjFvM22cnxr0TYwYAdi5FcgAAAGBLdHdXVZ/gNgeTHEySxcXFXlpamkosb73+plx91/x8DXLvy5fWXWd5eTnTev7bRczbZyfGLebtsxPj3okxAwA712avSQ4AAACw2kNVdVaSDPcPD+33Jzl31XrnDG0AAACwrRTJAQAAgGm6Ocnlw/TlSW5a1f7KmrgwyRddjxwAAIBZmJ9xxgAAAIAdpap+PclSkmdU1X1JfjzJVUluqKork3wmyUuH1d+X5EVJDiX5syQ/tO0BAwAAQBTJAQAAgJPU3S87zqKLjrFuJ3nV1kYEAAAA6zPcOgAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjMapsw4A2Fn2HLhl1iEAAAAAAADASXMmOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgBMRVX9k6r6RFV9vKp+vaqeVFXnVdXtVXWoqt5ZVU+YdZwAAAAAAIybIjkAsGlVdXaSf5xksbu/K8kpSS5L8jNJ3tzdz0zySJIrZxclAAAAAAAokgMA03NqktOr6tQk35jkgSQvSHLjsPy6JJfOJjQAAAAAAJg4ddYBAAA7X3ffX1U/m+SPkvznJL+V5I4kX+juw8Nq9yU5+1jbV9W+JPuSZGFhIcvLy5uOaeH0ZP/ew+uvuI2m8bw2Y2Vl5TExzFt+ZmGt18ms/16zcPRrBDk5FjkBAAAAdjpFcphjew7cMvV97t97OFdswX6Bcauqpya5JMl5Sb6Q5DeSXLzR7bv7YJKDSbK4uNhLS0ubjumt19+Uq++ar67OvS9fmunjLy8vZ3Vu/T+Y/F883utk1n+vWTj6NYKcHIucAAAAADud4dYBgGn4niSf7u7PdfefJ3l3kucnOXMYfj1Jzkly/6wCBAAAAACARJEcAJiOP0pyYVV9Y1VVkouS3J3ktiQvGda5PMlNM4oPAAAAAACSKJIDAFPQ3bcnuTHJR5LclUkf42CS1yX5sao6lOTpSa6ZWZAAAAAAABDXJAcApqS7fzzJjx/V/Kkkz5tBOAAAAAAAcEzOJAcAAAAAAABgNBTJAQAAAAAAABgNRXIAAAAAAAAARkORHAAAAAAAAIDRUCQHAAAAAAAAYDQUyQEAAAAAAAAYjVM3s3FV3Zvky0m+luRwdy9W1dOSvDPJniT3Jnlpdz+yuTABAAAAAAAAYPOmcSb53+7uZ3f34jB/IMmt3X1+kluHeQAAAAAAAACYua0Ybv2SJNcN09cluXQLHgMAAAAAAAAATtimhltP0kl+q6o6yb/u7oNJFrr7gWH5g0kWjrVhVe1Lsi9JFhYWsry8vMlQkoXTk/17D296P9M0jed1MlZWVmb22PNop+ZjK17P83iczMoYcrHR1/1OPUYAAAAAAABO1GaL5H+zu++vqr+U5P1V9furF3Z3DwX0xxkK6geTZHFxsZeWljYZSvLW62/K1Xdt9ilN170vX5rJ4y4vL2caOd0tdmo+rjhwy9T3uX/v4bk7TmZlDLnY6HvQTj1GAAAAAAAATtSmhlvv7vuH+4eTvCfJ85I8VFVnJclw//BmgwQAAAAAAACAaTjpInlVnVFVTzkyneTvJPl4kpuTXD6sdnmSmzYbJAAAAAAAAABMw2bGGV5I8p6qOrKfX+vu36yq301yQ1VdmeQzSV66+TABAAAAAAAAYPNOukje3Z9K8qxjtP9Jkos2ExQA07Fng9e137/3cK7Y4Lqbde9VL96WxwEAAAAAADiWTV2THAAAAAAAAAB2EkVyAAAAAAAAAEZDkRwAAAAAAACA0VAkBwAAAAAAAGA0FMkBAAAAAAAAGA1FcgAAAGDqquqfVNUnqurjVfXrVfWkqjqvqm6vqkNV9c6qesKs4wQAAGB8FMkBAACAqaqqs5P84ySL3f1dSU5JclmSn0ny5u5+ZpJHklw5uygBAAAYK0VyAAAAYCucmuT0qjo1yTcmeSDJC5LcOCy/LsmlswkNAACAMTt11gEAAAAAu0t3319VP5vkj5L85yS/leSOJF/o7sPDavclOfvobatqX5J9SbKwsJDl5eWpxLRwerJ/7+H1V9wmG3leKysrU3v+20XM22cnxi3m7bMT496JMQMAO5ciOQAAADBVVfXUJJckOS/JF5L8RpKLN7Jtdx9McjBJFhcXe2lpaSoxvfX6m3L1XfPzNci9L19ad53l5eVM6/lvFzFvn50Yt5i3z06MeyfGDADsXIZbBwAAAKbte5J8urs/191/nuTdSZ6f5Mxh+PUkOSfJ/bMKEACYrqr65ap6uKo+vqrtJ6rq/qq6c7i9aNWy11fVoar6g6r63tlEDcBYKZIDAAAA0/ZHSS6sqm+sqkpyUZK7k9yW5CXDOpcnuWlG8QEA03dtjj1yzJu7+9nD7X1JUlUXJLksyXcO2/wfVXXKtkUKwOgpkgMAAABT1d23J7kxyUeS3JXJ9w8Hk7wuyY9V1aEkT09yzcyCBACmqrt/J8nnN7j6JUne0d1f6e5PJzmU5HlbFhwAHGV+LsYFAAAA7Brd/eNJfvyo5k/FF+AAMDavrqpXJvlwkv3d/UiSs5N8cNU69w1tj1NV+5LsS5KFhYUsLy9vOqCVlZWp7Ge3kp/1ydHa5Gd985aj/XsPzzqEx9iO/CiSAwAAAAAAW+FtSX4qSQ/3Vyf54RPZQXcfzGREmiwuLvbS0tKmg1peXs409rNbyc/65Ght8rO+ecvRFQdumXUIj3HtxWdseX4UyQEAAAAAgKnr7oeOTFfVLyZ57zB7f5JzV616ztC2Le66/4tzVRC696oXzzoEgNFxTXIAAAAAAGDqquqsVbM/mOTjw/TNSS6rqidW1XlJzk/yoe2OD4DxciY5AAAAAACwKVX160mWkjyjqu5L8uNJlqrq2ZkMt35vkh9Jku7+RFXdkOTuJIeTvKq7vzaDsAEYKUVyAAAAAABgU7r7ZcdovmaN9d+Y5I1bFxEAHJ/h1gEAAAAAAAAYDUVyAAAAAAAAAEZDkRwAAAAAAACA0VAkBwAAAAAAAGA0Tp11AAAAAADAzrbnwC3rrrN/7+FcsYH1puHeq168LY8DAMDO5ExyAAAAAAAAAEbDmeQAAAAAsMPcdf8Xt+2sbAAA2G2cSQ4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaGy6SF5Vp1TVR6vqvcP8eVV1e1Udqqp3VtUTNh8mAAAAAAAAAGzeNM4kf02Se1bN/0ySN3f3M5M8kuTKKTwGADDnqurMqrqxqn6/qu6pqu+uqqdV1fur6pPD/VNnHScAAAAAAOO2qSJ5VZ2T5MVJfmmYryQvSHLjsMp1SS7dzGMAADvGW5L8Znd/R5JnZfIjugNJbu3u85PcOswDAAAAAMDMnLrJ7f9lkn+W5CnD/NOTfKG7Dw/z9yU5+1gbVtW+JPuSZGFhIcvLy5sMJVk4Pdm/9/D6K26jaTyvk7GysjKzx55HOzUfW/F6nsfjZFbk4lHbmYudeCyyvqr65iR/K8kVSdLdX03y1aq6JMnSsNp1SZaTvG77IwQAAAAAgImTLpJX1fcnebi776iqpRPdvrsPJjmYJIuLi720dMK7eJy3Xn9Trr5rs3X/6br35Uszedzl5eVMI6e7xU7NxxUHbpn6PvfvPTx3x8msyMWjtjMXs3pfZMudl+RzSX6lqp6V5I5MLsmy0N0PDOs8mGThWBv78dz2OPpHY/OWn1lY63Uy67/XLOzUHxZuJTl5PDkBAAAAdrrNVESen+QHqupFSZ6U5JsyGWb1zKo6dTib/Jwk928+TABgzp2a5LlJfrS7b6+qt+SoodW7u6uqj7WxH89tj6N/NLYVP8baadb6kdCs/16zsFN/WLiV5OTx5AQAAADY6U76muTd/fruPqe79yS5LMlvd/fLk9yW5CXDapcnuWnTUQIA8+6+JPd19+3D/I2ZFM0fqqqzkmS4f3hG8QEAAAAAQJJNFMnX8LokP1ZVhzK5Rvk1W/AYAMAc6e4Hk3y2qr59aLooyd1Jbs7kR3OJH88BAAAAADAHpjIGaXcvJ1kepj+V5HnT2C8AsKP8aJLrq+oJST6V5Icy+UHeDVV1ZZLPJHnpDOMDAAAAAIDpFMkBALr7ziSLx1h00TaHAgAAAAAAx7UVw60DAAAAAAAAwFxSJAcAAAAAAABgNBTJAQAAAAAAABgNRXIAAAAAAAAARkORHAAAAAAAAIDRUCQHAAAAAAAAYDQUyQEAAAAAAAAYDUVyAAAAAAAAAEZDkRwAAAAAAACA0VAkBwAAAAAAAGA0FMkBAAAAAAAAGA1FcgAAAAAAAABGQ5EcAAAAAAAAgNFQJAcAAACmrqrOrKobq+r3q+qeqvruqnpaVb2/qj453D911nECAAAwPorkAAAAwFZ4S5Lf7O7vSPKsJPckOZDk1u4+P8mtwzwAAABsK0VyAAAAYKqq6puT/K0k1yRJd3+1u7+Q5JIk1w2rXZfk0lnEBwAAwLidOusAAAAAgF3nvCSfS/IrVfWsJHckeU2She5+YFjnwSQLR29YVfuS7EuShYWFLC8vTyWghdOT/XsPT2Vf07CR57WysjK1579dxLx95u01vRHbGfO0/qY79fWxE+PeiTEDADuXIjkAAAAwbacmeW6SH+3u26vqLTlqaPXu7qrqozfs7oNJDibJ4uJiLy0tTSWgt15/U66+a36+Brn35UvrrrO8vJxpPf/tIubtM2+v6Y3Yv/fwtsW8kWNsI3bq62Mnxr0TYwYAdi7DrQMAAADTdl+S+7r79mH+xkyK5g9V1VlJMtw/PKP4AAAAGDFFcgAAAGCquvvBJJ+tqm8fmi5KcneSm5NcPrRdnuSmGYQHAADAyO2sMZkAAACAneJHk1xfVU9I8qkkP5TJj/VvqKork3wmyUtnGB8AAAAjpUgOAAAATF1335lk8RiLLtrmUAAAAOAxDLcOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAJtSVb9cVQ9X1cdXtT2tqt5fVZ8c7p86tFdV/VxVHaqqj1XVc2cXOQBjpEgOAAAAAABs1rVJLj6q7UCSW7v7/CS3DvNJ8n1Jzh9u+5K8bZtiBIAkiuQAAAAAAMAmdffvJPn8Uc2XJLlumL4uyaWr2t/eEx9McmZVnbUtgQJAklNPdsOqelKS30nyxGE/N3b3j1fVeUnekeTpSe5I8oru/uo0ggUAAAAAAHaMhe5+YJh+MMnCMH12ks+uWu++oe2BHKWq9mVytnkWFhayvLy8+aBOT/bvPbzp/UzLNJ7TNK2srMxdTPNGjtYmP+ubtxzN03tisj35OekieZKvJHlBd69U1WlJPlBV/zbJjyV5c3e/o6p+IcmVMVQKAAAAAACMVnd3VfVJbHcwycEkWVxc7KWlpU3H8tbrb8rVd22mPDJd9758adYhPMby8nKmkefdTI7WJj/rm7ccXXHgllmH8BjXXnzGlufnpIdbH4ZBWRlmTxtuneQFSW4c2lcPnwIAAAAAAIzHQ0eGUR/uHx7a709y7qr1zhnaAGBbbOqnUlV1SiZDqj8zyc8n+cMkX+juI+fkHxki5Vjb7vohUpLZDZMyb8M0zNpOzcdWvJ7n8TiZFbl41HbmYiceiwAAAACclJuTXJ7kquH+plXtr66qdyT5G0m+uGpYdgDYcpsqknf315I8u6rOTPKeJN9xAtvu+iFSktkNkzJvwzTM2k7Nx1YMb7F/7+G5O05mRS4etZ25mLfhowAAAADYvKr69SRLSZ5RVfcl+fFMiuM3VNWVST6T5KXD6u9L8qIkh5L8WZIf2vaAARi1qVREuvsLVXVbku9OcmZVnTqcTW6IFAAAAAAA2OW6+2XHWXTRMdbtJK/a2ogA4PhO+prkVfUtwxnkqarTk7wwyT1JbkvykmG11cOnAAAAAAAAAMBMbeZM8rOSXDdcl/wbktzQ3e+tqruTvKOqfjrJR5NcM4U4AQAAAAAAAGDTTrpI3t0fS/KcY7R/KsnzNhMUAAAAAAAAAGyFqVyTHAAAAAB2sz0Hbpl1CI+xf++sIwAAgJ3rpK9JDgAAAAAAAAA7jSI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAU1NVp1TVR6vqvcP8eVV1e1Udqqp3VtUTZh0jAAAAAADjpkgOAEzTa5Lcs2r+Z5K8ubufmeSRJFfOJCoAAAAAABgokgMAU1FV5yR5cZJfGuYryQuS3Discl2SS2cSHAAAAAAADE6ddQAAwK7xL5P8syRPGeafnuQL3X14mL8vydnH2rCq9iXZlyQLCwtZXl7edDALpyf79x5ef8VtNI3ntRkrKyuPiWHe8jMLa71OZv33moWjXyPIybHICQAAALDTKZIDAJtWVd+f5OHuvqOqlk50++4+mORgkiwuLvbS0gnv4nHeev1Nufqu+erq3PvypZk+/vLyclbn9ooDt8wumDmxf+/h475OZv33moWjXyPIybHICQAAALDTzdc3xwDATvX8JD9QVS9K8qQk35TkLUnOrKpTh7PJz0ly/wxjBAAAAAAA1yQHADavu1/f3ed0954klyX57e5+eZLbkrxkWO3yJDfNKEQAAAAAAEiiSA4AbK3XJfmxqjqUyTXKr5lxPAAAAAAAjJzh1gGAqeru5STLw/SnkjxvlvEAAAAAAMBqziQHAAAAAAAAYDQUyQEAAAAAAAAYDUVyAAAAAAAAAEZDkRwAAAAAAACA0VAkBwAAAAAAAGA0FMkBAACAqauqU6rqo1X13mH+vKq6vaoOVdU7q+oJs44RAACAcTp11gEAAAAAu9JrktyT5JuG+Z9J8ubufkdV/UKSK5O8bVbBAbvbngO3TGU/+/cezhVT2Ne9V714CtEAADAtziQHAAAApqqqzkny4iS/NMxXkhckuXFY5bokl84kOAAAAEbPmeQAAADAtP3LJP8syVOG+acn+UJ3Hx7m70ty9rE2rKp9SfYlycLCQpaXl6cS0MLpkzNC58VGntfKysrUnv922c0xz9PrJ5m/1/RGjDnm7T4udvOxCAAwDYrkAAAAwNRU1fcnebi776iqpRPdvrsPJjmYJIuLi720dMK7OKa3Xn9Trr5rfr4GufflS+uus7y8nGk9/+2ym2OexpDb07R/7+G5ek1vxJhj3sgxP027+VgEAJiGndUrBQAAAObd85P8QFW9KMmTMrkm+VuSnFlVpw5nk5+T5P4ZxggAAMCIuSY5AAAAMDXd/fruPqe79yS5LMlvd/fLk9yW5CXDapcnuWlGIQIAADByiuQAAADAdnhdkh+rqkOZXKP8mhnHAwAAwEgZbh0AAADYEt29nGR5mP5UkufNMh4AAABInEkOAAAAAAAAwIgokgMAAAAAAAAwGoZbBwCAY9hz4JZZh/A491714lmHAAAAAAA7njPJAQAAAAAAABgNRXIAAAAAAAAARkORHAAAAAAAAIDRcE1yWGUerz0KAAAAAAAATI8zyQEAAAAAAAAYjZMuklfVuVV1W1XdXVWfqKrXDO1Pq6r3V9Unh/unTi9cAAAAAAAAADh5mzmT/HCS/d19QZILk7yqqi5IciDJrd19fpJbh3kAAAAAAAAAmLmTLpJ39wPd/ZFh+stJ7klydpJLklw3rHZdkks3GSMAAAAAAAAATMWp09hJVe1J8pwktydZ6O4HhkUPJlk4zjb7kuxLkoWFhSwvL286joXTk/17D296P9M0jed1MlZWVmb22PNoo/mYt9fPVpjH42RW5OJR25kL700AAAAAAMAsbbpIXlVPTvKuJK/t7i9V1deXdXdXVR9ru+4+mORgkiwuLvbS0tJmQ8lbr78pV981lbr/1Nz78qWZPO7y8nKmkdPdYqP5uOLALVsfzIzt33t47o6TWZGLR21nLmb1vggAAAAAAJBs7prkqarTMimQX9/d7x6aH6qqs4blZyV5eHMhAgAAAAAAAMB0nHSRvCanjF+T5J7uftOqRTcnuXyYvjzJTScfHgAAAAAAAABMz2bG1n1+klckuauq7hza3pDkqiQ3VNWVST6T5KWbihAAAAAAAAAApuSki+Td/YEkdZzFF53sfgEAAAAAAABgq2zqmuQAAAAAAAAAsJMokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo3HqrAMAABiLPQdumenj7997OFfMOAYAAAAAgFlzJjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjceqsAwAAAAAAAHavqro3yZeTfC3J4e5erKqnJXlnkj1J7k3y0u5+ZFYxAjAuziQHAAAAAAC22t/u7md39+IwfyDJrd19fpJbh3kA2BaK5AAAAAAAwHa7JMl1w/R1SS6dXSgAjI3h1gEAAAAAgK3USX6rqjrJv+7ug0kWuvuBYfmDSRaOtWFV7UuyL0kWFhayvLy86WAWTk/27z286f1MyzSe0zStrKzMXUzzRo7WJj/rm7cczdN7YrI9+VEkBwAAAAAAttLf7O77q+ovJXl/Vf3+6oXd3UMB/XGGgvrBJFlcXOylpaVNB/PW62/K1XfNT3nk3pcvzTqEx1heXs408rybydHa5Gd985ajKw7cMusQHuPai8/Y8vwYbh0AAAAAANgy3X3/cP9wkvckeV6Sh6rqrCQZ7h+eXYQAjI0iOQAAAAAAsCWq6oyqesqR6SR/J8nHk9yc5PJhtcuT3DSbCAEYo/kZTwQAAAAAANhtFpK8p6qSSU3i17r7N6vqd5PcUFVXJvlMkpfOMEYARkaRHAAAAAAA2BLd/akkzzpG+58kuWj7IwIAw60DAFNQVedW1W1VdXdVfaKqXjO0P62q3l9VnxzunzrrWAEAAAAAGDdFcgBgGg4n2d/dFyS5MMmrquqCJAeS3Nrd5ye5dZgHAAAAAICZUSQHADatux/o7o8M019Ock+Ss5NckuS6YbXrklw6kwABAAAAAGDgmuQAwFRV1Z4kz0lye5KF7n5gWPRgkoXjbLMvyb4kWVhYyPLy8qbjWDg92b/38Kb3s5vIyePttJxM49hYy8rKypY/xk4jJ48nJwAAAMBOp0gOAExNVT05ybuSvLa7v1RVX1/W3V1VfaztuvtgkoNJsri42EtLS5uO5a3X35Sr79LVWW3/3sNycpSdlpN7X760pftfXl7ONI6/3UROHk9OAAAAgJ3OcOsAwFRU1WmZFMiv7+53D80PVdVZw/Kzkjw8q/gAAAAAACBRJAcApqAmp4xfk+Se7n7TqkU3J7l8mL48yU3bHRsAAAAAAKy2c8aWBADm2fOTvCLJXVV159D2hiRXJbmhqq5M8pkkL51NeAAAAAAAMKFIDgBsWnd/IEkdZ/FF2xkLADB7VXVukrcnWUjSSQ5291uq6mlJ3plkT5J7k7y0ux+ZVZwAAACMk+HWAQAAgGk7nGR/d1+Q5MIkr6qqC5IcSHJrd5+f5NZhHgAAALaVIjkAAAAwVd39QHd/ZJj+cpJ7kpyd5JIk1w2rXZfk0pkECAAAwKgZbh0AAADYMlW1J8lzktyeZKG7HxgWPZjJcOxHr78vyb4kWVhYyPLy8lTiWDg92b/38FT2NQ0beV4rKytTe/7bZTfHPE+vn2T+XtMbMeaYt/u42M3HIgDANCiSAwAAAFuiqp6c5F1JXtvdX6qqry/r7q6qPnqb7j6Y5GCSLC4u9tLS0lRieev1N+Xqu+bna5B7X7607jrLy8uZ1vPfLrs55isO3LL1wZyA/XsPz9VreiPGHPNGjvlp2s3HIgDANBhuHQAAAJi6qjotkwL59d397qH5oao6a1h+VpKHZxUfAAAA46VIDgAAAExVTU4ZvybJPd39plWLbk5y+TB9eZKbtjs2AAAA2FnjGwEAAAA7wfOTvCLJXVV159D2hiRXJbmhqq5M8pkkL51NeAAAAIzZporkVfXLSb4/ycPd/V1D29OSvDPJniT3Jnlpdz+yuTABAACAnaK7P5CkjrP4ou2MBQAAAI622eHWr01y8VFtB5Lc2t3nJ7l1mAcAAAAAAACAmdtUkby7fyfJ549qviTJdcP0dUku3cxjAAAAAAAAAMC0bMU1yRe6+4Fh+sEkC8daqar2JdmXJAsLC1leXt78A5+e7N97eNP7maZpPK+TsbKyMrPHnkcbzce8vX62wjweJ7MiF4/azlx4bwIAAAAAAGZpK4rkX9fdXVV9nGUHkxxMksXFxV5aWtr04731+pty9V1b+pRO2L0vX5rJ4y4vL2caOd0tNpqPKw7csvXBzNj+vYfn7jiZFbl41HbmYlbviwAAAAAAAMnmr0l+LA9V1VlJMtw/vAWPAQAAAAAAAAAnbCuK5DcnuXyYvjzJTVvwGAAAAAAAAABwwjZVJK+qX0/yH5J8e1XdV1VXJrkqyQur6pNJvmeYBwAAAAAAAICZ29QFaLv7ZcdZdNFm9gsAAAAAAAAAW2FTRXIAAAAAmLY9B27Ztsfav/dwrtjGxwMAAGZvK65JDgAAAAAAAABzSZEcAAAAAAAAgNFQJAcAAAAAAABgNBTJAQAAAAAAABgNRXIAAAAAAAAARkORHAAAAAAAAIDRUCQHAAAAAAAAYDQUyQEAAAAAAAAYDUVyAAAAAAAAAEZDkRwAAAAAAACA0VAkBwAAAAAAAGA0FMkBAAAAAAAAGI1TZx0A47bnwC3b8jj79x7OFdv0WAAAAAAAAMD8UiQHAIAdYqt/YHiiPyy896oXb2E0AAC7x3adKHLERvp1+nIAwJgZbh0AAAAAAACA0VAkBwAAAAAAAGA0FMkBAAAAAAAAGA1FcgAAAAAAAABGQ5EcAAAAAAAAgNFQJAcAAAAAAABgNBTJAQAAAAAAABgNRXIAAAAAAAAARkORHAAAAAAAAIDRUCQHAAAAAAAAYDQUyQEAAAAAAAAYDUVyAAAAAAAAAEZDkRwAAAAAAACA0Th11gGwvfYcuGXWIQAAAAAAAADMjDPJAQAAAAAAABgNRXIAAAAAAAAARsNw6wAAAAAjN63Ls+3fezhXuNQbAAAw55xJDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKNx6qwDAAAAdqY9B26ZdQhbbv/ew7niJJ/nvVe9eMrRAAAAADANiuRbbFZfHG7myzwAAAAAAACA3cpw6wAAAAAAAACMxpadSV5VFyd5S5JTkvxSd1+1VY8FAMw3/QJgjHbrcPTTHLXKkPTjpF8AMB/mra9y7cVnzDoEZkC/AIBZ2ZIzyavqlCQ/n+T7klyQ5GVVdcFWPBYAMN/0CwCAI/QLAIAj9AsAmKWtGm79eUkOdfenuvurSd6R5JIteiwAYL7pFwAAR+gXAABH6BcAMDPV3dPfadVLklzc3f9gmH9Fkr/R3a9etc6+JPuG2W9P8gdTeOhnJPnjKexnN5CLx5KPR8nFo+TiUTsxF3+lu79l1kGwPv2CuSInjycnjyUfjycnjzePOdEv2CFm2C9I5vO1ux4xb4+dGHOyM+MW8/bZiXFPK2b9gh1iI/2Cod13BttPftYnR2uTn/XJ0dq2vF+wZdckX093H0xycJr7rKoPd/fiNPe5U8nFY8nHo+TiUXLxKLlg1vQLtoecPJ6cPJZ8PJ6cPJ6csNW2ol+Q7MzXrpi3x06MOdmZcYt5++zEuHdizGwP3xlsP/lZnxytTX7WJ0dr2478bNVw6/cnOXfV/DlDGwAwPvoFAMAR+gUAwBH6BQDMzFYVyX83yflVdV5VPSHJZUlu3qLHAgDmm34BAHCEfgEAcIR+AQAzsyXDrXf34ap6dZL/K8kpSX65uz+xFY91lKkPx7aDycVjycej5OJRcvEouWDL6BfMFTl5PDl5LPl4PDl5PDnhpM2wX5DszNeumLfHTow52Zlxi3n77MS4d2LMbIJ+wVyTn/XJ0drkZ31ytLYtz09191Y/BgAAAAAAAADMha0abh0AAAAAAAAA5o4iOQAAAAAAAACjsWuK5FV1cVX9QVUdqqoDs45nO1XVL1fVw1X18VVtT6uq91fVJ4f7p84yxu1SVedW1W1VdXdVfaKqXjO0jy4fVfWkqvpQVf3ekIufHNrPq6rbh2PlnVX1hFnHul2q6pSq+mhVvXeYH2Uuqureqrqrqu6sqg8PbaM7RtjdxtQvOJFjuiZ+bsjLx6rquav2c/mw/ier6vJZPZ+TcSJ9oZPJQVX99SHHh4Zta3uf4Yk7Tk5+oqruH14rd1bVi1Yte/3w/P6gqr53Vfsxj6Wd9j/0RPuIY3idrJGT0b5O2L12Yr/gWO/j8+547yvzrI7zuXknqKM+3+4EdYx+67yrqjOr6saq+v2quqeqvnvWMa2lqr591f/wO6vqS1X12lnHtZ6q+ifDMfjxqvr1qnrSrGNid1ivD1BVTxz6qYeGfuueGYQ5UxvI0Y8N/9s/VlW3VtVfmUWcs7LRfmRV/XdV1VW1uJ3xzYON5KiqXrqqj/hr2x3jLG3gGPvLQx/6o8Nx9qJj7We3Wu9zz+TrmWN/PzMV3b3jb0lOSfKHSf6rJE9I8ntJLph1XNv4/P9Wkucm+fiqtv8tyYFh+kCSn5l1nNuUi7OSPHeYfkqS/5jkgjHmI0klefIwfVqS25NcmOSGJJcN7b+Q5B/OOtZtzMmPJfm1JO8d5keZiyT3JnnGUW2jO0bcdu9tbP2CEzmmk7woyb8d/kdcmOT2of1pST413D91mH7qrJ/bCeRgw32hk8lBkg8N69aw7ffN+jmfZE5+Isn/eIx1LxiOkycmOW84fk5Z61jaaf9Dc4J9xDG8TtbIyWhfJ26787bWa3Seb8d6H5/32/HeV2Yd1zoxH/Nz86zj2mDsj/l8uxNuOUa/dd5vSa5L8g+G6SckOXPWMZ1A7KckeTDJX5l1LOvEeXaSTyc5fZi/IckVs47LbeffNtIHSPKPkvzCMH1ZknfOOu45zNHfTvKNw/Q/HFOONtqPHPo9v5Pkg0kWZx33vOUoyflJPppHPzv/pVnHPWf5OXjks3Imn7vvnXXc25yjNT/35Djfz0zrtlvOJH9ekkPd/anu/mqSdyS5ZMYxbZvu/p0knz+q+ZJMOvIZ7i/dzphmpbsf6O6PDNNfTnJPJp3t0eWjJ1aG2dOGWyd5QZIbh/ZR5CJJquqcJC9O8kvDfGWkuTiO0R0j7Gqj7hcMjndMX5Lk7cP/iA8mObOqzkryvUne392f7+5Hkrw/ycXbHPNJO8G+0AnlYFj2Td39wZ70zt+eHfAeeZycHM8lSd7R3V/p7k8nOZTJcXTMY2kn/g89iT7irn+drJGT49n1rxN2rR3ZLzjB9/G5cBLvKzO3xufmuXb051u2RlV9cyZf3F6TJN391e7+wkyDOjEXJfnD7v7MrAPZgFOTnF5Vpyb5xiT/acbxsDtspA+w+vPAjUkuGvqxY7Fujrr7tu7+s2H2g0nO2eYYZ2mj/cifSvIzSf7LdgY3JzaSo/8+yc8Pn6HT3Q9vc4yztJH8dJJvGqa/OSP7H7iBzz3H+35mKnZLkfzsJJ9dNX9f5vyD2DZY6O4HhukHkyzMMphZGIbHeU4mvwQfZT6G4dfuTPJwJl/i/mGSL3T34WGVMR0r/zLJP0vyF8P80zPeXHSS36qqO6pq39A2ymOEXWts/YITOaaPl5vdmLNp5eDsYfro9p3q1cPwVL9cj15a40RzsqP/h26wjziq18lROUm8TthdduP/uLl3jPeVuXX05+bunvuY8/jPtzvFsfqt8+y8JJ9L8ivDEKi/VFVnzDqoE3BZkl+fdRDr6e77k/xskj9K8kCSL3b3b802KnaJjfQBvr7O0G/9Yib92LE40X7SlZmc0TkW6+ZnGPr53O6+ZTsDmyMbeQ19W5Jvq6p/X1UfrKodc1LGFGwkPz+R5O9X1X1J3pfkR7cntB1jSz/P7ZYiOWsYzmaZ+19CT1NVPTnJu5K8tru/tHrZmPLR3V/r7mdn8gu/5yX5jtlGNBtV9f1JHu7uO2Ydy5z4m9393CTfl+RVVfW3Vi8c0zECu4Rjeh1y8HVvS/JXkzw7ky8gr55pNDOgj/h4x8jJ6F8nwOas9V47j47+3FxV3zXjkNa0wz/frtlvnUOnZjL859u6+zlJ/jSTy7PMvap6QpIfSPIbs45lPcMP8i7J5EcJ35rkjKr6+7ONCjjacFwuJvnfZx3LvKiqb0jypiT7Zx3LnDs1kyHXl5K8LMkvVtWZswxozrwsybXdfU4mQ4v/6vDaYhvslkTfn+TcVfPnDG1j9tCRIQeG+9EMYVFVp2Xygfz67n730DzafCTJMBzYbUm+O5PhKE4dFo3lWHl+kh+oqnszGdLkBUneknHm4sivtI8MbfOeTH5AMepjhF1nVP2CEzymj5eb3ZizaeXg/jx2OLkdm5vufmgoBPxFkl/M5LWSnHhO/iQ78H/oCfYRR/E6OVZOxv46YVfajf/j5tZx3mt3hFWfm+f97KbHfb6tqn8z25A25jj91nl2X5L7Vo0ucGMmRfOd4PuSfKS7H5p1IBvwPUk+3d2f6+4/T/LuJP/vGcfE7rCRPsDX1xn6rd+cST92LDbUT6qq70nyz5P8QHd/ZZtimwfr5ecpSb4ryfLwf/nCJDdX1eK2RTh7G3kN3Zfk5u7+8+HSXf8xk6L5GGwkP1cmuSFJuvs/JHlSkmdsS3Q7w5Z+ntstRfLfTXJ+VZ03/FLysiQ3zzimWbs5yeXD9OVJbpphLNtmuGbMNUnu6e43rVo0unxU1bcc+UVWVZ2e5IWZXBPutiQvGVYbRS66+/XdfU5378nk/eG3u/vlGWEuquqMqnrKkekkfyfJxzPCY4RdbTT9gpM4pm9O8sqauDCToQwfSPJ/Jfk7VfXU4UyOvzO07WRTycGw7EtVdeHQz3hlduh75FHXbPrBTF4rySQnl1XVE6vqvEw+rH4oxzmWhjOud9T/0JPoI+7618nxcjLm1wm71mj6BbO2xnvt3DrO5+bfn2lQ6zjO59u5P+t2jX7r3OruB5N8tqq+fWi6KMndMwzpRLwsO2Co9cEfJbmwqr5xeB+5KJPvr2CzNtIHWP154CWZvKeOaXSpdXNUVc9J8q8zKZCP7aSaNfPT3V/s7md0957h//IHM8nTh2cT7kxs5Dj7PzM5izxV9YxMhl//1DbGOEsbyc8fZfK/L1X11zIpkn9uW6Ocb8f7fmYqTl1/lfnX3Yer6tWZfGl1SpJf7u5PzDisbVNVv57Jm8wzanLdgh9PclWSG6rqyiSfSfLS2UW4rZ6f5BVJ7qrJNcWS5A0ZZz7OSnJdVZ2SyQ9ibuju91bV3UneUVU/neSjmXyJMVavy/hysZDkPZPPnTk1ya91929W1e9mfMcIu9TI+gUneky/L5Ohmw4l+bMkP5Qk3f35qvqpTDrvSfIvuvvz2/c0NucE+0Ink4N/lOTaJKdncv21ub8G23FyslRVz85kSPF7k/xIknT3J6rqhky+9D2c5FXd/bVhP8c7lnba/9AT7SOO4XVyvJy8bMSvE3ahndovONb7eHfP+zF0zPeV7n7f7EJa1zE/N884pt3qmP3W2Ya0IT+a5Prhi+1PZegTzLPhRwgvzPA/fN519+1VdWOSj2TSx/hokoOzjYrd4Hh9gKr6F0k+3N03Z9I//dWqOpTk85kUsEZjgzn635M8OclvDO/hf9TdPzCzoLfRBvMzahvM0ZEfm9+d5GtJ/ml3j2LEhg3mZ38mQ9D/k0w+h18xph/rHOf7q9OSpLt/Icf5fmZqjz+iXAMAAAAAAAAwcrtluHUAAAAAAAAAWJciOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOcyRqrq2qn561nEAADuPfgQAAAAAbIwiOQAAAACMQFUtV9U/mHUcAAAwa4rkAAAAAAAAAIyGIjnMUFU9p6o+UlVfrqp3JnnS0L5UVfdV1T+rqoer6oGqurSqXlRV/7GqPl9Vb5hx+ADAlFTVuVX17qr6XFX9SVX9q6r6q1X128P8H1fV9VV15qptjtmPAAB2hqo6UFV/OPwvv7uqfnBov6Kq/v3QH/hiVf1+VV20arvlqvpfq+pDVfWlqrqpqp62avmFVfX/VNUXqur3qmppaH9jkv9Pkn9VVStV9a+29xkDAJtVVfdW1euHvsMjVfUrVXWkrvD9VXXn0Af4f6rqv551vDDPFMlhRqrqCUn+zyS/muRpSX4jyX+3apX/VyZfdp+d5H9O8otJ/n6Sv57Jh9r/qarO28aQAYAtUFWnJHlvks8k2ZPJ//53JKkk/2uSb03y15Kcm+Qnhm3W60cAAPPvDzP5fP/NSX4yyb+pqrOGZX9jWP6MJD+e5N2rC+FJXpnkh5OcleRwkp9Lkqo6O8ktSX46kz7C/5jkXVX1Ld39z5P830le3d1P7u5Xb/HzAwC2xsuTfG+Sv5rk25L8/6rqOUl+OcmPJHl6kn+d5OaqeuLMooQ5p0gOs3NhktOS/Mvu/vPuvjHJ765a/udJ3tjdf57JF+XPSPKW7v5yd38iyd1JnrXdQQMAU/e8TArh/7S7/7S7/0t3f6C7D3X3+7v7K939uSRvSvL/HbZZrx8BAMy57v6N7v5P3f0X3f3OJJ/MpF+QJA/n0f/z70zyB0levGrzX+3uj3f3nyb5n5K8dPjh3d9P8r7uft+w3/cn+XCSF23bEwMAttq/6u7Pdvfnk7wxycuS7Evyr7v79u7+Wndfl+QrmXx/AByDIjnMzrcmub+7e1XbZ1ZN/0l3f22Y/s/D/UOrlv/nJE/ewvgAgO1xbpLPdPfh1Y1VtVBV76iq+6vqS0n+TSY/mkvW70cAAHOuql65akjULyT5rjz6v/5Y/+e/ddX8Z49adtqw7V9J8neP7HPY79/M5IxzAGB3OLof8K2Z9AH2H9UHODeP7T8AqyiSw+w8kOTsqqpVbX95VsEAADPz2SR/uapOPar9f0nSSfZ29zdlcmbYkX6DfgQA7GBV9Vcyuazaq5M8vbvPTPLxPPq//lj/5//Tqvlzj1r250n+OJN+xa9295mrbmd091XDuqsL7wDAznR0P+A/ZdIHeONRfYBv7O5fn02IMP8UyWF2/kMm1w37x1V1WlX9t3l0WDUAYDw+lEnR+6qqOqOqnlRVz0/ylCQrSb44XF/0n67aRj8CAHa2MzIpWH8uSarqhzI5k/yIv5RH/8//3SR/Lcn7Vi3/+1V1QVV9Y5J/keTGYTS6f5Pkv6mq762qU4Z+xVJVnTNs91CS/2prnxoAsMVeVVXnVNXTkvzzJO/M5Md3/0NV/Y2aOKOqXlxVT5ltqDC/FMlhRrr7q0n+2yRXJPl8kr+X5N2zjAkA2H7DF9r/TZJnJvmjJPdl0i/4ySTPTfLFJLdkVT9BPwIAdrbuvjvJ1Zn88O2hJHuT/PtVq9ye5PxMzg5/Y5KXdPefrFr+q0muTfJgkicl+cfDfj+b5JIkb8ikAP/ZTH5od+Q7wLckeUlVPVJVP7cVzw0A2HK/luS3knwqyR8m+enu/nCS/z7Jv0rySJJDmXxnABxHPfbyRgAAAADArFTVFUn+QXf/zeMsX07yb7r7l7YzLgBg9qrq3kz6Cf9u1rHATudMcgAAAAAAAABGQ5EcAAAAAAAAgNEw3DoAAAAAAAAAo+FMcgAAAAAAAABG49RZB5Akz3jGM3rPnj2b3s+f/umf5owzzth8QLuYHK1NftYnR2uTn/VNK0d33HHHH3f3t0whJOaMfsH2kaO1yc/65Ght8rM+/QLWM61+QeKYXI/8rE+O1iY/a5Of9ekXsBG+M9ge8rM+OVqb/KxPjta2Hf2CuSiS79mzJx/+8Ic3vZ/l5eUsLS1tPqBdTI7WJj/rk6O1yc/6ppWjqvrM5qNhHukXbB85Wpv8rE+O1iY/69MvYD3T6hckjsn1yM/65Ght8rM2+VmffgEb4TuD7SE/65OjtcnP+uRobdvRLzDcOgAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIzGqbMOAICts+fALbMO4XGuvfiMWYcAAKM1b30D/QIAmB39AgDgiDH2C5xJDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjsW6RvKrOrarbquruqvpEVb1maP+Jqrq/qu4cbi9atc3rq+pQVf1BVX3vVj4BAGD7VNWTqupDVfV7Q7/gJ4f2a6vq06v6Bc8e2quqfm7oF3ysqp470ycAAAAAAMDonbqBdQ4n2d/dH6mqpyS5o6rePyx7c3f/7OqVq+qCJJcl+c4k35rk31XVt3X316YZOAAwE19J8oLuXqmq05J8oKr+7bDsn3b3jUet/31Jzh9ufyPJ24Z7AAAAAACYiXXPJO/uB7r7I8P0l5Pck+TsNTa5JMk7uvsr3f3pJIeSPG8awQIAs9UTK8PsacOt19jkkiRvH7b7YJIzq+qsrY4TAAAAAACOZyNnkn9dVe1J8pwktyd5fpJXV9Urk3w4k7PNH8mkgP7BVZvdl2MU1atqX5J9SbKwsJDl5eWTCP+xVlZWprKf3UyO1iY/65Ojtc1bfvbvPTzrEB5n3nLEiauqU5LckeSZSX6+u2+vqn+Y5I1V9T8nuTXJge7+SiZ9gM+u2vxIv+CBo/apXzADcrQ2+VmfHK1tHvMzb32DecwRAAAAsPttuEheVU9O8q4kr+3uL1XV25L8VCZnj/1UkquT/PBG99fdB5McTJLFxcVeWlo6gbCPbXl5OdPYz24mR2uTn/XJ0drmLT9XHLhl1iE8zrUXnzFXOeLEDZdQeXZVnZnkPVX1XUlen+TBJE/I5P/765L8ixPYp37BDMjR2uRnfXK0tnnMz7z1DfQLAAAAgFlYd7j1JBmuOfquJNd397uTpLsf6u6vdfdfJPnFPDqk+v1Jzl21+TlDGwCwi3T3F5LcluTi4fIsPZw9/ivRLwAAAAAAYE6tWySvqkpyTZJ7uvtNq9pXX0/0B5N8fJi+OcllVfXEqjovyflJPjS9kAGAWamqbxnOIE9VnZ7khUl+/0i/YOg3XJrH9gteWRMXJvlidz/wuB0DAAAAAMA22chw689P8ookd1XVnUPbG5K8rKqenclw6/cm+ZEk6e5PVNUNSe5OcjjJq4ZhWQGAne+sJNcN1yX/hiQ3dPd7q+q3q+pbklSSO5P8D8P670vyoiSHkvxZkh/a/pABAAAAAOBR6xbJu/sDmXzhfbT3rbHNG5O8cRNxAQBzqLs/luQ5x2h/wXHW7ySv2uq4AIDtV1VPSvI7SZ6YyfcLN3b3jw+jyr0jydOT3JHkFd391ap6YpK3J/nrSf4kyd/r7ntnEjwAAACjtqFrkgMAAAAc5StJXtDdz0ry7CQXD5dX+Zkkb+7uZyZ5JMmVw/pXJnlkaH/zsB4AAABsO0VyAAAA4IT1xMowe9pw6yQvSHLj0H5dkkuH6UuG+QzLL6qqY41cBwAAAFtqI9ckBwAAAHicqjolkyHVn5nk55P8YZIvdPfhYZX7kpw9TJ+d5LNJ0t2Hq+qLmQzJ/sdH7XNfkn1JsrCwkOXl5anEurKyMrV97Ubysz45Wpv8rG0e87N/7+H1V9pG85gjAGD3UiQHAAAATkp3fy3Js6vqzCTvSfIdU9jnwSQHk2RxcbGXlpY2u8skyfLycqa1r91IftYnR2uTn7XNY36uOHDLrEN4jGsvPmPucgQA7F6GWwcAAAA2pbu/kOS2JN+d5MyqOvKj/HOS3D9M35/k3CQZln9zkj/Z3kgBAABAkRwAAAA4CVX1LcMZ5Kmq05O8MMk9mRTLXzKsdnmSm4bpm4f5DMt/u7t72wIGAACAgSI5AAAAcDLOSnJbVX0sye8meX93vzfJ65L8WFUdyuSa49cM61+T5OlD+48lOTCDmAGALVJVT6qqD1XV71XVJ6rqJ4f286rq9qo6VFXvrKonDO1PHOYPDcv3zPQJADAqrkkOAAAAnLDu/liS5xyj/VNJnneM9v+S5O9uQ2gAwGx8JckLunulqk5L8oGq+reZ/Djuzd39jqr6hSRXJnnbcP9Idz+zqi5L8jNJ/t6sggdgXJxJDgAAAAAAbEpPrAyzpw23TvKCJDcO7dcluXSYvmSYz7D8oqqq7YkWgLFzJjkAAAAAALBpVXVKkjuSPDPJzyf5wyRf6O7Dwyr3JTl7mD47yWeTpLsPV9UXM7lUyx8ftc99SfYlycLCQpaXlzcd58rKylT2s1vJz/rkaG3ys755y9H+vYfXX2kbbUd+FMkBAAAAAIBN6+6vJXl2VZ2Z5D1JvmMK+zyY5GCSLC4u9tLS0mZ3meXl5UxjP7uV/KxPjtYmP+ubtxxdceCWWYfwGNdefMaW58dw6wAAAAAAwNR09xeS3Jbku5OcWVVHTtg7J8n9w/T9Sc5NkmH5Nyf5k+2NFICxUiQHAAAAAAA2paq+ZTiDPFV1epIXJrknk2L5S4bVLk9y0zB98zCfYflvd3dvW8AAjJrh1gEAAAAAgM06K8l1w3XJvyHJDd393qq6O8k7quqnk3w0yTXD+tck+dWqOpTk80kum0XQAIyTIjkAAAAAALAp3f2xJM85RvunkjzvGO3/Jcnf3YbQAOBxDLcOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgBsWFU9qao+VFW/V1WfqKqfHNrPq6rbq+pQVb2zqp4wtD9xmD80LN8z0ycAAAAAAMDoKZIDACfiK0le0N3PSvLsJBdX1YVJfibJm7v7mUkeSXLlsP6VSR4Z2t88rAcAAAAAADOjSA4AbFhPrAyzpw23TvKCJDcO7dcluXSYvmSYz7D8oqqq7YkWAAAAAAAe79RZBwAA7CxVdUqSO5I8M8nPJ/nDJF/o7sPDKvclOXuYPjvJZ5Okuw9X1ReTPD3JHx+1z31J9iXJwsJClpeXNx3nysrKVPazm8nR2uRnfXK0tnnMz/69h9dfaRvNY44AAACA3U+RHAA4Id39tSTPrqozk7wnyXdMYZ8HkxxMksXFxV5aWtrsLrO8vJxp7Gc3k6O1yc/65Ght85ifKw7cMusQHuPai8+YuxwBAAAAu5/h1gGAk9LdX0hyW5LvTnJmVR358d05Se4fpu9Pcm6SDMu/OcmfbG+kAAAAAADwKEVyAGDDqupbhjPIU1WnJ3lhknsyKZa/ZFjt8iQ3DdM3D/MZlv92d/e2BQwAAAAAAEcx3DoAcCLOSnLdcF3yb0hyQ3e/t6ruTvKOqvrpJB9Ncs2w/jVJfrWqDiX5fJLLZhE0AAAAAAAcoUgOAGxYd38syXOO0f6pJM87Rvt/SfJ3tyE0AAAAAADYEMOtAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAwAmrqnOr6raquruqPlFVrxnaf6Kq7q+qO4fbi1Zt8/qqOlRVf1BV3zu76AEAABizU2cdAAAAALAjHU6yv7s/UlVPSXJHVb1/WPbm7v7Z1StX1QVJLkvynUm+Ncm/q6pv6+6vbWvUAAAAjJ4zyQEAAIAT1t0PdPdHhukvJ7knydlrbHJJknd091e6+9NJDiV53tZHCgAAAI/lTHIAAABgU6pqT5LnJLk9yfOTvLqqXpnkw5mcbf5IJgX0D67a7L4co6heVfuS7EuShYWFLC8vTyXGlZWVqe1rN5Kf9cnR2uRnbfOYn/17D886hMeYxxwBALuXIjkAAABw0qrqyUneleS13f2lqnpbkp9K0sP91Ul+eKP76+6DSQ4myeLiYi8tLU0lzuXl5UxrX7uR/KxPjtYmP2ubx/xcceCWWYfwGNdefMbc5QgA2L3WHW69qs6tqtuq6u6q+kRVvWZof1pVvb+qPjncP3Vor6r6uao6VFUfq6rnbvWTAAAAALZfVZ2WSYH8+u5+d5J090Pd/bXu/oskv5hHh1S/P8m5qzY/Z2gDAACAbbWRa5IfzmRotAuSXJjkVVV1QZIDSW7t7vOT3DrMJ8n3JTl/uO1L8rapRw0AAADMVFVVkmuS3NPdb1rVftaq1X4wyceH6ZuTXFZVT6yq8zL53uBD2xUvALB11jjZ7ieq6v6qunO4vWjVNq8fTrb7g6r63tlFD8AYrTvcenc/kOSBYfrLVXVPJtcMuyTJ0rDadUmWk7xuaH97d3eSD1bVmVV11rAfAAAAYHd4fpJXJLmrqu4c2t6Q5GVV9exMhlu/N8mPJEl3f6KqbkhydyY/yH9Vd39tm2MGALbGkZPtPlJVT0lyR1W9f1j25u7+2dUrDyfiXZbkO5N8a5J/V1Xfpm8AwHY5oWuSV9WeJM9JcnuShVWF7weTLAzTZyf57KrN7hvaHlMkr6p9mZxpnoWFhSwvL59g6I+3srIylf3sZnK0NvlZnxytbd7ys3/v4VmH8DjzliMAAE5Od38gSR1j0fvW2OaNSd64ZUEBADOxxsl2x3NJknd091eSfLqqDmVyiZb/sOXBAkBOoEheVU/O5Dpjr+3uL01GVZvo7q6qPpEH7u6DSQ4myeLiYi8tLZ3I5se0vLycaexnN5OjtcnP+uRobfOWnysO3DLrEB7n2ovPmKscAQAAADA9R51s9/wkr66qVyb5cCZnmz+SSQH9g6s2O3Ky3bH254S7bSY/65OjtcnP+uYtR/N2wt125GdDRfKqOi2TAvn13f3uofmhI8OoD9cbe3hovz/Juas2P2doAwAAAAAAdqljnGz3tiQ/lcllWH4qydVJfvhE9umEu+0nP+uTo7XJz/rmLUfzdsLddpxs9w3rrVCTU8avSXJPd79p1aKbk1w+TF+e5KZV7a+siQuTfNH1yAEAAAAAYPc61sl23f1Qd3+tu/8iyS9mMqR64mQ7AGZs3SJ5JsOhvCLJC6rqzuH2oiRXJXlhVX0yyfcM88nk2mOfSnIok396/2j6YQMAAAAAAPPgeCfbDaPQHvGDST4+TN+c5LKqemJVnZfk/CQf2q54AWDd4da7+wNJ6jiLLzrG+p3kVZuMCwAAAAAA2BmOnGx3V1XdObS9IcnLqurZmQy3fm+SH0mS7v5EVd2Q5O4kh5O8qru/ts0xAzBiG7omOQAAAAAAwLGscbLd+9bY5o1J3rhlQQHAGjYy3DoAAAAAAAAA7AqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo6FIDgAAAAAAAMBoKJIDAAAAAAAAMBqK5AAAAAAAAACMhiI5AAAAAAAAAKOhSA4AAAAAAADAaCiSAwAAAAAAADAaiuQAAAAAAAAAjIYiOQAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAsGFVdW5V3VZVd1fVJ6rqNUP7T1TV/VV153B70aptXl9Vh6rqD6rqe2cXPQAAAAAAJKfOOgAAYEc5nGR/d3+kqp6S5I6qev+w7M3d/bOrV66qC5JcluQ7k3xrkn9XVd/W3V/b1qgBAAAAAGDgTHIAYMO6+4Hu/sgw/eUk9yQ5e41NLknyju7+Snd/OsmhJM/b+kgBAAAAAODYnEkOAJyUqtqT5DlJbk/y/CSvrqpXJvlwJmebP5JJAf2Dqza7L8coqlfVviT7kmRhYSHLy8ubjm9lZWUq+9nN5Ght8rM+OVrbPOZn/97Dsw7hMeYxRwAAAMDup0gOAJywqnpykncleW13f6mq3pbkp5L0cH91kh/e6P66+2CSg0myuLjYS0tLm45xeXk509jPbiZHa5Of9cnR2uYxP1ccuGXWITzGtRefMXc5AgAAAHY/w60DACekqk7LpEB+fXe/O0m6+6Hu/lp3/0WSX8yjQ6rfn+TcVZufM7QBAAAAAMBMKJIDABtWVZXkmiT3dPebVrWftWq1H0zy8WH65iSXVdUTq+q8JOcn+dB2xQsAAAAAAEcz3DoAcCKen+QVSe6qqjuHtjckeVlVPTuT4dbvTfIjSdLdn6iqG5LcneRwkld199e2OWYAAAAAAPg6RXIAYMO6+wNJ6hiL3rfGNm9M8sYtCwoAAAAAAE6A4dYBAAAAAAAAGA1FcgAAAAAAAABGQ5EcAAAAAAAAgNFQJAcAAAAAAABgNBTJAQAAAAAAABgNRXIAAAAAAAAARkORHAAAAAAAAIDRUCQHAAAAAAAAYDQUyQEAAAAAAAAYDUVyAAAAAAAAAEZDkRwAAAAAAACA0VAkBwAAAAAAAGA0FMkBAAAAAAAAGA1FcgAAAOCEVdW5VXVbVd1dVZ+oqtcM7U+rqvdX1SeH+6cO7VVVP1dVh6rqY1X13Nk+AwAAAMZKkRwAAAA4GYeT7O/uC5JcmORVVXVBkgNJbu3u85PcOswnyfclOX+47Uvytu0PGQAAABTJAQAAgJPQ3Q9090eG6S8nuSfJ2UkuSXLdsNp1SS4dpi9J8vae+GCSM6vqrO2NGgAAAJJTZx0AAAAAsLNV1Z4kz0lye5KF7n5gWPRgkoVh+uwkn1212X1D2wOr2lJV+zI50zwLCwtZXl6eSowrKytT29duJD/rk6O1yc/a5jE/+/cennUIjzGPOQIAdi9FcgAAAOCkVdWTk7wryWu7+0tV9fVl3d1V1Seyv+4+mORgkiwuLvbS0tJU4lxeXs609rUbyc/65Ght8rO2eczPFQdumXUIj3HtxWfMXY44MVV1bpK3Z/IDuU5ysLvfUlVPS/LOJHuS3Jvkpd39SE06DW9J8qIkf5bkiiOj1ADAVjPcOgAAAHBSquq0TArk13f3u4fmh44Moz7cPzy035/k3FWbnzO0AQC7w+Ek+7v7giQXJnlVVV2Q5ECSW7v7/CS3DvNJ8n1Jzh9u+5K8bftDBmCsFMkBAACAEzac/XVNknu6+02rFt2c5PJh+vIkN61qf2VNXJjki6uGZQcAdrjufuDImeDd/eUk92RyaZVLklw3rHZdkkuH6UuSvL0nPpjkzCM/tAOArWa4dQAAAOBkPD/JK5LcVVV3Dm1vSHJVkhuq6sokn0ny0mHZ+zIZTvVQJkOq/tC2RgsAbJuq2pPkOUluT7Kw6odxD2YyHHsyKaB/dtVm9w1tj/kRXVXty+RM8ywsLEzl2vUrKytT2c9uJT/rk6O1yc/65i1H+/cennUIj7Ed+VEkBwAAAE5Yd38gSR1n8UXHWL+TvGpLgwIAZq6qnpzJ5Vhe291fmgw+M9HdXVV9Ivvr7oNJDibJ4uJiT+Pa9cvLy5nGfnYr+VmfHK1NftY3bzm64sAtsw7hMa69+Iwtz4/h1gEAAAAAgE2rqtMyKZBf393vHpofOjKM+nD/8NB+f5JzV21+ztAGAFtOkRwAAAAAANiUmpwyfk2Se7r7TasW3Zzk8mH68iQ3rWp/ZU1cmOSLq4ZlB4AtZbh1AAAAAABgs56f5BVJ7qqqO4e2NyS5KskNVXVlks8keemw7H1JXpTkUJI/S/JD2xotAKOmSA4AAAAAAGxKd38gSR1n8UXHWL+TvGpLgwKA4zDcOgAAAAAAAACjoUgOAAAAAAAAwGgokgMAAAAAAAAwGorkAAAAAAAAAIyGIjkAAAAAAAAAo7FukbyqfrmqHq6qj69q+4mqur+q7hxuL1q17PVVdaiq/qCqvnerAgcAAAAAAACAE7WRM8mvTXLxMdrf3N3PHm7vS5KquiDJZUm+c9jm/6iqU6YVLAAAAAAAAABsxrpF8u7+nfz/27v/YFvvuj70748Jok0ogUb3pElquNc4txGuiHsQR+/tjmn1EDsGp72ZMFoSzO3x9kKv1kyHo+0MtpaZ2BaZi1XqYeCe0CohtaVkDP6gkT0MHSMERZKglCMEyWlIVGL0SItN/Nw/9hPZSQ5r7XP22nuts7+v18ya9Tzf51nP/uzPnHPyhfd6vk/y2R1e75okt3b357v7k0mOJ3nxLuoDAAAAAAAAgIU5dxeffXVVvSLJ3Ulu6u5Hklyc5K5t5zwwjT1NVR1OcjhJ1tbWsrm5uYtStpw8eXIh1znI9Gg2/ZlPj2Zbtf7c9ILHll3C06xajwAAAAAAgLGcaUj+piQ/mqSn99cn+d7TuUB3H01yNEnW19d7Y2PjDEv5gs3NzSziOgeZHs2mP/Pp0Wyr1p8bjtyx7BKe5tih81aqRwAAAAAAwFh28kzyp+nuh7r78e7+syRvzheWVD+R5NJtp14yjQEAAAAAAADA0p1RSF5VF23b/a4k907btye5rqqeWVXPS3J5kg/srkQAAAAAAAAAWIy5y61X1duTbCS5sKoeSPLaJBtV9cJsLbd+f5LvS5Luvq+qbkvy0SSPJXlVdz++J5UDAAAAAAAAwGmaG5J398tPMfyWGee/LsnrdlMUAAAAAAAAAOyFM1puHQAAAAAAAADORkJyAAAAAAAAAIYhJAcAdqyqLq2q91bVR6vqvqr6/mn8uVX1nqr6+PT+nGm8quqNVXW8qj5SVS9a7m8AAAAAAMDohOQAwOl4LMlN3X1FkpckeVVVXZHkSJI7u/vyJHdO+0ny0iSXT6/DSd60/yUDAAAAAMAXCMkBgB3r7ge7+9en7T9O8ltJLk5yTZJbptNuSfKyafuaJG/rLXcluaCqLtrfqgEAAAAA4AvOXXYBi3TPiUdzw5E7ll3Gk9x/83csuwQA2BNVdVmSr0/ya0nWuvvB6dBnkqxN2xcn+fS2jz0wjT24bSxVdThbd5pnbW0tm5ubu67v5MmTC7nOQaZHs+nPfHo02yr256YXPLbsEp5kFXsEAAAAHHwHKiQHAPZHVZ2f5N8n+YHu/qOq+vNj3d1V1adzve4+muRokqyvr/fGxsaua9zc3MwirnOQ6dFs+jOfHs22iv1ZtS8VHzt03sr1CAAAADj4LLcOAJyWqnpGtgLyn+nu/zANP/TEMurT+8PT+Ikkl277+CXTGAAAAAAALIWQHADYsdq6ZfwtSX6ru39826Hbk1w/bV+f5F3bxl9RW16S5NFty7IDAAAAAMC+s9w6AHA6vjnJ30lyT1V9eBr74SQ3J7mtqm5M8qkk107H3p3k6iTHk3wuySv3tVoAAAAAAHgKITkAsGPd/f4k9UUOX3WK8zvJq/a0KAAAAAAAOA2WWwcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAADOSFW9taoerqp7t439SFWdqKoPT6+rtx37oao6XlUfq6pvX07VAAAAjE5IDgAAAJypY0kOnWL8Dd39wun17iSpqiuSXJfka6fP/FRVnbNvlQIAAMBESA4AAACcke5+X5LP7vD0a5Lc2t2f7+5PJjme5MV7VhwAAAB8EecuuwAAAADgwHl1Vb0iyd1JburuR5JcnOSubec8MI09SVUdTnI4SdbW1rK5ubmQgk6ePLmwax1E+jOfHs2mP7OtYn9uesFjyy7hSVaxR5yeqnprkr+Z5OHufv409iNJ/m6S35tO++Ftq8z8UJIbkzye5P/p7l/a96IBGJaQHAAAAFikNyX50SQ9vb8+yffu9MPdfTTJ0SRZX1/vjY2NhRS1ubmZRV3rINKf+fRoNv2ZbRX7c8ORO5ZdwpMcO3TeyvWI03Ysyb9K8ranjL+hu//l9oGnPIblLyf5T1X1Nd39+H4UCgCWWwcAAAAWprsf6u7Hu/vPkrw5X1hS/USSS7edesk0BgAcAB7DAsDZxJ3kAAAAwMJU1UXd/eC0+11J7p22b0/ys1X149m6Y+zyJB9YQokAwP4648ewJHvzKBbL+8+mP/Pp0Wz6M9+q9WjEx7AIyQEAAIAzUlVvT7KR5MKqeiDJa5NsVNULs7Xc+v1Jvi9Juvu+qrotyUeTPJbkVZZUBYADb1ePYUn25lEsq/gIhFWiP/Pp0Wz6M9+q9WjEx7AIyQEAAIAz0t0vP8XwW2ac/7okr9u7igCAVdLdDz2xXVVvTvLz067HsACwVJ5JDgAAAAAALFxVXbRt96mPYbmuqp5ZVc+Lx7AAsM/cSQ4AAAAAAOyKx7AAcDYRkgMAAAAAALviMSwAnE0stw4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4A7FhVvbWqHq6qe7eN/UhVnaiqD0+vq7cd+6GqOl5VH6uqb19O1QAAAAAA8AVCcgDgdBxLcugU42/o7hdOr3cnSVVdkeS6JF87feanquqcfasUAAAAAABOQUgOAOxYd78vyWd3ePo1SW7t7s939yeTHE/y4j0rDgAAAAAAduDcZRcAABwIr66qVyS5O8lN3f1IkouT3LXtnAemsaepqsNJDifJ2tpaNjc3d13QyZMnF3Kdg0yPZtOf+fRotlXsz00veGzZJTzJKvYIAAAAOPiE5ADAbr0pyY8m6en99Um+93Qu0N1HkxxNkvX19d7Y2Nh1UZubm1nEdQ4yPZpNf+bTo9lWsT83HLlj2SU8ybFD561cjwAAAICDz3LrAMCudPdD3f14d/9ZkjfnC0uqn0hy6bZTL5nGAAAAAABgaYTkAMCuVNVF23a/K8m90/btSa6rqmdW1fOSXJ7kA/tdHwAAAAAAbGe5dQBgx6rq7Uk2klxYVQ8keW2Sjap6YbaWW78/yfclSXffV1W3JflokseSvKq7H19C2QAAAAAA8OeE5ADAjnX3y08x/JYZ578uyev2riIAAAAAADg9llsHAAAAAAAAYBhzQ/KqemtVPVxV924be25VvaeqPj69P2car6p6Y1Udr6qPVNWL9rJ4AAAAAAAAADgdO7mT/FiSQ08ZO5Lkzu6+PMmd036SvDTJ5dPrcJI3LaZMAAAAAAAAANi9uSF5d78vyWefMnxNklum7VuSvGzb+Nt6y11JLqiqixZUKwAAAAAAAADsyrln+Lm17n5w2v5MkrVp++Ikn9523gPT2IN5iqo6nK27zbO2tpbNzc0zLGVbUV+e3PSCx3Z9nUVaxO+1SCdPnly5mlaJ/synR7OtWn9W7d/EZPV6BAAAAAAAjOVMQ/I/191dVX0Gnzua5GiSrK+v98bGxm5LyU/8zLvy+nt2/Sst1P3fvbHsEp5kc3Mzi+j1QaU/8+nRbKvWnxuO3LHsEp7m2KHzVqpHAAAAAADAWHbyTPJTeeiJZdSn94en8RNJLt123iXTGAAAAAAAAAAs3ZmG5LcnuX7avj7Ju7aNv6K2vCTJo9uWZQcAAAAAAACApZq7NnlVvT3JRpILq+qBJK9NcnOS26rqxiSfSnLtdPq7k1yd5HiSzyV55R7UDAAAAAAAAABnZG5I3t0v/yKHrjrFuZ3kVbstCgAAAAAAAAD2wpkutw4AAAAAAAAAZx0hOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAAAAAADDEJIDAAAAAAAAMAwhOQAAAHBGquqtVfVwVd27bey5VfWeqvr49P6cabyq6o1VdbyqPlJVL1pe5QAAAIxMSA4AAACcqWNJDj1l7EiSO7v78iR3TvtJ8tIkl0+vw0netE81AgAAwJMIyQEAAIAz0t3vS/LZpwxfk+SWafuWJC/bNv623nJXkguq6qJ9KRQAAAC2OXfZBQAAAAAHylp3PzhtfybJ2rR9cZJPbzvvgWnswW1jqarD2brTPGtra9nc3FxIUSdPnlzYtQ4i/ZlPj2bTn9lWsT83veCxZZfwJKvYI05PVb01yd9M8nB3P38ae26SdyS5LMn9Sa7t7keqqpL8v0muTvK5JDd0968vo24AxiQkBwAAAPZEd3dV9Wl+5miSo0myvr7eGxsbC6llc3Mzi7rWQaQ/8+nRbPoz2yr254Yjdyy7hCc5dui8lesRp+1Ykn+V5G3bxp54DMvNVXVk2n9NnvwYlm/M1mNYvnFfqwVgaJZbBwAAABbpoSeWUZ/eH57GTyS5dNt5l0xjAMAB4DEsAJxN3EkOAAAALNLtSa5PcvP0/q5t46+uqluzdafYo9uWZQcADqZdPYYl2ZtHsVjefzb9mU+PZtOf+VatRyM+hkVIDgAAAJyRqnp7ko0kF1bVA0lem61w/LaqujHJp5JcO53+7mw9d/R4tp49+sp9LxgAWJozeQzL9LmFP4plFR+BsEr0Zz49mk1/5lu1Ho34GBYhOQAAAHBGuvvlX+TQVac4t5O8am8rAgBWzENVdVF3P+gxLACsEs8kBwAAAAAA9sITj2FJnv4YllfUlpfEY1gA2GfuJAcAAAAAAHbFY1gAOJsIyQEAAAAAgF3xGBYAziaWWwcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAOC0VNVbq+rhqrp329hzq+o9VfXx6f0503hV1Rur6nhVfaSqXrS8ygEAAAAAQEgOAJy+Y0kOPWXsSJI7u/vyJHdO+0ny0iSXT6/DSd60TzUCAAAAAMApCckBgNPS3e9L8tmnDF+T5JZp+5YkL9s2/rbecleSC6rqon0pFAAAAAAATuHcZRcAABwIa9394LT9mSRr0/bFST697bwHprEHt42lqg5n607zrK2tZXNzc9cFnTx5ciHXOcj0aDb9mU+PZlvF/tz0gseWXcKTrGKPAAAAgINPSA4ALFR3d1X1aX7maJKjSbK+vt4bGxu7rmNzczOLuM5Bpkez6c98ejTbKvbnhiN3LLuEJzl26LyV6xEAAABw8FluHQBYhIeeWEZ9en94Gj+R5NJt510yjQEAAAAAwFIIyQGARbg9yfXT9vVJ3rVt/BW15SVJHt22LDsAAAAAAOw7y60DAKelqt6eZCPJhVX1QJLXJrk5yW1VdWOSTyW5djr93UmuTnI8yeeSvHLfCwYAAAAAgG2E5ADAaenul3+RQ1ed4txO8qq9rQgAYL57TjyaG47csewy/tz9N3/HsksAAAAYluXWAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYZy77AIAAAAAAAD2yz0nHs0NR+5Ydhl/7v6bv2PZJQAMx53kAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMM7dzYer6v4kf5zk8SSPdfd6VT03yTuSXJbk/iTXdvcjuysTAAAAAAAAAHZvEXeSX9ndL+zu9Wn/SJI7u/vyJHdO+wAAAAAAAACwdHux3Po1SW6Ztm9J8rI9+BkAAAAAAAAAcNp2tdx6kk7yy1XVSX66u48mWevuB6fjn0mydqoPVtXhJIeTZG1tLZubm7ssJVn78uSmFzy26+ss0iJ+r0U6efLkytW0SvRnPj2abdX6s2r/Jiar1yMAAAAAAGAsuw3Jv6W7T1TVVyZ5T1X99vaD3d1TgP40U6B+NEnW19d7Y2Njl6UkP/Ez78rr79ntr7RY93/3xrJLeJLNzc0sotcHlf7Mp0ezrVp/bjhyx7JLeJpjh85bqR4BAAAAAABj2dVy6919Ynp/OMk7k7w4yUNVdVGSTO8P77ZIAAAAAAAAAFiEMw7Jq+q8qnrWE9tJvi3JvUluT3L9dNr1Sd612yIBAAAAAAAAYBF2szb5WpJ3VtUT1/nZ7v7Fqvpgktuq6sYkn0py7e7LBAAAAAAAAIDdO+OQvLs/keTrTjH+B0mu2k1RAAAAAAAAALAXdvVMcgAAAAAAAAA4mwjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYZy77AIAAACAg6eq7k/yx0keT/JYd69X1XOTvCPJZUnuT3Jtdz+yrBoBAAAYkzvJAQAAgL1yZXe/sLvXp/0jSe7s7suT3DntAwAHXFXdX1X3VNWHq+ruaey5VfWeqvr49P6cZdcJwDiE5AAAAMB+uSbJLdP2LUletrxSAIB95stzAKwMy60DAAAAe6GT/HJVdZKf7u6jSda6+8Hp+GeSrD31Q1V1OMnhJFlbW8vm5uZCiln78uSmFzy2kGstwqJ+r0U5efLkytW0avRoNv2ZbRX7s0r/Jiar2SP23DVJNqbtW5JsJnnNsooBYCxCcgAAAGAvfEt3n6iqr0zynqr67e0Hu7unAD1PGT+a5GiSrK+v98bGxkKK+YmfeVdef8/q/N8g93/3xrJLeJLNzc0sqtcHlR7Npj+zrWJ/bjhyx7JLeJJjh85buR6xUGf05blkb75A58tzs/nSynx6NJv+zLdqPVqlfxOT/enP6vyvQwAAAODA6O4T0/vDVfXOJC9O8lBVXdTdD1bVRUkeXmqRAMB+OaMvz03HFv4FOl+em20Vv9izavRoNv2Zb9V6NOKX5zyTHAAAAFioqjqvqp71xHaSb0tyb5Lbk1w/nXZ9knctp0IAYD9t//Jckid9eS5JfHkOgP0mJAcAFqaq7q+qe6rqw1V19zT23Kp6T1V9fHp/zrLrBAD23FqS91fVbyb5QJI7uvsXk9yc5G9U1ceT/PVpHwA4wHx5DoBVtDrriQAAB8WV3f372/aPJLmzu2+uqiPT/muWUxoAsB+6+xNJvu4U43+Q5Kr9rwgAWKK1JO+sqmQrk/jZ7v7Fqvpgktuq6sYkn0py7RJrBGAwQnIAYK9dk2Rj2r4lyWaE5AAAADAEX54DYBUJyQGAReokv1xVneSnu/tokrXufnA6/plsfYP8SarqcJLDSbK2tpbNzc1dF3Ly5MmFXOcg06PZ9Gc+PZptFftz0wseW3YJT7KKPQIAAAAOPiE5ALBI39LdJ6rqK5O8p6p+e/vB7u4pQM9Txo8mOZok6+vrvbGxsetCNjc3s4jrHGR6NJv+zKdHs61if244cseyS3iSY4fOW7keAQAAAAfflyy7AADg4OjuE9P7w0nemeTFSR6qqouSZHp/eHkVAgAAAAAwOiE5ALAQVXVeVT3rie0k35bk3iS3J7l+Ou36JO9aToUAAAAAAGC5dQBgcdaSvLOqkq05xs929y9W1QeT3FZVNyb5VJJrl1gjAAAAAACDE5IDAAvR3Z9I8nWnGP+DJFftf0UAAAAAAPB0llsHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGce6yCwAA2Av3nHg0Nxy5Y9llPMn9N3/HsksAAAAAABieO8kBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGMaeheRVdaiqPlZVx6vqyF79HABg9ZkXAABPMC8AAJ5gXgDAsuxJSF5V5yT5ySQvTXJFkpdX1RV78bMAgNVmXgAAPMG8AAB4gnkBAMu0V3eSvzjJ8e7+RHf/aZJbk1yzRz8LAFht5gUAwBPMCwCAJ5gXALA05+7RdS9O8ult+w8k+cbtJ1TV4SSHp92TVfWxBfzcC5P8/gKuszD1Y8uu4GlWrkcrRn/m06PZ9GeOK39sYT36qgVcg/1hXjAxLzjr6M98ejSb/sxhXjCkZc0LkhX7O2lecFbSo9n0Zzb9mcO8YEhz5wXJGP+fgXnBWUmPZtOf+fRohv2YF+xVSD5Xdx9NcnSR16yqu7t7fZHXPGj0aDb9mU+PZtOf+fSIUzEvWA49mk1/5tOj2fRnPj3iVPZiXpD48zaP/synR7Ppz2z6M58e8cX4/wz2n/7Mp0ez6c98ejTbfvRnr5ZbP5Hk0m37l0xjAMB4zAsAgCeYFwAATzAvAGBp9iok/2CSy6vqeVX1pUmuS3L7Hv0sAGC1mRcAAE8wLwAAnmBeAMDS7Mly6939WFW9OskvJTknyVu7+769+FlPsfDl2A4gPZpNf+bTo9n0Zz49Gox5wUrTo9n0Zz49mk1/5tOjwSxxXpD48zaP/synR7Ppz2z6M58eDca8YKXpz3x6NJv+zKdHs+15f6q79/pnAAAAAAAAAMBK2Kvl1gEAAAAAAABg5QjJAQAAAAAAABjGWRmSV9WhqvpYVR2vqiOnOP7MqnrHdPzXquqyJZS5NDvozw9W1Uer6iNVdWdVfdUy6lymeT3adt7fqqquqvX9rG/ZdtKfqrp2+nN0X1X97H7XuGw7+Hv2V6rqvVX1G9PftauXUeeyVNVbq+rhqrr3ixyvqnrj1L+PVNWL9rtGDg7zgvnMDWYzL5jP3GA284LZzAvYT+YF85kXzGZeMJ95wWzmBbOZF7CfzAvmMy+YzbxgPvOC2cwLZlv6vKC7z6pXknOS/E6S/ynJlyb5zSRXPOWc/zvJv562r0vyjmXXvWL9uTLJX5i2/95I/dlpj6bznpXkfUnuSrK+7LpXqT9JLk/yG0meM+1/5bLrXsEeHU3y96btK5Lcv+y697lH/3uSFyW594scvzrJLySpJC9J8mvLrtnr7HyZFyysR8PODcwLFvZnaNi5gXnBjnpkXuC1Ly/zgoX1yLzAvGC3f4bMC8wLZvXIvMBrX17mBQvrkXmBecFu/wyZF5gXzOrRUucFZ+Od5C9Ocry7P9Hdf5rk1iTXPOWca5LcMm3/XJKrqqr2scZlmtuf7n5vd39u2r0rySX7XOOy7eTPUJL8aJIfS/Lf97O4FbCT/vzdJD/Z3Y8kSXc/vM81LttOetRJ/uK0/ewk/3Uf61u67n5fks/OOOWaJG/rLXcluaCqLtqf6jhgzAvmMzeYzbxgPnOD2cwL5jAvYB+ZF8xnXjCbecF85gWzmRfMYV7APjIvmM+8YDbzgvnMC2YzL5hj2fOCszEkvzjJp7ftPzCNnfKc7n4syaNJ/tK+VLd8O+nPdjdm61sYI5nbo2nJhku7+479LGxF7OTP0Nck+Zqq+s9VdVdVHdq36lbDTnr0I0m+p6oeSPLuJH9/f0o7a5zuv1XwxZgXzGduMJt5wXzmBrOZF+yeeQGLYl4wn3nBbOYF85kXzGZesHvmBSyKecF85gWzmRfMZ14wm3nB7u3pvODcRV2Is09VfU+S9SR/bdm1rJKq+pIkP57khiWXssrOzdYyKRvZ+vbg+6rqBd39h8ssasW8PMmx7n59VX1Tkn9TVc/v7j9bdmEAX4y5wdOZF+yYucFs5gXAWce84OnMC3bMvGA28wLgrGNe8HTmBTtmXjCbecESnY13kp9Icum2/UumsVOeU1XnZmuJgj/Yl+qWbyf9SVX99ST/KMl3dvfn96m2VTGvR89K8vwkm1V1f7aec3B7Va3vW4XLtZM/Qw8kub27/0d3fzLJf8nWf+hGsZMe3ZjktiTp7l9N8mVJLtyX6s4OO/q3CnbAvGA+c4PZzAvmMzeYzbxg98wLWBTzgvnMC2YzL5jPvGA284LdMy9gUcwL5jMvmM28YD7zgtnMC3ZvT+cFZ2NI/sEkl1fV86rqS5Ncl+T2p5xze5Lrp+2/neRXuree8D6Auf2pqq9P8tPZ+o/aSM9/eMLMHnX3o919YXdf1t2XZetZK9/Z3Xcvp9x9t5O/Y/8xW9/8SlVdmK0lUz6xjzUu20569LtJrkqSqvqr2fqP2+/ta5Wr7fYkr6gtL0nyaHc/uOyiOCuZF8xnbjCbecF85gazmRfsnnkBi2JeMJ95wWzmBfOZF8xmXrB75gUsinnBfOYFs5kXzGdeMJt5we7t6bzgrFtuvbsfq6pXJ/mlJOckeWt331dV/zTJ3d19e5K3ZGtJguPZeuD7dcureH/tsD//Isn5Sf5dVSXJ73b3dy6t6H22wx4Na4f9+aUk31ZVH03yeJJ/2N3DfMtyhz26Kcmbq+ofJOkkN4w0ya6qt2dr8nNhbT1P5bVJnpEk3f2vs/V8lauTHE/yuSSvXE6lnO3MC+YzN5jNvGA+c4PZzAvmMy9gv5gXzGdeMJt5wXzmBbOZF8xnXsB+MS+Yz7xgNvOC+cwLZjMvmG/Z84IaqNcAAAAAAAAADO5sXG4dAAAAAAAAAM6IkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJYUmq6khV/U5V/XFVfbSqvmsav6Gq3l9V/7KqHqmqT1bVS7d97tlV9ZaqerCqTlTVP6uqc5b3mwAAAAAAAMDZQ0gOy/M7Sf63JM9O8k+S/Nuqumg69o1JPpbkwiT/PMlbqqqmY8eSPJbkq5N8fZJvS/J/7l/ZAAAAAAAAcPaq7l52DUCSqvpwktcmeU6Sf9zdXz2N/4Ukf5LkoiSd5HeTXNDd/206/vIkh7v7ymXUDQAAAAAAAGeTc5ddAIyqql6R5AeTXDYNnZ+tO8cfT/KZJ87r7s9NN5Gfn+S5SZ6R5MEv3FieL0ny6X0pGgAAAAAAAM5yQnJYgqr6qiRvTnJVkl/t7senO8lr5ge3wvDPJ7mwux/b2yoBAAAAAADg4PFMcliO87K1dPrvJUlVvTLJ8+d9qLsfTPLLSV5fVX+xqr6kqv7nqvpre1otAAAAAAAAHBBCcliC7v5oktcn+dUkDyV5QZL/vMOPvyLJlyb5aJJHkvxctp5XDgAAAAAAAMxR3b3sGgAAAAAAAABgX7iTHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGMa5yy4gSS688MK+7LLLdn2dP/mTP8l55523+4IOMD2aTX/m06PZ9Ge+RfXoQx/60O9391csoCQAAAAAAGAgKxGSX3bZZbn77rt3fZ3Nzc1sbGzsvqADTI9m05/59Gg2/ZlvUT2qqk/tvhoAAAAAAGA0llsHAAAAAAAAYBhzQ/Kq+rKq+kBV/WZV3VdV/2QaP1ZVn6yqD0+vF07jVVVvrKrjVfWRqnrRHv8OAAAAAAAAALAjO1lu/fNJvrW7T1bVM5K8v6p+YTr2D7v7555y/kuTXD69vjHJm6Z3AAAAAAAAAFiquXeS95aT0+4zplfP+Mg1Sd42fe6uJBdU1UW7LxUAAAAAAAAAdqe6Z+Xd00lV5yT5UJKvTvKT3f2aqjqW5Juydaf5nUmOdPfnq+rnk9zc3e+fPntnktd0991PuebhJIeTZG1t7RtuvfXWXf8yJ0+ezPnnn7/r6xxkejSb/synR7Ppz3yL6tGVV175oe5eX0BJAAAAAADAQHay3Hq6+/EkL6yqC5K8s6qen+SHknwmyZcmOZrkNUn+6U5/cHcfnT6X9fX13tjYOK3CT2VzczOLuM5Bpkez6c98ejSb/synRwAAAAAAwDLNXW59u+7+wyTvTXKoux+cllT/fJL/L8mLp9NOJLl028cumcYAAAAAAAAAYKnmhuRV9RXTHeSpqi9P8jeS/PYTzxmvqkrysiT3Th+5PckrastLkjza3Q/uQe0AAAAAAAAAcFp2stz6RUlumZ5L/iVJbuvun6+qX6mqr0hSST6c5P+azn93kquTHE/yuSSvXHjVAAAAAAAAAHAG5obk3f2RJF9/ivFv/SLnd5JX7b40AAAAAAAAAFis03omOQAAAAAAAACczYTkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAzj3GUXAMDeuezIHcsu4WmOHTpv2SUAAAAAAAADcyc5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMOYG5JX1ZdV1Qeq6jer6r6q+ifT+POq6teq6nhVvaOqvnQaf+a0f3w6ftke/w4AAAAAAAAAsCM7uZP880m+tbu/LskLkxyqqpck+bEkb+jur07ySJIbp/NvTPLINP6G6TwAAAAAAAAAWLq5IXlvOTntPmN6dZJvTfJz0/gtSV42bV8z7Wc6flVV1aIKBgAAAAAAAIAzVd09/6Sqc5J8KMlXJ/nJJP8iyV3T3eKpqkuT/EJ3P7+q7k1yqLsfmI79TpJv7O7ff8o1Dyc5nCRra2vfcOutt+76lzl58mTOP//8XV/nINOj2fRnPj2abdX6c8+JR5ddwtM879nnLKRHV1555Ye6e30BJQEAAAAAAAM5dycndffjSV5YVRckeWeS/2W3P7i7jyY5miTr6+u9sbGx20tmc3Mzi7jOQaZHs+nPfHo026r154Yjdyy7hKc5dui8leoRAAAAAAAwlp08k/zPdfcfJnlvkm9KckFVPRGyX5LkxLR9IsmlSTIdf3aSP1hEsQAAAAAAAACwG3ND8qr6iukO8lTVlyf5G0l+K1th+d+eTrs+ybum7dun/UzHf6V3sqY7AAAAAAAAAOyxnSy3flGSW6bnkn9Jktu6++er6qNJbq2qf5bkN5K8ZTr/LUn+TVUdT/LZJNftQd0AAAAAAAAAcNrmhuTd/ZEkX3+K8U8kefEpxv97kv9jIdUBAAAAAAAAwAKd1jPJAQAAAAAAAOBsJiQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGMTckr6pLq+q9VfXRqrqvqr5/Gv+RqjpRVR+eXldv+8wPVdXxqvpYVX37Xv4CAAAAAAAAALBT5+7gnMeS3NTdv15Vz0ryoap6z3TsDd39L7efXFVXJLkuydcm+ctJ/lNVfU13P77IwgEAAAAAAADgdM29k7y7H+zuX5+2/zjJbyW5eMZHrklya3d/vrs/meR4khcvolgAAAAAAAAA2I3q7p2fXHVZkvcleX6SH0xyQ5I/SnJ3tu42f6Sq/lWSu7r7306feUuSX+jun3vKtQ4nOZwka2tr33Drrbfu+pc5efJkzj///F1f5yDTo9n0Zz49mm3V+nPPiUeXXcLTPO/Z5yykR1deeeWHunt9ASUBAAAAAAAD2cly60mSqjo/yb9P8gPd/UdV9aYkP5qkp/fXJ/nenV6vu48mOZok6+vrvbGxcRpln9rm5mYWcZ2DTI9m05/59Gi2VevPDUfuWHYJT3Ps0Hkr1SMAAAAAAGAsc5dbT5Kqeka2AvKf6e7/kCTd/VB3P97df5bkzfnCkuonkly67eOXTGMAAAAAAAAAsFRzQ/KqqiRvSfJb3f3j28Yv2nbadyW5d9q+Pcl1VfXMqnpeksuTfGBxJQMAAAAAAADAmdnJcuvfnOTvJLmnqj48jf1wkpdX1Quztdz6/Um+L0m6+76qui3JR5M8luRV3f34YssGAAAAAAAAgNM3NyTv7vcnqVMceveMz7wuyet2URcAAAAAAAAALNyOnkkOAAAAAAAAAAeBkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYQjJAQAAAAAAABiGkBwAAAAAAACAYcwNyavq0qp6b1V9tKruq6rvn8afW1XvqaqPT+/Pmcarqt5YVcer6iNV9aK9/iUAAAAAAAAAYCd2cif5Y0lu6u4rkrwkyauq6ookR5Lc2d2XJ7lz2k+Slya5fHodTvKmhVcNAAAAAAAAAGdgbkje3Q92969P23+c5LeSXJzkmiS3TKfdkuRl0/Y1Sd7WW+5KckFVXbTowgEAAAAAAADgdFV37/zkqsuSvC/J85P8bndfMI1Xkke6+4Kq+vkkN3f3+6djdyZ5TXff/ZRrHc7WneZZW1v7hltvvXXXv8zJkydz/vnn7/o6B5kezaY/8+nRbKvWn3tOPLrsEp7mec8+ZyE9uvLKKz/U3esLKAkAAAAAABjIuTs9sarOT/Lvk/xAd//RVi6+pbu7qnaetm995miSo0myvr7eGxsbp/PxU9rc3MwirnOQ6dFs+jOfHs22av254cgdyy7haY4dOm+legQAAAAAAIxlJ88kT1U9I1sB+c9093+Yhh96Yhn16f3hafxEkku3ffySaQwAAAAAAAAAlmpuSD4tpf6WJL/V3T++7dDtSa6ftq9P8q5t46+oLS9J8mh3P7jAmgEAAAAAAADgjOxkufVvTvJ3ktxTVR+exn44yc1JbquqG5N8Ksm107F3J7k6yfEkn0vyykUWDAAAAAAAAABnam5I3t3vT1Jf5PBVpzi/k7xql3UBAAAAAAAAwMLt6JnkAAAAAAAAAHAQCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhCMkBAAAAAAAAGIaQHAAAAAAAAIBhzA3Jq+qtVfVwVd27bexHqupEVX14el297dgPVdXxqvpYVX37XhUOAAAAAAAAAKdrJ3eSH0ty6BTjb+juF06vdydJVV2R5LokXzt95qeq6pxFFQsAAAAAAAAAuzE3JO/u9yX57A6vd02SW7v78939ySTHk7x4F/UBAAAAAAAAwMKcu4vPvrqqXpHk7iQ3dfcjSS5Octe2cx6Yxp6mqg4nOZwka2tr2dzc3EUpW06ePLmQ6xxkejSb/synR7OtWn9uesFjyy7haVatRwAAAAAAwFjONCR/U5IfTdLT++uTfO/pXKC7jyY5miTr6+u9sbFxhqV8webmZhZxnYNMj2bTn/n0aLZV688NR+5YdglPc+zQeSvVIwAAAAAAYCw7eSb503T3Q939eHf/WZI35wtLqp9Icum2Uy+ZxgAAAAAAAABg6c4oJK+qi7btfleSe6ft25NcV1XPrKrnJbk8yQd2VyIAAAAAAAAALMbc5dar6u1JNpJcWFUPJHltko2qemG2llu/P8n3JUl331dVtyX5aJLHkryqux/fk8oBAAAAAAAA4DTNDcm7++WnGH7LjPNfl+R1uykKAAAAAAAAAPbCGS23DgAAAAAAAABnIyE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMMQkgMAAAAAAAAwDCE5AAAAAAAAAMOYG5JX1Vur6uGqunfb2HOr6j1V9fHp/TnTeFXVG6vqeFV9pKpetJfFAwAAAAAAAMDp2Mmd5MeSHHrK2JEkd3b35UnunPaT5KVJLp9eh5O8aTFlAgAAAAAAAMDuzQ3Ju/t9ST77lOFrktwybd+S5GXbxt/WW+5KckFVXbSgWgEAAAAAAABgV6q7559UdVmSn+/u50/7f9jdF0zbleSR7r6gqn4+yc3d/f7p2J1JXtPdd5/imoezdbd51tbWvuHWW2/d9S9z8uTJnH/++bu+zkGmR7Ppz3x6NNuq9eeeE48uu4Sned6zz1lIj6688soPdff6AkoCAAAAAAAGcu5uL9DdXVXzk/anf+5okqNJsr6+3hsbG7stJZubm1nEdQ4yPZpNf+bTo9lWrT83HLlj2SU8zbFD561UjwAAAAAAgLHs5Jnkp/LQE8uoT+8PT+Mnkly67bxLpjEAAAAAAAAAWLozDclvT3L9tH19kndtG39FbXlJkke7+8Fd1ggAAAAAAAAACzF3ufWqenuSjSQXVtUDSV6b5OYkt1XVjUk+leTa6fR3J7k6yfEkn0vyyj2oGQAAAAAAAADOyNyQvLtf/kUOXXWKczvJq3ZbFAAAAAAAAADshTNdbh0AAAAAAAAAzjpCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGISQHAAAAAAAAYBhCcgAAAAAAAACGce6yC1ike048mhuO3LHsMp7k/pu/Y9klAAAAAAAAADBxJzkAAAAAAAAAwxCSAwAAAAAAADAMITkAAAAAAAAAwxCSAwAAAAAAADAMITkAAAAAAAAAwxCSAwAAAAAAADAMITkAAAAAAAAAwxCSAwAAAAAAADCMc3fz4aq6P8kfJ3k8yWPdvV5Vz03yjiSXJbk/ybXd/cjuygQAAAAAAACA3VvEneRXdvcLu3t92j+S5M7uvjzJndM+AAAAAAAAACzdXiy3fk2SW6btW5K8bA9+BgAAAAAAAACcturuM/9w1SeTPJKkk/x0dx+tqj/s7gum45XkkSf2n/LZw0kOJ8na2to33HrrrWdcxxMe/uyjeei/7foyC/WCi5+97BKe5OTJkzn//POXXcbK0p/59Gi2VevPPSceXXYJT/O8Z5+zkB5deeWVH9q2igkAAAAAAMCO7OqZ5Em+pbtPVNVXJnlPVf329oPd3VV1yhS+u48mOZok6+vrvbGxsctSkp/4mXfl9ffs9ldarPu/e2PZJTzJ5uZmFtHrg0p/5tOj2VatPzccuWPZJTzNsUPnrVSPAAAAAACAsexqufXuPjG9P5zknUlenOShqrooSab3h3dbJAAAAAAAAAAswhmH5FV1XlU964ntJN+W5N4ktye5fjrt+iTv2m2RAAAAAAAAALAIu1mbfC3JO7ceO55zk/xsd/9iVX0wyW1VdWOSTyW5dvdlAgAAAAAAAMDunXFI3t2fSPJ1pxj/gyRX7aYoAAAAAAAAANgLu3omOQAAAAAAAACcTYTkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxDSA4AAAAAAADAMITkAAAAAAAAAAxjz0LyqjpUVR+rquNVdWSvfg4AAAAAAAAA7NSehORVdU6Sn0zy0iRXJHl5VV2xFz8LAAAAAAAAAHZqr+4kf3GS4939ie7+0yS3Jrlmj34WAAAAAAAAAOzIuXt03YuTfHrb/gNJvnH7CVV1OMnhafdkVX1sAT/3wiS/v4DrLEz92LIreJqV69GK0Z/59Gg2/Znjyh9bWI++agHXAAAAAAAABrNXIflc3X00ydFFXrOq7u7u9UVe86DRo9n0Zz49mk1/5tMjAAAAAABgmfZqufUTSS7dtn/JNAYAAAAAAAAAS7NXIfkHk1xeVc+rqi9Ncl2S2/foZwEAAAAAAADAjuzJcuvd/VhVvTrJLyU5J8lbu/u+vfhZT7HQ5dsPKD2aTX/m06PZ9Gc+PQIAAAAAAJamunvZNQAAAAAAAADAvtir5dYBAAAAAAAAYOUIyQEAAAAAAAAYxlkZklfVoar6WFUdr6ojpzj+zKp6x3T816rqsiWUuTQ76M8PVtVHq+ojVXVnVX3VMupcpnk92nbe36qqrqr1/axv2XbSn6q6dvpzdF9V/ex+17hsO/h79leq6r1V9RvT37Wrl1HnslTVW6vq4aq694scr6p649S/j1TVi/a7RgAAAAAAYExnXUheVeck+ckkL01yRZKXV9UVTzntxiSPdPdXJ3lDkh/b3yqXZ4f9+Y0k6939vyb5uST/fH+rXK4d9ihV9awk35/k1/a3wuXaSX+q6vIkP5Tkm7v7a5P8wH7XuUw7/DP0j5Pc1t1fn+S6JD+1v1Uu3bEkh2Ycf2mSy6fX4SRv2oeaAAAAAAAAzr6QPMmLkxzv7k90958muTXJNU8555okt0zbP5fkqqqqfaxxmeb2p7vf292fm3bvSnLJPte4bDv5M5QkP5qtL1j89/0sbgXspD9/N8lPdvcjSdLdD+9zjcu2kx51kr84bT87yX/dx/qWrrvfl+SzM065JsnbestdSS6oqov2pzoAAAAAAGBkZ2NIfnGST2/bf2AaO+U53f1YkkeT/KV9qW75dtKf7W5M8gt7WtHqmdujaennS7v7jv0sbEXs5M/Q1yT5mqr6z1V1V1XNumP4INpJj34kyfdU1QNJ3p3k7+9PaWeN0/23CgAAAAAAYCHOXXYBLE9VfU+S9SR/bdm1rJKq+pIkP57khiWXssrOzdYy2RvZWongfVX1gu7+w2UWtWJenuRYd7++qr4pyb+pqud3958tuzAAAAAAAICRnY13kp9Icum2/UumsVOeU1XnZmup4z/Yl+qWbyf9SVX99ST/KMl3dvfn96m2VTGvR89K8vwkm1V1f5KXJLm9qtb3rcLl2smfoQeS3N7d/6O7P5nkv2QrNB/FTnp0Y5LbkqS7fzXJlyW5cF+qOzvs6N8qAAAAAACARTsbQ/IPJrm8qp5XVV+a5Loktz/lnNuTXD9t/+0kv9LdvY81LtPc/lTV1yf56WwF5KM9SzqZ06PufrS7L+zuy7r7smw9t/07u/vu5ZS773byd+w/Zusu8lTVhdlafv0T+1jjsu2kR7+b5Kokqaq/mq2Q/Pf2tcrVdnuSV9SWlyR5tLsfXHZRAAAAAADAwXfWLbfe3Y9V1auT/FKSc5K8tbvvq6p/muTu7r49yVuytbTx8SSfzVaANYQd9udfJDk/yb+rqiT53e7+zqUVvc922KNh7bA/v5Tk26rqo0keT/IPu3uU1Rp22qObkry5qv5Bkk5yw0Bf1klVvT1bX6S4cHou+2uTPCNJuvtfZ+s57VcnOZ7kc0leuZxKAQAAAACA0dRAmQ0AAAAAAAAAgzsbl1sHAAAAAAAAgDMiJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIYhJAcAAAAAAABgGEJyAAAAAAAAAIbx/wN+hNnPzYPyiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2520x2520 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize = (35,35))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a92b69",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cdd5538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (400, 25)\n",
      "Total number of records in dataset = 400\n",
      "Total number of attributes in dataset = 25\n",
      "\n",
      "     class\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "..     ...\n",
      "395      1\n",
      "396      1\n",
      "397      1\n",
      "398      1\n",
      "399      1\n",
      "\n",
      "[400 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Description of Datasets\n",
    "    #Print number of records and attributes of whole kidney dataset\n",
    "    print('Shape of dataset: ' + str(df.shape))\n",
    "    print('Total number of records in dataset = ' + str(df.shape[0]))\n",
    "    print('Total number of attributes in dataset = ' + str(df.shape[1]))\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    df = df.replace('?', np.nan)\n",
    "    \n",
    "    #set the features and the target variables\n",
    "    target_class = df['class']\n",
    "    \n",
    "    feature_classes = df.iloc[:, 0:24]\n",
    "    \n",
    "    \n",
    "#     KNN imputation (n_neighbour = 5 means that the missing values will be replaced by the mean value of 5 nearest neighbors)\n",
    "    knn_missing_values_imputer = KNNImputer(n_neighbors=5)\n",
    "    feature_classes = pd.DataFrame(knn_missing_values_imputer.fit_transform(feature_classes),\n",
    "                                   columns = feature_classes.columns)\n",
    "\n",
    "    target_label_encoder = preprocessing.LabelEncoder()\n",
    "    target_class = target_label_encoder.fit_transform(target_class)\n",
    "    target_class1 = pd.DataFrame(target_class, columns=['class'])\n",
    "    print(target_class1)\n",
    "\n",
    "                                                      \n",
    "except FileNotFoundError as e:\n",
    "    logging.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd602a8",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17a2ad",
   "metadata": {},
   "source": [
    "## Method-1 Using Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981471f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = RandomForestClassifier()\n",
    "model.fit(feature_classes,target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906c2032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hemo    0.228557\n",
      "pcv     0.152027\n",
      "sg      0.124400\n",
      "sc      0.111288\n",
      "rbcc    0.088373\n",
      "dtype: float64\n",
      "hemo    0.228557\n",
      "pcv     0.152027\n",
      "sg      0.124400\n",
      "sc      0.111288\n",
      "rbcc    0.088373\n",
      "al      0.068269\n",
      "dtype: float64\n",
      "hemo    0.228557\n",
      "pcv     0.152027\n",
      "sg      0.124400\n",
      "sc      0.111288\n",
      "rbcc    0.088373\n",
      "al      0.068269\n",
      "bgr     0.037948\n",
      "dtype: float64\n",
      "hemo    0.228557\n",
      "pcv     0.152027\n",
      "sg      0.124400\n",
      "sc      0.111288\n",
      "rbcc    0.088373\n",
      "al      0.068269\n",
      "bgr     0.037948\n",
      "htn     0.037811\n",
      "dtype: float64\n",
      "hemo    0.228557\n",
      "pcv     0.152027\n",
      "sg      0.124400\n",
      "sc      0.111288\n",
      "rbcc    0.088373\n",
      "al      0.068269\n",
      "bgr     0.037948\n",
      "htn     0.037811\n",
      "bu      0.032958\n",
      "dtype: float64\n",
      "hemo    0.228557\n",
      "pcv     0.152027\n",
      "sg      0.124400\n",
      "sc      0.111288\n",
      "rbcc    0.088373\n",
      "al      0.068269\n",
      "bgr     0.037948\n",
      "htn     0.037811\n",
      "bu      0.032958\n",
      "dm      0.031138\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=feature_classes.columns)\n",
    "for i in range(5,11):\n",
    "    feat_importances.nlargest(i).plot(kind='barh')\n",
    "    print(feat_importances.nlargest(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4fe2a",
   "metadata": {},
   "source": [
    "## Method-2 Selectkbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66609711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(feature_classes,target_class)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(feature_classes.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683747f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Features\n",
      "\n",
      "   Specs       Score\n",
      "14  hemo  558.308298\n",
      "2     sg  413.050584\n",
      "17  rbcc  280.783698\n",
      "3     al  236.151572\n",
      "15   pcv  223.587689\n",
      "\n",
      "Top 6 Features\n",
      "\n",
      "   Specs       Score\n",
      "14  hemo  558.308298\n",
      "2     sg  413.050584\n",
      "17  rbcc  280.783698\n",
      "3     al  236.151572\n",
      "15   pcv  223.587689\n",
      "18   htn  197.036645\n",
      "\n",
      "Top 7 Features\n",
      "\n",
      "   Specs       Score\n",
      "14  hemo  558.308298\n",
      "2     sg  413.050584\n",
      "17  rbcc  280.783698\n",
      "3     al  236.151572\n",
      "15   pcv  223.587689\n",
      "18   htn  197.036645\n",
      "19    dm  175.397966\n",
      "\n",
      "Top 8 Features\n",
      "\n",
      "   Specs       Score\n",
      "14  hemo  558.308298\n",
      "2     sg  413.050584\n",
      "17  rbcc  280.783698\n",
      "3     al  236.151572\n",
      "15   pcv  223.587689\n",
      "18   htn  197.036645\n",
      "19    dm  175.397966\n",
      "9    bgr   83.762171\n",
      "\n",
      "Top 9 Features\n",
      "\n",
      "    Specs       Score\n",
      "14   hemo  558.308298\n",
      "2      sg  413.050584\n",
      "17   rbcc  280.783698\n",
      "3      al  236.151572\n",
      "15    pcv  223.587689\n",
      "18    htn  197.036645\n",
      "19     dm  175.397966\n",
      "9     bgr   83.762171\n",
      "21  appet   68.678957\n",
      "\n",
      "Top 10 Features\n",
      "\n",
      "    Specs       Score\n",
      "14   hemo  558.308298\n",
      "2      sg  413.050584\n",
      "17   rbcc  280.783698\n",
      "3      al  236.151572\n",
      "15    pcv  223.587689\n",
      "18    htn  197.036645\n",
      "19     dm  175.397966\n",
      "9     bgr   83.762171\n",
      "21  appet   68.678957\n",
      "10     bu   67.528762\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,11):\n",
    "    print(\"\\nTop \"+str(i)+\" Features\\n\")\n",
    "    print(featureScores.nlargest(i,'Score'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e4be3",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d9a8452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Pre-processing:\n",
      "Size of train dataset: 280\n",
      "Size of test dataset: 120\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_target, test_target = train_test_split(feature_classes, target_class, \n",
    "                                                                                train_size = 0.7, test_size = 0.3, random_state = 42)\n",
    "print('\\nAfter Pre-processing:')\n",
    "print('Size of train dataset: ' + str(train_target.shape[0]))\n",
    "print('Size of test dataset: ' + str(test_target.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0672f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>62.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>54.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.014</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.4</td>\n",
       "      <td>...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>46.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14600.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>50.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>23.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.6</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bp     sg   al   su  rbc   pc  pcc   ba    bgr  ...  hemo   pcv  \\\n",
       "157  62.0   70.0  1.025  3.0  0.0  0.0  1.0  1.0  1.0  122.0  ...  12.6  39.0   \n",
       "109  54.0   70.0  1.014  1.6  1.8  0.0  0.0  1.0  1.0  233.0  ...  11.7   0.0   \n",
       "17   47.0   80.0  1.016  0.8  0.4  0.0  0.0  1.0  1.0  114.0  ...  12.1   0.0   \n",
       "347  43.0   60.0  1.025  0.0  0.0  0.0  0.0  1.0  1.0  108.0  ...  17.8  43.0   \n",
       "24   42.0  100.0  1.015  4.0  0.0  0.0  1.0  1.0  0.0  156.4  ...  11.1  39.0   \n",
       "..    ...    ...    ...  ...  ...  ...  ...  ...  ...    ...  ...   ...   ...   \n",
       "71   46.0   60.0  1.010  1.0  0.0  0.0  0.0  1.0  1.0  163.0  ...   9.8  28.0   \n",
       "106  50.0   90.0  1.018  0.6  0.0  0.0  0.0  1.0  1.0   89.0  ...   6.0  17.0   \n",
       "270  23.0   80.0  1.025  0.0  0.0  0.0  0.0  1.0  1.0  111.0  ...  14.3  41.0   \n",
       "348  38.0   80.0  1.020  0.0  0.0  0.0  0.0  1.0  1.0   99.0  ...  13.6  44.0   \n",
       "102  17.0   60.0  1.010  0.0  0.0  0.0  0.0  1.0  1.0   92.0  ...  13.9  52.0   \n",
       "\n",
       "        wbcc  rbcc  htn   dm  cad  appet   pe  ane  \n",
       "157   7900.0   3.9  0.0  0.0  1.0    1.0  1.0  1.0  \n",
       "109      0.0   0.0  1.0  0.0  1.0    1.0  1.0  1.0  \n",
       "17       0.0   0.0  0.0  1.0  1.0    0.0  1.0  1.0  \n",
       "347   7200.0   5.5  1.0  1.0  1.0    1.0  1.0  1.0  \n",
       "24    8300.0   4.6  0.0  1.0  1.0    0.0  1.0  1.0  \n",
       "..       ...   ...  ...  ...  ...    ...  ...  ...  \n",
       "71   14600.0   3.2  0.0  0.0  1.0    1.0  1.0  1.0  \n",
       "106   6500.0   0.0  0.0  0.0  1.0    1.0  0.0  0.0  \n",
       "270   7200.0   5.0  1.0  1.0  1.0    1.0  1.0  1.0  \n",
       "348   7300.0   6.4  1.0  1.0  1.0    1.0  1.0  1.0  \n",
       "102   7000.0   0.0  1.0  1.0  1.0    1.0  1.0  1.0  \n",
       "\n",
       "[280 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63840fe8",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2b29f80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #Scaling and normalization of features\n",
    "    standard_feature_scaler = StandardScaler()\n",
    "    train_features = standard_feature_scaler.fit_transform(train_features)\n",
    "    train_features = pd.DataFrame(train_features, columns=['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', \n",
    "                                                             'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', \n",
    "                                                             'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', \n",
    "                                                             'cad', 'appet', 'pe', 'ane'])\n",
    "    test_features  = standard_feature_scaler.transform(test_features)\n",
    "    test_features = pd.DataFrame(test_features, columns=['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', \n",
    "                                                             'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', \n",
    "                                                             'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', \n",
    "                                                             'cad', 'appet', 'pe', 'ane'])\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "961ef703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.97238883 -0.60956815  0.5296106  ...  0.46056619  0.52592371\n",
      "   0.46056619]\n",
      " [-0.25975019  0.21417259  0.16748369 ...  0.46056619  0.52592371\n",
      "   0.46056619]\n",
      " [ 0.53540346  1.86165408  0.5296106  ... -2.17124059  0.52592371\n",
      "   0.46056619]\n",
      " ...\n",
      " [ 0.90239745 -0.60956815  0.5296106  ...  0.46056619  0.52592371\n",
      "   0.46056619]\n",
      " [-0.62674419  0.21417259  0.5296106  ...  0.46056619  0.52592371\n",
      "   0.46056619]\n",
      " [ 0.22957513  0.21417259  1.43492787 ...  0.46056619  0.52592371\n",
      "   0.46056619]]\n"
     ]
    }
   ],
   "source": [
    "print(standard_feature_scaler.fit_transform(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cfdd36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "print(standard_feature_scaler.fit(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9f8484b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.872236</td>\n",
       "      <td>-0.429337</td>\n",
       "      <td>0.490370</td>\n",
       "      <td>-0.788128</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269496</td>\n",
       "      <td>-1.877104</td>\n",
       "      <td>0.190581</td>\n",
       "      <td>-1.316487</td>\n",
       "      <td>0.762837</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.533295</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.256747</td>\n",
       "      <td>0.283678</td>\n",
       "      <td>0.124715</td>\n",
       "      <td>-0.788128</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-0.782344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375391</td>\n",
       "      <td>1.170129</td>\n",
       "      <td>0.452698</td>\n",
       "      <td>0.873146</td>\n",
       "      <td>0.762837</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.533295</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.493301</td>\n",
       "      <td>1.709707</td>\n",
       "      <td>0.490370</td>\n",
       "      <td>0.741157</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>2.941967</td>\n",
       "      <td>2.171241</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-0.144993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.771075</td>\n",
       "      <td>-0.177686</td>\n",
       "      <td>-1.316592</td>\n",
       "      <td>-1.316487</td>\n",
       "      <td>-1.310895</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>-1.875134</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.435605</td>\n",
       "      <td>1.709707</td>\n",
       "      <td>-0.423769</td>\n",
       "      <td>2.270442</td>\n",
       "      <td>1.524825</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>1.414484</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.774232</td>\n",
       "      <td>-0.705091</td>\n",
       "      <td>0.824031</td>\n",
       "      <td>0.325738</td>\n",
       "      <td>-1.310895</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-3.125577</td>\n",
       "      <td>0.533295</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>-2.449490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.243349</td>\n",
       "      <td>1.709707</td>\n",
       "      <td>-1.337908</td>\n",
       "      <td>1.505800</td>\n",
       "      <td>1.524825</td>\n",
       "      <td>2.941967</td>\n",
       "      <td>2.171241</td>\n",
       "      <td>-2.886751</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>1.956910</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.093518</td>\n",
       "      <td>-0.119085</td>\n",
       "      <td>0.212424</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>-1.310895</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>-3.125577</td>\n",
       "      <td>-1.875134</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.897173</td>\n",
       "      <td>0.996692</td>\n",
       "      <td>0.490370</td>\n",
       "      <td>-0.023485</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>2.171241</td>\n",
       "      <td>-2.886751</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-0.131432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720917</td>\n",
       "      <td>-1.877104</td>\n",
       "      <td>-1.316592</td>\n",
       "      <td>-1.316487</td>\n",
       "      <td>-1.310895</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.533295</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.262517</td>\n",
       "      <td>0.283678</td>\n",
       "      <td>-1.337908</td>\n",
       "      <td>-0.023485</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.194024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447045</td>\n",
       "      <td>0.466922</td>\n",
       "      <td>1.260892</td>\n",
       "      <td>0.788930</td>\n",
       "      <td>-1.310895</td>\n",
       "      <td>-1.290994</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>-1.875134</td>\n",
       "      <td>-2.119008</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.839477</td>\n",
       "      <td>-0.429337</td>\n",
       "      <td>0.490370</td>\n",
       "      <td>-0.788128</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-0.768783</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342721</td>\n",
       "      <td>0.525522</td>\n",
       "      <td>-0.158908</td>\n",
       "      <td>1.167905</td>\n",
       "      <td>0.762837</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.533295</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-0.602923</td>\n",
       "      <td>0.283678</td>\n",
       "      <td>0.490370</td>\n",
       "      <td>-0.788128</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-0.389084</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736819</td>\n",
       "      <td>0.525522</td>\n",
       "      <td>0.671129</td>\n",
       "      <td>0.873146</td>\n",
       "      <td>0.762837</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.533295</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.204821</td>\n",
       "      <td>0.283678</td>\n",
       "      <td>1.404509</td>\n",
       "      <td>-0.788128</td>\n",
       "      <td>-0.432768</td>\n",
       "      <td>-0.339909</td>\n",
       "      <td>-0.460566</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-0.280599</td>\n",
       "      <td>...</td>\n",
       "      <td>1.163586</td>\n",
       "      <td>0.525522</td>\n",
       "      <td>0.671129</td>\n",
       "      <td>1.210013</td>\n",
       "      <td>0.762837</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.533295</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age        bp        sg        al        su       rbc        pc  \\\n",
       "0   -1.872236 -0.429337  0.490370 -0.788128 -0.432768 -0.339909 -0.460566   \n",
       "1   -0.256747  0.283678  0.124715 -0.788128 -0.432768 -0.339909 -0.460566   \n",
       "2    0.493301  1.709707  0.490370  0.741157 -0.432768  2.941967  2.171241   \n",
       "3    0.435605  1.709707 -0.423769  2.270442  1.524825 -0.339909 -0.460566   \n",
       "4    1.243349  1.709707 -1.337908  1.505800  1.524825  2.941967  2.171241   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "115  0.897173  0.996692  0.490370 -0.023485 -0.432768 -0.339909  2.171241   \n",
       "116  0.262517  0.283678 -1.337908 -0.023485 -0.432768 -0.339909 -0.460566   \n",
       "117  0.839477 -0.429337  0.490370 -0.788128 -0.432768 -0.339909 -0.460566   \n",
       "118 -0.602923  0.283678  0.490370 -0.788128 -0.432768 -0.339909 -0.460566   \n",
       "119  0.204821  0.283678  1.404509 -0.788128 -0.432768 -0.339909 -0.460566   \n",
       "\n",
       "          pcc       ba       bgr  ...      hemo       pcv      wbcc      rbcc  \\\n",
       "0    0.346410  0.27735  0.552025  ... -0.269496 -1.877104  0.190581 -1.316487   \n",
       "1    0.346410  0.27735 -0.782344  ...  0.375391  1.170129  0.452698  0.873146   \n",
       "2    0.346410  0.27735 -0.144993  ... -0.771075 -0.177686 -1.316592 -1.316487   \n",
       "3    0.346410  0.27735  1.414484  ... -1.774232 -0.705091  0.824031  0.325738   \n",
       "4   -2.886751  0.27735  1.956910  ... -1.093518 -0.119085  0.212424  0.030980   \n",
       "..        ...      ...       ...  ...       ...       ...       ...       ...   \n",
       "115 -2.886751  0.27735 -0.131432  ... -0.720917 -1.877104 -1.316592 -1.316487   \n",
       "116  0.346410  0.27735  0.194024  ...  0.447045  0.466922  1.260892  0.788930   \n",
       "117  0.346410  0.27735 -0.768783  ...  1.342721  0.525522 -0.158908  1.167905   \n",
       "118  0.346410  0.27735 -0.389084  ...  1.736819  0.525522  0.671129  0.873146   \n",
       "119  0.346410  0.27735 -0.280599  ...  1.163586  0.525522  0.671129  1.210013   \n",
       "\n",
       "          htn        dm       cad     appet        pe       ane  \n",
       "0    0.762837  0.774597  0.319941  0.533295  0.471919  0.408248  \n",
       "1    0.762837  0.774597  0.319941  0.533295  0.471919  0.408248  \n",
       "2   -1.310895  0.774597  0.319941 -1.875134  0.471919  0.408248  \n",
       "3   -1.310895 -1.290994 -3.125577  0.533295  0.471919 -2.449490  \n",
       "4   -1.310895 -1.290994 -3.125577 -1.875134  0.471919  0.408248  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "115 -1.310895  0.774597  0.319941  0.533295  0.471919  0.408248  \n",
       "116 -1.310895 -1.290994  0.319941 -1.875134 -2.119008  0.408248  \n",
       "117  0.762837  0.774597  0.319941  0.533295  0.471919  0.408248  \n",
       "118  0.762837  0.774597  0.319941  0.533295  0.471919  0.408248  \n",
       "119  0.762837  0.774597  0.319941  0.533295  0.471919  0.408248  \n",
       "\n",
       "[120 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "548b64c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of features are \n",
      " 5\n",
      "Index(['hemo', 'pcv', 'rbcc', 'sc', 'sg'], dtype='object')\n",
      "         hemo       pcv      rbcc        sc        sg\n",
      "0    0.124601  0.408321  0.325738 -0.226819  1.404509\n",
      "1   -0.197842 -1.877104 -1.316487 -0.191919 -0.606597\n",
      "2   -0.054534 -1.877104 -1.316487  0.383931 -0.240941\n",
      "3    1.987608  0.642724  0.999471 -0.348968  1.404509\n",
      "4   -0.412804  0.408321  0.620496 -0.279169 -0.423769\n",
      "..        ...       ...       ...       ...       ...\n",
      "275 -0.878556 -0.236286  0.030980  0.052381 -1.337908\n",
      "276 -2.239984 -0.880893 -1.316487  0.540981  0.124715\n",
      "277  0.733661  0.525522  0.788930 -0.331518  1.404509\n",
      "278  0.482872  0.701324  1.378446 -0.436218  0.490370\n",
      "279  0.590353  1.170129 -1.316487 -0.157019 -1.337908\n",
      "\n",
      "[280 rows x 5 columns]\n",
      "         hemo       pcv      rbcc        sc        sg\n",
      "0   -0.265758 -1.913880 -1.396007 -0.164989  0.529611\n",
      "1    0.354019  1.209188  0.832462 -0.433445  0.167484\n",
      "2   -0.747807 -0.172169 -1.396007 -0.135160  0.529611\n",
      "3   -1.711905 -0.712700  0.275345  1.785049 -0.375707\n",
      "4   -1.057696 -0.112110 -0.024642  0.442767 -1.281024\n",
      "..        ...       ...       ...       ...       ...\n",
      "115 -0.699602 -1.913880 -1.396007 -0.004661  0.529611\n",
      "116  0.422883  0.488480  0.746751 -0.265660 -1.281024\n",
      "117  1.283685  0.548539  1.132448 -0.470731  0.529611\n",
      "118  1.662437  0.548539  0.832462 -0.452088  0.529611\n",
      "119  1.111524  0.548539  1.175303 -0.377517  1.434928\n",
      "\n",
      "[120 rows x 5 columns]\n",
      "The no of features are \n",
      " 6\n",
      "Index(['hemo', 'pcv', 'rbcc', 'sc', 'sg', 'al'], dtype='object')\n",
      "         hemo       pcv      rbcc        sc        sg        al\n",
      "0    0.124601  0.408321  0.325738 -0.226819  1.404509  1.505800\n",
      "1   -0.197842 -1.877104 -1.316487 -0.191919 -0.606597  0.435300\n",
      "2   -0.054534 -1.877104 -1.316487  0.383931 -0.240941 -0.176414\n",
      "3    1.987608  0.642724  0.999471 -0.348968  1.404509 -0.788128\n",
      "4   -0.412804  0.408321  0.620496 -0.279169 -0.423769  2.270442\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "275 -0.878556 -0.236286  0.030980  0.052381 -1.337908 -0.023485\n",
      "276 -2.239984 -0.880893 -1.316487  0.540981  0.124715 -0.329342\n",
      "277  0.733661  0.525522  0.788930 -0.331518  1.404509 -0.788128\n",
      "278  0.482872  0.701324  1.378446 -0.436218  0.490370 -0.788128\n",
      "279  0.590353  1.170129 -1.316487 -0.157019 -1.337908 -0.788128\n",
      "\n",
      "[280 rows x 6 columns]\n",
      "         hemo       pcv      rbcc        sc        sg        al\n",
      "0   -0.265758 -1.913880 -1.396007 -0.164989  0.529611 -0.811905\n",
      "1    0.354019  1.209188  0.832462 -0.433445  0.167484 -0.811905\n",
      "2   -0.747807 -0.172169 -1.396007 -0.135160  0.529611  0.767164\n",
      "3   -1.711905 -0.712700  0.275345  1.785049 -0.375707  2.346233\n",
      "4   -1.057696 -0.112110 -0.024642  0.442767 -1.281024  1.556699\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "115 -0.699602 -1.913880 -1.396007 -0.004661  0.529611 -0.022370\n",
      "116  0.422883  0.488480  0.746751 -0.265660 -1.281024 -0.022370\n",
      "117  1.283685  0.548539  1.132448 -0.470731  0.529611 -0.811905\n",
      "118  1.662437  0.548539  0.832462 -0.452088  0.529611 -0.811905\n",
      "119  1.111524  0.548539  1.175303 -0.377517  1.434928 -0.811905\n",
      "\n",
      "[120 rows x 6 columns]\n",
      "The no of features are \n",
      " 7\n",
      "Index(['hemo', 'pcv', 'rbcc', 'sc', 'sg', 'al', 'bgr'], dtype='object')\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr\n",
      "0    0.124601  0.408321  0.325738 -0.226819  1.404509  1.505800 -0.389084\n",
      "1   -0.197842 -1.877104 -1.316487 -0.191919 -0.606597  0.435300  1.116149\n",
      "2   -0.054534 -1.877104 -1.316487  0.383931 -0.240941 -0.176414 -0.497570\n",
      "3    1.987608  0.642724  0.999471 -0.348968  1.404509 -0.788128 -0.578934\n",
      "4   -0.412804  0.408321  0.620496 -0.279169 -0.423769  2.270442  0.077402\n",
      "..        ...       ...       ...       ...       ...       ...       ...\n",
      "275 -0.878556 -0.236286  0.030980  0.052381 -1.337908 -0.023485  0.166903\n",
      "276 -2.239984 -0.880893 -1.316487  0.540981  0.124715 -0.329342 -0.836586\n",
      "277  0.733661  0.525522  0.788930 -0.331518  1.404509 -0.788128 -0.538252\n",
      "278  0.482872  0.701324  1.378446 -0.436218  0.490370 -0.788128 -0.700980\n",
      "279  0.590353  1.170129 -1.316487 -0.157019 -1.337908 -0.788128 -0.795904\n",
      "\n",
      "[280 rows x 7 columns]\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr\n",
      "0   -0.265758 -1.913880 -1.396007 -0.164989  0.529611 -0.811905  0.566156\n",
      "1    0.354019  1.209188  0.832462 -0.433445  0.167484 -0.811905 -0.646947\n",
      "2   -0.747807 -0.172169 -1.396007 -0.135160  0.529611  0.767164 -0.067518\n",
      "3   -1.711905 -0.712700  0.275345  1.785049 -0.375707  2.346233  1.350234\n",
      "4   -1.057696 -0.112110 -0.024642  0.442767 -1.281024  1.556699  1.843365\n",
      "..        ...       ...       ...       ...       ...       ...       ...\n",
      "115 -0.699602 -1.913880 -1.396007 -0.004661  0.529611 -0.022370 -0.055190\n",
      "116  0.422883  0.488480  0.746751 -0.265660 -1.281024 -0.022370  0.240689\n",
      "117  1.283685  0.548539  1.132448 -0.470731  0.529611 -0.811905 -0.634619\n",
      "118  1.662437  0.548539  0.832462 -0.452088  0.529611 -0.811905 -0.289427\n",
      "119  1.111524  0.548539  1.175303 -0.377517  1.434928 -0.811905 -0.190801\n",
      "\n",
      "[120 rows x 7 columns]\n",
      "The no of features are \n",
      " 8\n",
      "Index(['hemo', 'pcv', 'rbcc', 'sc', 'sg', 'al', 'bgr', 'htn'], dtype='object')\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr  \\\n",
      "0    0.124601  0.408321  0.325738 -0.226819  1.404509  1.505800 -0.389084   \n",
      "1   -0.197842 -1.877104 -1.316487 -0.191919 -0.606597  0.435300  1.116149   \n",
      "2   -0.054534 -1.877104 -1.316487  0.383931 -0.240941 -0.176414 -0.497570   \n",
      "3    1.987608  0.642724  0.999471 -0.348968  1.404509 -0.788128 -0.578934   \n",
      "4   -0.412804  0.408321  0.620496 -0.279169 -0.423769  2.270442  0.077402   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "275 -0.878556 -0.236286  0.030980  0.052381 -1.337908 -0.023485  0.166903   \n",
      "276 -2.239984 -0.880893 -1.316487  0.540981  0.124715 -0.329342 -0.836586   \n",
      "277  0.733661  0.525522  0.788930 -0.331518  1.404509 -0.788128 -0.538252   \n",
      "278  0.482872  0.701324  1.378446 -0.436218  0.490370 -0.788128 -0.700980   \n",
      "279  0.590353  1.170129 -1.316487 -0.157019 -1.337908 -0.788128 -0.795904   \n",
      "\n",
      "          htn  \n",
      "0   -1.310895  \n",
      "1    0.762837  \n",
      "2   -1.310895  \n",
      "3    0.762837  \n",
      "4   -1.310895  \n",
      "..        ...  \n",
      "275 -1.310895  \n",
      "276 -1.310895  \n",
      "277  0.762837  \n",
      "278  0.762837  \n",
      "279  0.762837  \n",
      "\n",
      "[280 rows x 8 columns]\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr  \\\n",
      "0   -0.265758 -1.913880 -1.396007 -0.164989  0.529611 -0.811905  0.566156   \n",
      "1    0.354019  1.209188  0.832462 -0.433445  0.167484 -0.811905 -0.646947   \n",
      "2   -0.747807 -0.172169 -1.396007 -0.135160  0.529611  0.767164 -0.067518   \n",
      "3   -1.711905 -0.712700  0.275345  1.785049 -0.375707  2.346233  1.350234   \n",
      "4   -1.057696 -0.112110 -0.024642  0.442767 -1.281024  1.556699  1.843365   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "115 -0.699602 -1.913880 -1.396007 -0.004661  0.529611 -0.022370 -0.055190   \n",
      "116  0.422883  0.488480  0.746751 -0.265660 -1.281024 -0.022370  0.240689   \n",
      "117  1.283685  0.548539  1.132448 -0.470731  0.529611 -0.811905 -0.634619   \n",
      "118  1.662437  0.548539  0.832462 -0.452088  0.529611 -0.811905 -0.289427   \n",
      "119  1.111524  0.548539  1.175303 -0.377517  1.434928 -0.811905 -0.190801   \n",
      "\n",
      "          htn  \n",
      "0    0.788430  \n",
      "1    0.788430  \n",
      "2   -1.268344  \n",
      "3   -1.268344  \n",
      "4   -1.268344  \n",
      "..        ...  \n",
      "115 -1.268344  \n",
      "116 -1.268344  \n",
      "117  0.788430  \n",
      "118  0.788430  \n",
      "119  0.788430  \n",
      "\n",
      "[120 rows x 8 columns]\n",
      "The no of features are \n",
      " 9\n",
      "Index(['hemo', 'pcv', 'rbcc', 'sc', 'sg', 'al', 'bgr', 'htn', 'dm'], dtype='object')\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr  \\\n",
      "0    0.124601  0.408321  0.325738 -0.226819  1.404509  1.505800 -0.389084   \n",
      "1   -0.197842 -1.877104 -1.316487 -0.191919 -0.606597  0.435300  1.116149   \n",
      "2   -0.054534 -1.877104 -1.316487  0.383931 -0.240941 -0.176414 -0.497570   \n",
      "3    1.987608  0.642724  0.999471 -0.348968  1.404509 -0.788128 -0.578934   \n",
      "4   -0.412804  0.408321  0.620496 -0.279169 -0.423769  2.270442  0.077402   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "275 -0.878556 -0.236286  0.030980  0.052381 -1.337908 -0.023485  0.166903   \n",
      "276 -2.239984 -0.880893 -1.316487  0.540981  0.124715 -0.329342 -0.836586   \n",
      "277  0.733661  0.525522  0.788930 -0.331518  1.404509 -0.788128 -0.538252   \n",
      "278  0.482872  0.701324  1.378446 -0.436218  0.490370 -0.788128 -0.700980   \n",
      "279  0.590353  1.170129 -1.316487 -0.157019 -1.337908 -0.788128 -0.795904   \n",
      "\n",
      "          htn        dm  \n",
      "0   -1.310895 -1.290994  \n",
      "1    0.762837 -1.290994  \n",
      "2   -1.310895  0.774597  \n",
      "3    0.762837  0.774597  \n",
      "4   -1.310895  0.774597  \n",
      "..        ...       ...  \n",
      "275 -1.310895 -1.290994  \n",
      "276 -1.310895 -1.290994  \n",
      "277  0.762837  0.774597  \n",
      "278  0.762837  0.774597  \n",
      "279  0.762837  0.774597  \n",
      "\n",
      "[280 rows x 9 columns]\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr  \\\n",
      "0   -0.265758 -1.913880 -1.396007 -0.164989  0.529611 -0.811905  0.566156   \n",
      "1    0.354019  1.209188  0.832462 -0.433445  0.167484 -0.811905 -0.646947   \n",
      "2   -0.747807 -0.172169 -1.396007 -0.135160  0.529611  0.767164 -0.067518   \n",
      "3   -1.711905 -0.712700  0.275345  1.785049 -0.375707  2.346233  1.350234   \n",
      "4   -1.057696 -0.112110 -0.024642  0.442767 -1.281024  1.556699  1.843365   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "115 -0.699602 -1.913880 -1.396007 -0.004661  0.529611 -0.022370 -0.055190   \n",
      "116  0.422883  0.488480  0.746751 -0.265660 -1.281024 -0.022370  0.240689   \n",
      "117  1.283685  0.548539  1.132448 -0.470731  0.529611 -0.811905 -0.634619   \n",
      "118  1.662437  0.548539  0.832462 -0.452088  0.529611 -0.811905 -0.289427   \n",
      "119  1.111524  0.548539  1.175303 -0.377517  1.434928 -0.811905 -0.190801   \n",
      "\n",
      "          htn        dm  \n",
      "0    0.788430  0.667670  \n",
      "1    0.788430  0.667670  \n",
      "2   -1.268344  0.667670  \n",
      "3   -1.268344 -1.497746  \n",
      "4   -1.268344 -1.497746  \n",
      "..        ...       ...  \n",
      "115 -1.268344  0.667670  \n",
      "116 -1.268344 -1.497746  \n",
      "117  0.788430  0.667670  \n",
      "118  0.788430  0.667670  \n",
      "119  0.788430  0.667670  \n",
      "\n",
      "[120 rows x 9 columns]\n",
      "The no of features are \n",
      " 10\n",
      "Index(['hemo', 'pcv', 'rbcc', 'sc', 'sg', 'al', 'bgr', 'htn', 'dm', 'sod'], dtype='object')\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr  \\\n",
      "0    0.124601  0.408321  0.325738 -0.226819  1.404509  1.505800 -0.389084   \n",
      "1   -0.197842 -1.877104 -1.316487 -0.191919 -0.606597  0.435300  1.116149   \n",
      "2   -0.054534 -1.877104 -1.316487  0.383931 -0.240941 -0.176414 -0.497570   \n",
      "3    1.987608  0.642724  0.999471 -0.348968  1.404509 -0.788128 -0.578934   \n",
      "4   -0.412804  0.408321  0.620496 -0.279169 -0.423769  2.270442  0.077402   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "275 -0.878556 -0.236286  0.030980  0.052381 -1.337908 -0.023485  0.166903   \n",
      "276 -2.239984 -0.880893 -1.316487  0.540981  0.124715 -0.329342 -0.836586   \n",
      "277  0.733661  0.525522  0.788930 -0.331518  1.404509 -0.788128 -0.538252   \n",
      "278  0.482872  0.701324  1.378446 -0.436218  0.490370 -0.788128 -0.700980   \n",
      "279  0.590353  1.170129 -1.316487 -0.157019 -1.337908 -0.788128 -0.795904   \n",
      "\n",
      "          htn        dm       sod  \n",
      "0   -1.310895 -1.290994 -0.114332  \n",
      "1    0.762837 -1.290994  0.272648  \n",
      "2   -1.310895  0.774597  0.175903  \n",
      "3    0.762837  0.774597  0.659629  \n",
      "4   -1.310895  0.774597 -0.791548  \n",
      "..        ...       ...       ...  \n",
      "275 -1.310895 -1.290994  0.369394  \n",
      "276 -1.310895 -1.290994 -0.985038  \n",
      "277  0.762837  0.774597  0.756374  \n",
      "278  0.762837  0.774597  0.949864  \n",
      "279  0.762837  0.774597  0.369394  \n",
      "\n",
      "[280 rows x 10 columns]\n",
      "         hemo       pcv      rbcc        sc        sg        al       bgr  \\\n",
      "0   -0.265758 -1.913880 -1.396007 -0.164989  0.529611 -0.811905  0.566156   \n",
      "1    0.354019  1.209188  0.832462 -0.433445  0.167484 -0.811905 -0.646947   \n",
      "2   -0.747807 -0.172169 -1.396007 -0.135160  0.529611  0.767164 -0.067518   \n",
      "3   -1.711905 -0.712700  0.275345  1.785049 -0.375707  2.346233  1.350234   \n",
      "4   -1.057696 -0.112110 -0.024642  0.442767 -1.281024  1.556699  1.843365   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "115 -0.699602 -1.913880 -1.396007 -0.004661  0.529611 -0.022370 -0.055190   \n",
      "116  0.422883  0.488480  0.746751 -0.265660 -1.281024 -0.022370  0.240689   \n",
      "117  1.283685  0.548539  1.132448 -0.470731  0.529611 -0.811905 -0.634619   \n",
      "118  1.662437  0.548539  0.832462 -0.452088  0.529611 -0.811905 -0.289427   \n",
      "119  1.111524  0.548539  1.175303 -0.377517  1.434928 -0.811905 -0.190801   \n",
      "\n",
      "          htn        dm       sod  \n",
      "0    0.788430  0.667670  0.335780  \n",
      "1    0.788430  0.667670  0.911837  \n",
      "2   -1.268344  0.667670 -0.088682  \n",
      "3   -1.268344 -1.497746 -0.452508  \n",
      "4   -1.268344 -1.497746  0.305462  \n",
      "..        ...       ...       ...  \n",
      "115 -1.268344  0.667670  0.002274  \n",
      "116 -1.268344 -1.497746 -1.513665  \n",
      "117  0.788430  0.667670 -0.452508  \n",
      "118  0.788430  0.667670  0.002274  \n",
      "119  0.788430  0.667670  1.366619  \n",
      "\n",
      "[120 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# featureScores.nlargest(5,'Score').iloc[:,0:1]\n",
    "# featureScores.nlargest('Specs')\n",
    "\n",
    "# for i in range(5,11):\n",
    "#     f = featureScores.nlargest(i,'Score').iloc[:,0:1]\n",
    "#     t = train_features[f[\"Specs\"].tolist()]\n",
    "#     print(t)\n",
    "    \n",
    "# for i in range(5,11):\n",
    "#     print('The no of features are \\n ' +str(i))\n",
    "#     f = featureScores.nlargest(i,'Score').iloc[:,0:1]\n",
    "#     tr = train_features[f[\"Specs\"].tolist()]\n",
    "#     ts = test_features[f[\"Specs\"].tolist()]\n",
    "#     print(tr)\n",
    "#     print(ts)\n",
    "    \n",
    "# print(feat_importances.nlargest(i).index)\n",
    "for i in range(5,11):\n",
    "    print('The no of features are \\n ' +str(i))\n",
    "    f = feat_importances.nlargest(i).index\n",
    "    print(f)\n",
    "    tr = train_features[f.tolist()]\n",
    "    ts = test_features[f.tolist()]\n",
    "    print(tr)\n",
    "    print(ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd60c9c",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5442252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "\n",
      "Precision: 0.9130434782608695\n",
      "Accuracy: 0.95\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9333333333333332\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "\n",
      "Precision: 0.9565217391304348\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 1.0\n",
      "F1-score: 0.9777777777777777\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "\n",
      "Precision: 0.8979591836734694\n",
      "Accuracy: 0.9583333333333334\n",
      "Recall: 1.0\n",
      "F1-score: 0.9462365591397849\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "\n",
      "Precision: 0.9565217391304348\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 1.0\n",
      "F1-score: 0.9777777777777777\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9767441860465117\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "\n",
      "Precision: 0.9772727272727273\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9772727272727273\n",
      "\n",
      "Features: All Features SVM\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9885057471264368\n"
     ]
    }
   ],
   "source": [
    "#Support vector machine\n",
    "\n",
    "\n",
    "#initialise the Support Vector Model\n",
    "support_vector_machine_model = SVC(random_state = 0)\n",
    "\n",
    "#defining the svc parameters for grid search\n",
    "parameters_grid = {'kernel': ['poly', 'rbf', 'linear', 'sigmoid'], \n",
    "                   'C': [0.1, 1, 10, 100, 1000], \n",
    "                   'gamma': ['scale', 'auto'], \n",
    "                   'shrinking': [True, False]}\n",
    "\n",
    "\n",
    "svm_grid_search = GridSearchCV(support_vector_machine_model, parameters_grid, scoring = 'accuracy')\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nFeatures From method 1\\n\")\n",
    "for i in range(5,11):\n",
    "    print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "    f = feat_importances.nlargest(i).index\n",
    "    tr = train_features[f.tolist()]\n",
    "    ts = test_features[f.tolist()]\n",
    "    svm_grid_search.fit(tr, train_target)\n",
    "    svm_prediction = svm_grid_search.predict(ts)\n",
    "    print('\\nPrecision: ' + str(metrics.precision_score(test_target, svm_prediction)))\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(test_target, svm_prediction)))\n",
    "    print('Recall: ' + str(metrics.recall_score(test_target, svm_prediction)))\n",
    "    print('F1-score: ' + str(metrics.f1_score(test_target, svm_prediction)))\n",
    "\n",
    "\n",
    "print(\"\\nFeatures From method 2\\n\")\n",
    "for i in range(5,11):\n",
    "    print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "\n",
    "    f = featureScores.nlargest(i,'Score').iloc[:,0:1]\n",
    "    tr = train_features[f[\"Specs\"].tolist()]\n",
    "    ts = test_features[f[\"Specs\"].tolist()]\n",
    "    \n",
    "    \n",
    "    svm_grid_search.fit(tr, train_target)\n",
    "\n",
    "\n",
    "#     print('The best parameters are:\\n ' +str(svm_grid_search.best_params_))\n",
    "\n",
    "\n",
    "#     print('\\nThe best model after gridsearch is:\\n ' + str(svm_grid_search.best_estimator_))\n",
    "\n",
    "    #svm predictions on test features\n",
    "    svm_prediction = svm_grid_search.predict(ts)\n",
    "\n",
    "    print('\\nPrecision: ' + str(metrics.precision_score(test_target, svm_prediction)))\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(test_target, svm_prediction)))\n",
    "    print('Recall: ' + str(metrics.recall_score(test_target, svm_prediction)))\n",
    "    print('F1-score: ' + str(metrics.f1_score(test_target, svm_prediction)))\n",
    "\n",
    "\n",
    "#     print('\\nClassification Report:\\n' + str(metrics.classification_report(test_target, svm_prediction)))\n",
    "\n",
    "\n",
    "#     print('\\nConfusion Matrix: \\n' + str(metrics.confusion_matrix(test_target, svm_prediction)))\n",
    "#     sns.heatmap(metrics.confusion_matrix(test_target, svm_prediction), annot = True)\n",
    "#     plt.show()\n",
    "\n",
    "print(\"\\nFeatures: All Features SVM\\n\")\n",
    "svm_grid_search.fit(train_features, train_target)\n",
    "svm_prediction = svm_grid_search.predict(test_features)\n",
    "print('\\nPrecision: ' + str(metrics.precision_score(test_target, svm_prediction)))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(test_target, svm_prediction)))\n",
    "print('Recall: ' + str(metrics.recall_score(test_target, svm_prediction)))\n",
    "print('F1-score: ' + str(metrics.f1_score(test_target, svm_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9be38c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "\n",
      "Precision: 0.9555555555555556\n",
      "Accuracy: 0.975\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9662921348314608\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "\n",
      "Precision: 0.9555555555555556\n",
      "Accuracy: 0.975\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9662921348314608\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "\n",
      "Precision: 0.9772727272727273\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9772727272727273\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "\n",
      "Precision: 0.9767441860465116\n",
      "Accuracy: 0.975\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9655172413793104\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "\n",
      "Precision: 0.9772727272727273\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9772727272727273\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "\n",
      "Precision: 0.9545454545454546\n",
      "Accuracy: 0.9666666666666667\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9545454545454546\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "\n",
      "Precision: 0.9555555555555556\n",
      "Accuracy: 0.975\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9662921348314608\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9885057471264368\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9767441860465117\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9767441860465117\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9767441860465117\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "Features: All Features KNN\n",
      "\n",
      "\n",
      "Precision: 0.9130434782608695\n",
      "Accuracy: 0.95\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "#K-Nearest Neighbour\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#initialise the k nearest neighbour Model\n",
    "k_nearest_neighbour_model = KNeighborsClassifier()\n",
    "\n",
    "#defining the knn parameters for grid search\n",
    "knn_parameters_grid = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "                       'weights': ['uniform', 'distance'], \n",
    "                       'algorithm':['auto', 'ball_tree','kd_tree','brute'], \n",
    "                       'n_jobs':[1, -1]}\n",
    "\n",
    "\n",
    "knn_grid_search = GridSearchCV(k_nearest_neighbour_model, knn_parameters_grid, scoring = 'accuracy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nFeatures From method 1\\n\")\n",
    "for i in range(5,11):\n",
    "    print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "    f = feat_importances.nlargest(i).index\n",
    "    tr = train_features[f.tolist()]\n",
    "    ts = test_features[f.tolist()]\n",
    "    knn_grid_search.fit(tr, train_target)\n",
    "    knn_prediction = knn_grid_search.predict(ts)\n",
    "    print('\\nPrecision: ' + str(metrics.precision_score(test_target, knn_prediction)))\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(test_target, knn_prediction)))\n",
    "    print('Recall: ' + str(metrics.recall_score(test_target, knn_prediction)))\n",
    "    print('F1-score: ' + str(metrics.f1_score(test_target, knn_prediction)))\n",
    "    \n",
    "    \n",
    "print(\"\\nFeatures From method 2\\n\")\n",
    "for i in range(5,11):\n",
    "    print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "\n",
    "    f = featureScores.nlargest(i,'Score').iloc[:,0:1]\n",
    "    tr = train_features[f[\"Specs\"].tolist()]\n",
    "    ts = test_features[f[\"Specs\"].tolist()]\n",
    "    \n",
    "\n",
    "    knn_grid_search.fit(tr, train_target)\n",
    "\n",
    "\n",
    "#     print('The best parameters are:\\n ' +str(knn_grid_search.best_params_))\n",
    "\n",
    "\n",
    "#     print('\\nThe best model after gridsearch is:\\n ' + str(knn_grid_search.best_estimator_))\n",
    "\n",
    "    #KNN predictions on test features\n",
    "    knn_prediction = knn_grid_search.predict(ts)\n",
    "\n",
    "    #Performance Measure\n",
    "    print('\\nPrecision: ' + str(metrics.precision_score(test_target, knn_prediction)))\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(test_target, knn_prediction)))\n",
    "    print('Recall: ' + str(metrics.recall_score(test_target, knn_prediction)))\n",
    "    print('F1-score: ' + str(metrics.f1_score(test_target, knn_prediction)))\n",
    "\n",
    "\n",
    "#     print('\\nClassification Report:\\n' + str(metrics.classification_report(test_target, knn_prediction)))\n",
    "\n",
    "\n",
    "#     print('\\nConfusion Matrix: \\n' + str(metrics.confusion_matrix(test_target, knn_prediction)))\n",
    "#     sns.heatmap(metrics.confusion_matrix(test_target, knn_prediction), annot = True)\n",
    "#     plt.show()\n",
    "print(\"\\nFeatures: All Features KNN\\n\")\n",
    "knn_grid_search.fit(train_features, train_target)\n",
    "knn_prediction = knn_grid_search.predict(test_features)\n",
    "print('\\nPrecision: ' + str(metrics.precision_score(test_target, knn_prediction)))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(test_target, knn_prediction)))\n",
    "print('Recall: ' + str(metrics.recall_score(test_target, knn_prediction)))\n",
    "print('F1-score: ' + str(metrics.f1_score(test_target, knn_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff39cf88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "\n",
      "Precision: 0.9361702127659575\n",
      "Accuracy: 0.975\n",
      "Recall: 1.0\n",
      "F1-score: 0.967032967032967\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "\n",
      "Precision: 0.9361702127659575\n",
      "Accuracy: 0.975\n",
      "Recall: 1.0\n",
      "F1-score: 0.967032967032967\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "\n",
      "Precision: 0.9318181818181818\n",
      "Accuracy: 0.95\n",
      "Recall: 0.9318181818181818\n",
      "F1-score: 0.9318181818181818\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "\n",
      "Precision: 0.9772727272727273\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9772727272727273\n",
      "F1-score: 0.9772727272727273\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.975\n",
      "Recall: 0.9318181818181818\n",
      "F1-score: 0.9647058823529412\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "\n",
      "Precision: 0.9777777777777777\n",
      "Accuracy: 0.9916666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9887640449438202\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.9833333333333333\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9767441860465117\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "Features: All Features DT\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#initialise the decision tree Model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state = 0)\n",
    "\n",
    "#defining the decision tree parameters for grid search\n",
    "dt_parameters_grid = {'criterion': ['gini', 'entropy'], \n",
    "                      'splitter': ['best', 'random'], \n",
    "                      'min_samples_leaf': [1, 2, 3, 4, 5], \n",
    "                      'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "\n",
    "dt_grid_search = GridSearchCV(decision_tree_model, dt_parameters_grid, scoring = 'accuracy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nFeatures From method 1\\n\")\n",
    "for i in range(5,11):\n",
    "    print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "    f = feat_importances.nlargest(i).index\n",
    "    tr = train_features[f.tolist()]\n",
    "    ts = test_features[f.tolist()]\n",
    "    dt_grid_search.fit(tr, train_target)\n",
    "    dt_prediction = dt_grid_search.predict(ts)\n",
    "    print('\\nPrecision: ' + str(metrics.precision_score(test_target, dt_prediction)))\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(test_target, dt_prediction)))\n",
    "    print('Recall: ' + str(metrics.recall_score(test_target, dt_prediction)))\n",
    "    print('F1-score: ' + str(metrics.f1_score(test_target, dt_prediction)))\n",
    "\n",
    "\n",
    "print(\"\\nFeatures From method 2\\n\")\n",
    "for i in range(5,11):\n",
    "    print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "\n",
    "    f = featureScores.nlargest(i,'Score').iloc[:,0:1]\n",
    "    tr = train_features[f[\"Specs\"].tolist()]\n",
    "    ts = test_features[f[\"Specs\"].tolist()]\n",
    "    \n",
    "    dt_grid_search.fit(tr, train_target)\n",
    "\n",
    "\n",
    "#     print('The best parameters are:\\n ' +str(dt_grid_search.best_params_))\n",
    "\n",
    "\n",
    "#     print('\\nThe best model after gridsearch is:\\n ' + str(dt_grid_search.best_estimator_))\n",
    "\n",
    "    #Decision Tree predictions on test features\n",
    "    dt_prediction = dt_grid_search.predict(ts)\n",
    "    print('\\nPrecision: ' + str(metrics.precision_score(test_target, dt_prediction)))\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(test_target, dt_prediction)))\n",
    "    print('Recall: ' + str(metrics.recall_score(test_target, dt_prediction)))\n",
    "    print('F1-score: ' + str(metrics.f1_score(test_target, dt_prediction)))\n",
    "\n",
    "\n",
    "#     print('\\nClassification Report:\\n' + str(metrics.classification_report(test_target, dt_prediction)))\n",
    "\n",
    "\n",
    "#     print('\\nConfusion Matrix: \\n' + str(metrics.confusion_matrix(test_target, dt_prediction)))\n",
    "#     sns.heatmap(metrics.confusion_matrix(test_target, dt_prediction), annot = True)\n",
    "#     plt.show()\n",
    "print(\"\\nFeatures: All Features DT\\n\")\n",
    "dt_grid_search.fit(train_features, train_target)\n",
    "dt_prediction = dt_grid_search.predict(test_features)\n",
    "print('\\nPrecision: ' + str(metrics.precision_score(test_target, dt_prediction)))\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(test_target, dt_prediction)))\n",
    "print('Recall: ' + str(metrics.recall_score(test_target, dt_prediction)))\n",
    "print('F1-score: ' + str(metrics.f1_score(test_target, dt_prediction)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc0d2d",
   "metadata": {},
   "source": [
    "| Classification Algorithm | Accuracy (%) | Recall (%)| Precision (%) | F1-score (%)|\n",
    "|---|---|---|---|---|\n",
    "|Support Vector Machine|99.16|97.72|100|98.85|\n",
    "|K Nearest Neighbour   |95|93.18|93.18|93.18|\n",
    "|Decision Tree         |97.5|97.72|95.55|96.62|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e352485",
   "metadata": {},
   "source": [
    "## Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e218bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models, layers, optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "import tensorflow as tf\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3addfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_epochs = 10\n",
    "n_nodes = 16\n",
    "nb_classes = 2\n",
    "weight = 0.2\n",
    "class_weight = {0: weight, 1: (1-weight)}\n",
    "dropout = 0.1\n",
    "lr = 0.01\n",
    "n_basic_features = 24\n",
    "n_features = n_basic_features\n",
    "n_cnn_features = n_features\n",
    "n_filters = 16\n",
    "kernel_size_3 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f3446fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The no of features are 5\n",
      "\n",
      "     hemo     sg  rbcc   al   pcv\n",
      "0    15.4  1.020   5.2  1.0  44.0\n",
      "1    11.3  1.020   0.0  4.0  38.0\n",
      "2     9.6  1.010   0.0  2.0  31.0\n",
      "3    11.2  1.005   3.9  4.0  32.0\n",
      "4    11.6  1.010   4.6  2.0  35.0\n",
      "..    ...    ...   ...  ...   ...\n",
      "395  15.7  1.020   4.9  0.0  47.0\n",
      "396  16.5  1.025   6.2  0.0  54.0\n",
      "397  15.8  1.020   5.4  0.0  49.0\n",
      "398  14.2  1.025   5.9  0.0  51.0\n",
      "399  15.8  1.025   6.1  0.0  53.0\n",
      "\n",
      "[400 rows x 5 columns]\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "     hemo     sg  rbcc   al   pcv  htn\n",
      "0    15.4  1.020   5.2  1.0  44.0  0.0\n",
      "1    11.3  1.020   0.0  4.0  38.0  1.0\n",
      "2     9.6  1.010   0.0  2.0  31.0  1.0\n",
      "3    11.2  1.005   3.9  4.0  32.0  0.0\n",
      "4    11.6  1.010   4.6  2.0  35.0  1.0\n",
      "..    ...    ...   ...  ...   ...  ...\n",
      "395  15.7  1.020   4.9  0.0  47.0  1.0\n",
      "396  16.5  1.025   6.2  0.0  54.0  1.0\n",
      "397  15.8  1.020   5.4  0.0  49.0  1.0\n",
      "398  14.2  1.025   5.9  0.0  51.0  1.0\n",
      "399  15.8  1.025   6.1  0.0  53.0  1.0\n",
      "\n",
      "[400 rows x 6 columns]\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "     hemo     sg  rbcc   al   pcv  htn   dm\n",
      "0    15.4  1.020   5.2  1.0  44.0  0.0  0.0\n",
      "1    11.3  1.020   0.0  4.0  38.0  1.0  1.0\n",
      "2     9.6  1.010   0.0  2.0  31.0  1.0  0.0\n",
      "3    11.2  1.005   3.9  4.0  32.0  0.0  1.0\n",
      "4    11.6  1.010   4.6  2.0  35.0  1.0  1.0\n",
      "..    ...    ...   ...  ...   ...  ...  ...\n",
      "395  15.7  1.020   4.9  0.0  47.0  1.0  1.0\n",
      "396  16.5  1.025   6.2  0.0  54.0  1.0  1.0\n",
      "397  15.8  1.020   5.4  0.0  49.0  1.0  1.0\n",
      "398  14.2  1.025   5.9  0.0  51.0  1.0  1.0\n",
      "399  15.8  1.025   6.1  0.0  53.0  1.0  1.0\n",
      "\n",
      "[400 rows x 7 columns]\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "     hemo     sg  rbcc   al   pcv  htn   dm    bgr\n",
      "0    15.4  1.020   5.2  1.0  44.0  0.0  0.0  121.0\n",
      "1    11.3  1.020   0.0  4.0  38.0  1.0  1.0  121.2\n",
      "2     9.6  1.010   0.0  2.0  31.0  1.0  0.0  423.0\n",
      "3    11.2  1.005   3.9  4.0  32.0  0.0  1.0  117.0\n",
      "4    11.6  1.010   4.6  2.0  35.0  1.0  1.0  106.0\n",
      "..    ...    ...   ...  ...   ...  ...  ...    ...\n",
      "395  15.7  1.020   4.9  0.0  47.0  1.0  1.0  140.0\n",
      "396  16.5  1.025   6.2  0.0  54.0  1.0  1.0   75.0\n",
      "397  15.8  1.020   5.4  0.0  49.0  1.0  1.0  100.0\n",
      "398  14.2  1.025   5.9  0.0  51.0  1.0  1.0  114.0\n",
      "399  15.8  1.025   6.1  0.0  53.0  1.0  1.0  131.0\n",
      "\n",
      "[400 rows x 8 columns]\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "     hemo     sg  rbcc   al   pcv  htn   dm    bgr  appet\n",
      "0    15.4  1.020   5.2  1.0  44.0  0.0  0.0  121.0    1.0\n",
      "1    11.3  1.020   0.0  4.0  38.0  1.0  1.0  121.2    1.0\n",
      "2     9.6  1.010   0.0  2.0  31.0  1.0  0.0  423.0    0.0\n",
      "3    11.2  1.005   3.9  4.0  32.0  0.0  1.0  117.0    0.0\n",
      "4    11.6  1.010   4.6  2.0  35.0  1.0  1.0  106.0    1.0\n",
      "..    ...    ...   ...  ...   ...  ...  ...    ...    ...\n",
      "395  15.7  1.020   4.9  0.0  47.0  1.0  1.0  140.0    1.0\n",
      "396  16.5  1.025   6.2  0.0  54.0  1.0  1.0   75.0    1.0\n",
      "397  15.8  1.020   5.4  0.0  49.0  1.0  1.0  100.0    1.0\n",
      "398  14.2  1.025   5.9  0.0  51.0  1.0  1.0  114.0    1.0\n",
      "399  15.8  1.025   6.1  0.0  53.0  1.0  1.0  131.0    1.0\n",
      "\n",
      "[400 rows x 9 columns]\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "     hemo     sg  rbcc   al   pcv  htn   dm    bgr  appet    bu\n",
      "0    15.4  1.020   5.2  1.0  44.0  0.0  0.0  121.0    1.0  36.0\n",
      "1    11.3  1.020   0.0  4.0  38.0  1.0  1.0  121.2    1.0  18.0\n",
      "2     9.6  1.010   0.0  2.0  31.0  1.0  0.0  423.0    0.0  53.0\n",
      "3    11.2  1.005   3.9  4.0  32.0  0.0  1.0  117.0    0.0  56.0\n",
      "4    11.6  1.010   4.6  2.0  35.0  1.0  1.0  106.0    1.0  26.0\n",
      "..    ...    ...   ...  ...   ...  ...  ...    ...    ...   ...\n",
      "395  15.7  1.020   4.9  0.0  47.0  1.0  1.0  140.0    1.0  49.0\n",
      "396  16.5  1.025   6.2  0.0  54.0  1.0  1.0   75.0    1.0  31.0\n",
      "397  15.8  1.020   5.4  0.0  49.0  1.0  1.0  100.0    1.0  26.0\n",
      "398  14.2  1.025   5.9  0.0  51.0  1.0  1.0  114.0    1.0  50.0\n",
      "399  15.8  1.025   6.1  0.0  53.0  1.0  1.0  131.0    1.0  18.0\n",
      "\n",
      "[400 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5,11):\n",
    "    print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "    f = featureScores.nlargest(i,'Score').iloc[:,0:1]\n",
    "    tr = feature_classes[f[\"Specs\"].tolist()]\n",
    "    print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5195fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 663ms/step - loss: 0.1989 - accuracy: 0.7571 - val_loss: 0.5303 - val_accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0973 - accuracy: 0.9000 - val_loss: 0.4839 - val_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0673 - accuracy: 0.9393 - val_loss: 0.4403 - val_accuracy: 0.9250\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0576 - accuracy: 0.9429 - val_loss: 0.3995 - val_accuracy: 0.9250\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0544 - accuracy: 0.9286 - val_loss: 0.3584 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0499 - accuracy: 0.9286 - val_loss: 0.3255 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0482 - accuracy: 0.9321 - val_loss: 0.3055 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0522 - accuracy: 0.9464 - val_loss: 0.2960 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0429 - accuracy: 0.9536 - val_loss: 0.2865 - val_accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0414 - accuracy: 0.9607 - val_loss: 0.2795 - val_accuracy: 0.9417\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "\n",
      "Precision: 0.8627450980392157\n",
      "Accuracy: 0.9416666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9263157894736842\n",
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 428ms/step - loss: 0.2213 - accuracy: 0.6714 - val_loss: 0.4521 - val_accuracy: 0.9500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0998 - accuracy: 0.8500 - val_loss: 0.3974 - val_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0774 - accuracy: 0.8750 - val_loss: 0.3686 - val_accuracy: 0.9417\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0660 - accuracy: 0.9071 - val_loss: 0.3449 - val_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0573 - accuracy: 0.9286 - val_loss: 0.3234 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0501 - accuracy: 0.9321 - val_loss: 0.3081 - val_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0494 - accuracy: 0.9429 - val_loss: 0.2986 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0503 - accuracy: 0.9500 - val_loss: 0.2847 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0424 - accuracy: 0.9464 - val_loss: 0.2692 - val_accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0415 - accuracy: 0.9571 - val_loss: 0.2576 - val_accuracy: 0.9583\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "\n",
      "Precision: 0.8979591836734694\n",
      "Accuracy: 0.9583333333333334\n",
      "Recall: 1.0\n",
      "F1-score: 0.9462365591397849\n",
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 494ms/step - loss: 0.3265 - accuracy: 0.3643 - val_loss: 0.5517 - val_accuracy: 0.8667\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1064 - accuracy: 0.7357 - val_loss: 0.4641 - val_accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0870 - accuracy: 0.8750 - val_loss: 0.4019 - val_accuracy: 0.9417\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0757 - accuracy: 0.9000 - val_loss: 0.3526 - val_accuracy: 0.9583\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0668 - accuracy: 0.9393 - val_loss: 0.3147 - val_accuracy: 0.9667\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0566 - accuracy: 0.9429 - val_loss: 0.2866 - val_accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0522 - accuracy: 0.9536 - val_loss: 0.2658 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0485 - accuracy: 0.9714 - val_loss: 0.2478 - val_accuracy: 0.9667\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0412 - accuracy: 0.9607 - val_loss: 0.2338 - val_accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0366 - accuracy: 0.9714 - val_loss: 0.2234 - val_accuracy: 0.9750\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "\n",
      "Precision: 0.9361702127659575\n",
      "Accuracy: 0.975\n",
      "Recall: 1.0\n",
      "F1-score: 0.967032967032967\n",
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 849ms/step - loss: 0.3196 - accuracy: 0.6071 - val_loss: 0.4922 - val_accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0798 - accuracy: 0.9536 - val_loss: 0.3848 - val_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0618 - accuracy: 0.9464 - val_loss: 0.3178 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0566 - accuracy: 0.9536 - val_loss: 0.2712 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0433 - accuracy: 0.9607 - val_loss: 0.2402 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0413 - accuracy: 0.9607 - val_loss: 0.2172 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0386 - accuracy: 0.9571 - val_loss: 0.2015 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0387 - accuracy: 0.9536 - val_loss: 0.1926 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0320 - accuracy: 0.9536 - val_loss: 0.1895 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0335 - accuracy: 0.9536 - val_loss: 0.1875 - val_accuracy: 0.9333\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "\n",
      "Precision: 0.8461538461538461\n",
      "Accuracy: 0.9333333333333333\n",
      "Recall: 1.0\n",
      "F1-score: 0.9166666666666666\n",
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 407ms/step - loss: 0.3102 - accuracy: 0.6000 - val_loss: 0.4277 - val_accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0762 - accuracy: 0.9321 - val_loss: 0.3574 - val_accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0541 - accuracy: 0.9429 - val_loss: 0.3126 - val_accuracy: 0.9083\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0503 - accuracy: 0.9500 - val_loss: 0.2809 - val_accuracy: 0.9083\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0417 - accuracy: 0.9429 - val_loss: 0.2622 - val_accuracy: 0.9083\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0443 - accuracy: 0.9286 - val_loss: 0.2533 - val_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0406 - accuracy: 0.9286 - val_loss: 0.2546 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0347 - accuracy: 0.9393 - val_loss: 0.2549 - val_accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0319 - accuracy: 0.9429 - val_loss: 0.2515 - val_accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0312 - accuracy: 0.9429 - val_loss: 0.2482 - val_accuracy: 0.9000\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "\n",
      "Precision: 0.7857142857142857\n",
      "Accuracy: 0.9\n",
      "Recall: 1.0\n",
      "F1-score: 0.88\n",
      "\n",
      "Features From method 1\n",
      "\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 407ms/step - loss: 0.4571 - accuracy: 0.4179 - val_loss: 0.5666 - val_accuracy: 0.8750\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1619 - accuracy: 0.8786 - val_loss: 0.4655 - val_accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0994 - accuracy: 0.9214 - val_loss: 0.3994 - val_accuracy: 0.9250\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0730 - accuracy: 0.9286 - val_loss: 0.3511 - val_accuracy: 0.9250\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0601 - accuracy: 0.9286 - val_loss: 0.3170 - val_accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0526 - accuracy: 0.9321 - val_loss: 0.2980 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0456 - accuracy: 0.9536 - val_loss: 0.2879 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0416 - accuracy: 0.9500 - val_loss: 0.2837 - val_accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0380 - accuracy: 0.9500 - val_loss: 0.2873 - val_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0306 - accuracy: 0.9571 - val_loss: 0.2896 - val_accuracy: 0.9167\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "\n",
      "Precision: 0.8148148148148148\n",
      "Accuracy: 0.9166666666666666\n",
      "Recall: 1.0\n",
      "F1-score: 0.8979591836734693\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 5\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 513ms/step - loss: 0.4034 - accuracy: 0.2929 - val_loss: 0.5103 - val_accuracy: 0.8583\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0992 - accuracy: 0.8393 - val_loss: 0.3973 - val_accuracy: 0.8917\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0687 - accuracy: 0.9143 - val_loss: 0.3595 - val_accuracy: 0.8917\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0578 - accuracy: 0.9214 - val_loss: 0.3477 - val_accuracy: 0.8833\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0574 - accuracy: 0.9179 - val_loss: 0.3486 - val_accuracy: 0.8833\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0528 - accuracy: 0.9393 - val_loss: 0.3538 - val_accuracy: 0.8833\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0460 - accuracy: 0.9500 - val_loss: 0.3640 - val_accuracy: 0.8833\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0454 - accuracy: 0.9464 - val_loss: 0.3703 - val_accuracy: 0.8833\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0474 - accuracy: 0.9500 - val_loss: 0.3728 - val_accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0449 - accuracy: 0.9536 - val_loss: 0.3709 - val_accuracy: 0.8833\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "\n",
      "Precision: 0.7586206896551724\n",
      "Accuracy: 0.8833333333333333\n",
      "Recall: 1.0\n",
      "F1-score: 0.8627450980392156\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 6\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 379ms/step - loss: 0.2922 - accuracy: 0.4857 - val_loss: 0.4948 - val_accuracy: 0.8417\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0852 - accuracy: 0.9071 - val_loss: 0.3977 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0770 - accuracy: 0.9321 - val_loss: 0.3475 - val_accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0669 - accuracy: 0.9393 - val_loss: 0.3130 - val_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0598 - accuracy: 0.9571 - val_loss: 0.2875 - val_accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0573 - accuracy: 0.9500 - val_loss: 0.2673 - val_accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0502 - accuracy: 0.9464 - val_loss: 0.2510 - val_accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0462 - accuracy: 0.9536 - val_loss: 0.2362 - val_accuracy: 0.9250\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0452 - accuracy: 0.9536 - val_loss: 0.2238 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0437 - accuracy: 0.9536 - val_loss: 0.2135 - val_accuracy: 0.9417\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "\n",
      "Precision: 0.8627450980392157\n",
      "Accuracy: 0.9416666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9263157894736842\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 7\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 467ms/step - loss: 0.2583 - accuracy: 0.6536 - val_loss: 0.5029 - val_accuracy: 0.9250\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0708 - accuracy: 0.9071 - val_loss: 0.4152 - val_accuracy: 0.9583\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0516 - accuracy: 0.9429 - val_loss: 0.3605 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0421 - accuracy: 0.9464 - val_loss: 0.3309 - val_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0472 - accuracy: 0.9250 - val_loss: 0.3029 - val_accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0464 - accuracy: 0.9429 - val_loss: 0.2761 - val_accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0425 - accuracy: 0.9571 - val_loss: 0.2455 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0365 - accuracy: 0.9464 - val_loss: 0.2108 - val_accuracy: 0.9250\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0334 - accuracy: 0.9536 - val_loss: 0.1785 - val_accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0264 - accuracy: 0.9714 - val_loss: 0.1556 - val_accuracy: 0.9500\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "\n",
      "Precision: 0.88\n",
      "Accuracy: 0.95\n",
      "Recall: 1.0\n",
      "F1-score: 0.9361702127659575\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 8\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 550ms/step - loss: 0.5794 - accuracy: 0.4893 - val_loss: 0.4307 - val_accuracy: 0.9583\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1389 - accuracy: 0.9071 - val_loss: 0.3288 - val_accuracy: 0.9583\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0998 - accuracy: 0.9143 - val_loss: 0.2760 - val_accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0852 - accuracy: 0.9071 - val_loss: 0.2343 - val_accuracy: 0.9583\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0721 - accuracy: 0.9107 - val_loss: 0.1995 - val_accuracy: 0.9667\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0657 - accuracy: 0.9250 - val_loss: 0.1705 - val_accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0594 - accuracy: 0.9357 - val_loss: 0.1487 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0528 - accuracy: 0.9286 - val_loss: 0.1309 - val_accuracy: 0.9667\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0504 - accuracy: 0.9321 - val_loss: 0.1173 - val_accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0411 - accuracy: 0.9500 - val_loss: 0.1069 - val_accuracy: 0.9583\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "\n",
      "Precision: 0.9333333333333333\n",
      "Accuracy: 0.9583333333333334\n",
      "Recall: 0.9545454545454546\n",
      "F1-score: 0.9438202247191012\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 9\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 405ms/step - loss: 0.4983 - accuracy: 0.2429 - val_loss: 0.5753 - val_accuracy: 0.9583\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.1720 - accuracy: 0.8357 - val_loss: 0.4532 - val_accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1003 - accuracy: 0.9214 - val_loss: 0.3767 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0826 - accuracy: 0.9107 - val_loss: 0.3246 - val_accuracy: 0.9417\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0734 - accuracy: 0.9179 - val_loss: 0.2889 - val_accuracy: 0.9417\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0647 - accuracy: 0.9429 - val_loss: 0.2647 - val_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0549 - accuracy: 0.9464 - val_loss: 0.2473 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0491 - accuracy: 0.9429 - val_loss: 0.2367 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0463 - accuracy: 0.9393 - val_loss: 0.2305 - val_accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0425 - accuracy: 0.9607 - val_loss: 0.2293 - val_accuracy: 0.9417\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "\n",
      "Precision: 0.8627450980392157\n",
      "Accuracy: 0.9416666666666667\n",
      "Recall: 1.0\n",
      "F1-score: 0.9263157894736842\n",
      "\n",
      "Features From method 2\n",
      "\n",
      "\n",
      "The no of features are 10\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 4s 716ms/step - loss: 0.5091 - accuracy: 0.3571 - val_loss: 0.4842 - val_accuracy: 0.9667\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.1239 - accuracy: 0.8643 - val_loss: 0.3771 - val_accuracy: 0.9750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0859 - accuracy: 0.8857 - val_loss: 0.3050 - val_accuracy: 0.9750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0731 - accuracy: 0.8857 - val_loss: 0.2497 - val_accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0719 - accuracy: 0.8786 - val_loss: 0.2065 - val_accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0626 - accuracy: 0.9071 - val_loss: 0.1727 - val_accuracy: 0.9750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0581 - accuracy: 0.9143 - val_loss: 0.1449 - val_accuracy: 0.9750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0556 - accuracy: 0.9179 - val_loss: 0.1241 - val_accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0505 - accuracy: 0.9179 - val_loss: 0.1083 - val_accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0444 - accuracy: 0.9357 - val_loss: 0.0949 - val_accuracy: 0.9750\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "\n",
      "Precision: 1.0\n",
      "Accuracy: 0.975\n",
      "Recall: 0.9318181818181818\n",
      "F1-score: 0.9647058823529412\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,2):\n",
    "    \n",
    "    for i in range(5,11):\n",
    "        if k==0:\n",
    "            print(\"\\nFeatures From method 1\\n\")\n",
    "            print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "            f = feat_importances.nlargest(i).index\n",
    "            tr = feature_classes[f.tolist()]\n",
    "        else:\n",
    "            print(\"\\nFeatures From method 2\\n\")\n",
    "            print('\\nThe no of features are ' +str(i)+\"\\n\")\n",
    "            f = featureScores.nlargest(i,'Score').iloc[:,0:1]\n",
    "            tr = feature_classes[f[\"Specs\"].tolist()]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(tr, target_class1, test_size=0.3, random_state=42)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test  = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "        n_cnn_features = i\n",
    "        X_train_cnn = X_train\n",
    "        X_test_cnn = X_test\n",
    "\n",
    "\n",
    "        X_train_cnn = X_train_cnn.reshape((X_train.shape[0],n_cnn_features,1))\n",
    "        X_test_cnn  = X_test_cnn.reshape((X_test.shape[0],n_cnn_features,1))\n",
    "\n",
    "        nb_classes = 2\n",
    "        Y_train_cat = np_utils.to_categorical(y_train, nb_classes)\n",
    "        Y_test_cat = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "        inp_cnn   = Input(shape=(n_cnn_features,1))\n",
    "\n",
    "        adam = tf.keras.optimizers.Adam(lr=lr)\n",
    "        activation = 'relu'\n",
    "\n",
    "        #Two convolution layers\n",
    "        d_1 = layers.Conv1D(n_filters, kernel_size_3, input_shape=(n_cnn_features,1), padding='same', activation='relu', name='layer_1')(inp_cnn)\n",
    "        d_2 = layers.Dropout(dropout)(d_1)\n",
    "        d_3 = layers.Conv1D(n_filters, kernel_size_3, padding='same', activation='relu', name='layer_2')(d_2)\n",
    "        d_4 = layers.Dropout(dropout)(d_3)\n",
    "\n",
    "        #Flattening operation\n",
    "        d_5 = layers.Flatten()(d_4)\n",
    "\n",
    "        #Fully connected layer 1\n",
    "        d_6 = layers.Dense(n_nodes, name='layer_3')(d_5)\n",
    "        d_7 = layers.BatchNormalization()(d_6)\n",
    "        d_8 = layers.Dropout(dropout)(d_7)\n",
    "        d_9 = layers.Activation(activation='relu')(d_8)\n",
    "\n",
    "        #Output layer(softmax function)\n",
    "        d_10 = layers.Dense(2, activation='softmax')(d_9)\n",
    "\n",
    "        #Model definition:\n",
    "        model_cnn_3 = Model(inp_cnn, d_10)\n",
    "        #model_cnn_3.summary()\n",
    "        model_cnn_3.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        history = model_cnn_3.fit(X_train_cnn, Y_train_cat, batch_size=batch_size,\n",
    "                                  epochs=n_epochs, class_weight=class_weight,\n",
    "                                  validation_data=(X_test_cnn, Y_test_cat)) \n",
    "\n",
    "        pred = model_cnn_3.predict([X_test_cnn], verbose=1)\n",
    "        Y_pred = np.reshape(np.argmax(pred, axis=1), newshape=(pred.shape[0],1)) \n",
    "        Y_test_ = np.asarray(np.reshape(y_test, newshape=(y_test.shape[0],1)), dtype=np.int)\n",
    "\n",
    "        print('\\nPrecision: ' + str(metrics.precision_score(y_test, Y_pred)))\n",
    "        print('Accuracy: ' + str(metrics.accuracy_score(y_test, Y_pred)))\n",
    "        print('Recall: ' + str(metrics.recall_score(y_test, Y_pred)))\n",
    "        print('F1-score: ' + str(metrics.f1_score(y_test, Y_pred)))\n",
    "\n",
    "\n",
    "    #     print('\\nClassification Report:\\n' + str(metrics.classification_report(y_test, Y_pred)))\n",
    "\n",
    "\n",
    "    #     print('\\nConfusion Matrix: \\n' + str(metrics.confusion_matrix(y_test, Y_pred)))\n",
    "    #     sns.heatmap(metrics.confusion_matrix(y_test, Y_pred), annot = True)\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3208f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "960ef518",
   "metadata": {},
   "source": [
    "## Pickel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    " \n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(svm_grid_search, 'ckd.pkl')\n",
    " \n",
    "# Load the model from the file\n",
    "svm_from_joblib = joblib.load('ckd.pkl')\n",
    " \n",
    "# Use the loaded model to make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_from_joblib.predict(test_features)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c333965",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mean_squared_error(test_target, y_pred)\n",
    "mean_absolute_percentage_error(test_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e145453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
